<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="00045-DGL-KE 学习笔记, NLP LLM DeepLearning LuYF-Lemon-love 自然语言处理 深度学习 大语言模型">
    <meta name="description" content="前言Knowledge graphs (KGs) are data structures that store information about different entities (nodes) and their relations">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>00045-DGL-KE 学习笔记 | LuYF-Lemon-love の Blog</title>
    <link rel="icon" type="image/jpeg" href="https://cos.luyf-lemon-love.space/images/苏苏1.jpeg">
    
    <style>
        body{
            background-image: url(https://cos.luyf-lemon-love.space/images/016-%E6%8A%A5%E7%BA%B8%E5%A2%99%E9%BA%BB%E8%A1%A3%E5%AD%A6%E5%A7%90.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <span class="logo-span">LuYF-Lemon-love の Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>List</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/galleries">
          
          <i class="fas fa-image" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Image</span>
        </a>
      </li>
      
      <li>
        <a href="/verse">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Verse</span>
        </a>
      </li>
      
      <li>
        <a href="/bilibili">
          
          <i class="fas fa-video" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Bilibili</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Server</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="https://luyf-lemon-love.space">
          
          <i class="fas fa-cloud" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Github</span>
        </a>
      </li>
      
      <li>
        <a href="https://server.luyf-lemon-love.space">
          
          <i class="fas fa-cloud" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Cloud</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <div class="logo-name">LuYF-Lemon-love の Blog</div>
        <div class="logo-desc">
            
            天之道，损有余而补不足，人之道则不然，损不足以奉有余。
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			List
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/galleries " style="margin-left:75px">
				  
				   <i class="fa fas fa-image" style="position: absolute;left:50px" ></i>
			      
		          <span>Image</span>
                  </a>
                </li>
              
                <li>

                  <a href="/verse " style="margin-left:75px">
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Verse</span>
                  </a>
                </li>
              
                <li>

                  <a href="/bilibili " style="margin-left:75px">
				  
				   <i class="fa fas fa-video" style="position: absolute;left:50px" ></i>
			      
		          <span>Bilibili</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Server
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="https://luyf-lemon-love.space " style="margin-left:75px">
				  
				   <i class="fa fas fa-cloud" style="position: absolute;left:50px" ></i>
			      
		          <span>Github</span>
                  </a>
                </li>
              
                <li>

                  <a href="https://server.luyf-lemon-love.space " style="margin-left:75px">
				  
				   <i class="fa fas fa-cloud" style="position: absolute;left:50px" ></i>
			      
		          <span>Cloud</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/LuYF-Lemon-love/paper-is-all-you-need" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/LuYF-Lemon-love/paper-is-all-you-need" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cos.luyf-lemon-love.space/images/%E5%8E%9F%E7%A5%9E.webp')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">00045-DGL-KE 学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                                <span class="chip bg-color">知识图谱</span>
                            </a>
                        
                            <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/">
                                <span class="chip bg-color">知识图谱补全</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/PyTorch/" class="post-category">
                                PyTorch
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-01-27
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-28
                </div>
                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>Knowledge graphs (KGs) are data structures that store information about different entities (nodes) and their relations (edges).</strong> A common approach of using KGs in various machine learning tasks is to compute knowledge graph embeddings. <strong>DGL-KE is a high performance, easy-to-use, and scalable package for learning large-scale knowledge graph embeddings.</strong> The package is implemented on the top of <em><a href="https://github.com/dmlc/dgl">Deep Graph Library (DGL)</a></em> and developers can run DGL-KE on CPU machine, GPU machine, as well as clusters with a set of popular models, including <code>TransE</code>, <code>TransR</code>, <code>RESCAL</code>, <code>DistMult</code>, <code>ComplEx</code>, and <code>RotatE</code>.</p>
<p>DGL-KE 代码仓库链接: <a href="https://github.com/awslabs/dgl-ke">https://github.com/awslabs/dgl-ke</a> .</p>
<p>操作系统：<strong>Windows 10 家庭版</strong></p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol>
<li><p><a href="https://github.com/awslabs/dgl-ke">DGL-KE</a></p>
</li>
<li><p><a href="https://dglke.dgl.ai/doc/">DGL-KE Documentation</a></p>
</li>
<li><p><a href="https://arxiv.org/abs/2004.08532">DGL-KE paper</a></p>
</li>
</ol>
<h2 id="项目仓库"><a href="#项目仓库" class="headerlink" title="项目仓库"></a>项目仓库</h2><img src="https://cos.luyf-lemon-love.space/images/logo.png" width = "400"/>

<p><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" alt="License"></p>
<p><a href="https://dglke.dgl.ai/doc/">Documentation</a></p>
<p><strong>Knowledge graphs (KGs) are data structures that store information about different entities (nodes) and their relations (edges).</strong> A common approach of using KGs in various machine learning tasks is to compute knowledge graph embeddings. <strong>DGL-KE is a high performance, easy-to-use, and scalable package for learning large-scale knowledge graph embeddings.</strong> The package is implemented on the top of <em><a href="https://github.com/dmlc/dgl">Deep Graph Library (DGL)</a></em> and developers can run DGL-KE on CPU machine, GPU machine, as well as clusters with a set of popular models, including <code>TransE</code>, <code>TransR</code>, <code>RESCAL</code>, <code>DistMult</code>, <code>ComplEx</code>, and <code>RotatE</code>.</p>
<p align="center">
  <img src="https://cos.luyf-lemon-love.space/images/dgl_ke_arch.png" alt="DGL-ke architecture" width="600">
  <br>
  <b>Figure</b>: DGL-KE Overall Architecture
</p>

<p>Currently DGL-KE support three tasks:</p>
<ul>
<li><p>Training, trains KG embeddings using <code>dglke_train</code>(single machine) or <code>dglke_dist_train</code>(distributed environment).</p>
</li>
<li><p>Evaluation, reads the pre-trained embeddings and evaluates the embeddings with a link prediction task on the test set using <code>dglke_eval</code>.</p>
</li>
<li><p>Inference, reads the pre-trained embeddings and do the entities&#x2F;relations linkage predicting inference tasks using <code>dglke_predict</code> or do the embedding similarity  inference tasks using <code>dglke_emb_sim</code>.</p>
</li>
</ul>
<h3 id="A-Quick-Start"><a href="#A-Quick-Start" class="headerlink" title="A Quick Start"></a>A Quick Start</h3><p>To install the latest version of DGL-KE run:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pip3 <span class="token function">install</span> dgl
<span class="token function">sudo</span> pip3 <span class="token function">install</span> dglke<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>Train a <code>transE</code> model on <code>FB15k</code> dataset by running the following command:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">DGLBACKEND</span><span class="token operator">=</span>pytorch dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--max_step</span> <span class="token number">500</span> <span class="token parameter variable">--log_interval</span> <span class="token number">100</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">-adv</span> <span class="token parameter variable">--regularization_coef</span> <span class="token number">1</span>.00E-09 <span class="token parameter variable">--test</span> <span class="token parameter variable">--num_thread</span> <span class="token number">1</span> <span class="token parameter variable">--num_proc</span> <span class="token number">8</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>This command will download the <code>FB15k</code> dataset, train the <code>transE</code> model and save the trained embeddings into the file.</p>
<h3 id="Performance-and-Scalability"><a href="#Performance-and-Scalability" class="headerlink" title="Performance and Scalability"></a>Performance and Scalability</h3><p><strong>DGL-KE is designed for learning at scale.</strong> It introduces various novel optimizations that accelerate training on knowledge graphs with millions of nodes and billions of edges. Our benchmark on knowledge graphs consisting of over <em>86M</em> nodes and <em>338M</em> edges shows that DGL-KE can compute embeddings in 100 minutes on an EC2 instance with 8 GPUs and 30 minutes on an EC2 cluster with 4 machines (48 cores&#x2F;machine). These results represent a <em>2×∼5×</em> speedup over the best competing approaches.</p>
<p align="center">
  <img src="https://cos.luyf-lemon-love.space/images/vs-gv-fb15k.png" alt="vs-gv-fb15k" width="750">
  <br>
  <b>Figure</b>: DGL-KE vs GraphVite on FB15k
</p>

<p align="center">
  <img src="https://cos.luyf-lemon-love.space/images/vs-pbg-fb.png" alt="vs-pbg-fb" width="750">
  <br>
  <b>Figure</b>: DGL-KE vs Pytorch-BigGraph on Freebase
</p>

<p>Learn more details with our <a href="https://dglke.dgl.ai/doc/">documentation</a>! If you are interested in the optimizations in DGL-KE, please check out <a href="https://arxiv.org/abs/2004.08532">our paper</a> for more details.</p>
<h3 id="Cite"><a href="#Cite" class="headerlink" title="Cite"></a>Cite</h3><p>If you use DGL-KE in a scientific publication, we would appreciate citations to the following paper:</p>
<pre class="line-numbers language-bibtex" data-language="bibtex"><code class="language-bibtex">@inproceedings&#123;DGL-KE,
author &#x3D; &#123;Zheng, Da and Song, Xiang and Ma, Chao and Tan, Zeyuan and Ye, Zihao and Dong, Jin and Xiong, Hao and Zhang, Zheng and Karypis, George&#125;,
title &#x3D; &#123;DGL-KE: Training Knowledge Graph Embeddings at Scale&#125;,
year &#x3D; &#123;2020&#125;,
publisher &#x3D; &#123;Association for Computing Machinery&#125;,
address &#x3D; &#123;New York, NY, USA&#125;,
booktitle &#x3D; &#123;Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval&#125;,
pages &#x3D; &#123;739–748&#125;,
numpages &#x3D; &#123;10&#125;,
series &#x3D; &#123;SIGIR &#39;20&#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="License"><a href="#License" class="headerlink" title="License"></a>License</h3><p>This project is licensed under the Apache-2.0 License.</p>
<h2 id="DGL-KE-Documentation"><a href="#DGL-KE-Documentation" class="headerlink" title="DGL-KE Documentation"></a>DGL-KE Documentation</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/">https://dglke.dgl.ai/doc/</a> .</p>
<p><strong>Knowledge graphs (KGs) are data structures that store information about different entities (nodes) and their relations (edges).</strong> A common approach of using KGs in various machine learning tasks is to compute knowledge graph embeddings. <code>DGL-KE is a high performance, easy-to-use, and scalable package for learning large-scale knowledge graph embeddings.</code> The package is implemented on the top of Deep Graph Library (<a href="https://www.dgl.ai/">DGL</a>) and developers can run DGL-KE on CPU machine, GPU machine, as well as clusters with a set of popular models, including <code>TransE</code>, <code>TransR</code>, <code>RESCAL</code>, <code>DistMult</code>, <code>ComplEx</code>, and <code>RotatE</code>.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/dgl_ke_arch.png"></p>
<h3 id="Performance-and-Scalability-1"><a href="#Performance-and-Scalability-1" class="headerlink" title="Performance and Scalability"></a>Performance and Scalability</h3><p><strong>DGL-KE is designed for learning at scale.</strong> It introduces various novel optimizations that accelerate training on knowledge graphs with millions of nodes and billions of edges. Our benchmark on knowledge graphs consisting of over 86M nodes and 338M edges shows that DGL-KE can compute embeddings in 100 minutes on an EC2 instance with 8 GPUs and 30 minutes on an EC2 cluster with 4 machines (48 cores&#x2F;machine). These results represent a <strong>2×∼5×</strong> speedup over the best competing approaches.</p>
<p><em>DGL-KE vs Graphvite</em></p>
<p><img src="https://cos.luyf-lemon-love.space/images/vs-gv-fb15k.png"></p>
<p><em>DGL-KE vs Pytorch-Biggraph</em></p>
<p><img src="https://cos.luyf-lemon-love.space/images/vs-pbg-fb.png"></p>
<p><strong>Get started with DGL-KE!</strong></p>
<h2 id="Installation-Guide"><a href="#Installation-Guide" class="headerlink" title="Installation Guide"></a>Installation Guide</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/install.html">https://dglke.dgl.ai/doc/install.html</a> .</p>
<p>This topic explains how to install DGL-KE. We recommend installing DGL-KE by using <code>pip</code> and from the source.</p>
<h3 id="System-requirements"><a href="#System-requirements" class="headerlink" title="System requirements"></a>System requirements</h3><p>DGL-KE works with the following operating systems:</p>
<ul>
<li><p><code>Ubuntu 16.04 or higher version</code></p>
</li>
<li><p><code>macOS x</code></p>
</li>
</ul>
<p>DGL-KE requires <code>Python version 3.5 or later</code>. Python 3.4 or earlier is not tested. Python 2 support is coming.</p>
<p>DGL-KE supports multiple tensor libraries as backends, e.g., <code>PyTorch</code> and <code>MXNet</code>. For requirements on backends and how to select one, see Working with different backends. As a demo, we install <code>Pytorch</code> using <code>pip</code>:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pip3 <span class="token function">install</span> torch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="Install-DGL"><a href="#Install-DGL" class="headerlink" title="Install DGL"></a>Install DGL</h3><p>DGL-KE is implemented on the top of DGL (0.4.3 version). You can install DGL using pip:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pip3 <span class="token function">install</span> <span class="token assign-left variable">dgl</span><span class="token operator">==</span><span class="token number">0.4</span>.3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="Install-DGL-KE"><a href="#Install-DGL-KE" class="headerlink" title="Install DGL-KE"></a>Install DGL-KE</h3><p>After installing DGL, you can install DGL-KE. The fastest way to install DGL-KE is by using pip:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> pip3 <span class="token function">install</span> dglke<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>or you can install DGL-KE from source:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/awslabs/dgl-ke.git
<span class="token builtin class-name">cd</span> dgl-ke/python
<span class="token function">sudo</span> python3 setup.py <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h3 id="Have-a-Quick-Test"><a href="#Have-a-Quick-Test" class="headerlink" title="Have a Quick Test"></a>Have a Quick Test</h3><p>Once you install DGL-KE successfully, you can test it by the following command:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># create a new workspace</span>
<span class="token function">mkdir</span> my_task <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">cd</span> my_task
<span class="token comment"># Train transE model on FB15k dataset</span>
<span class="token assign-left variable">DGLBACKEND</span><span class="token operator">=</span>pytorch dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--max_step</span> <span class="token number">500</span> <span class="token parameter variable">--log_interval</span> <span class="token number">100</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">-adv</span> <span class="token parameter variable">--regularization_coef</span> <span class="token number">1</span>.00E-09 <span class="token parameter variable">--test</span> <span class="token parameter variable">--num_thread</span> <span class="token number">1</span> <span class="token parameter variable">--num_proc</span> <span class="token number">8</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>This command will download the FB15k dataset, train the transE model on that, and save the trained embeddings into the file. You could see the following output at the end:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">-------------- Test result --------------
Test average MRR <span class="token builtin class-name">:</span> <span class="token number">0.47221913961451095</span>
Test average MR <span class="token builtin class-name">:</span> <span class="token number">58.68289854581774</span>
Test average HITS@1 <span class="token builtin class-name">:</span> <span class="token number">0.2784276548560207</span>
Test average HITS@3 <span class="token builtin class-name">:</span> <span class="token number">0.6244265375564998</span>
Test average HITS@10 <span class="token builtin class-name">:</span> <span class="token number">0.7726295474936941</span>
-----------------------------------------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Introduction-to-Knowledge-Graph-Embedding"><a href="#Introduction-to-Knowledge-Graph-Embedding" class="headerlink" title="Introduction to Knowledge Graph Embedding"></a>Introduction to Knowledge Graph Embedding</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/kg.html">https://dglke.dgl.ai/doc/kg.html</a> .</p>
<p><strong>Knowledge Graphs (KGs) have emerged as an effective way to integrate disparate data sources and model underlying relationships for applications such as search.</strong> At Amazon, we use KGs to represent the hierarchical relationships among products; the relationships between creators and content on Amazon Music and Prime Video; and information for Alexa’s question-answering service. <strong>Information extracted from KGs in the form of embeddings is used to improve search, recommend products, and infer missing information.</strong></p>
<h3 id="What-is-a-graph"><a href="#What-is-a-graph" class="headerlink" title="What is a graph"></a>What is a graph</h3><p><strong>A graph is a structure used to represent things and their relations.</strong> It is made of two sets - the set of nodes (also called vertices) and the set of edges (also called arcs). Each edge itself connects a pair of nodes indicating that there is a relation between them. <strong>This relation can either be undirected, e.g., capturing symmetric relations between nodes, or directed, capturing asymmetric relations.</strong> For example, if a graph is used to model the friendship relations of people in a social network, then the edges will be undirected as they are used to indicate that two people are friends; however, if the graph is used to model how people follow each other on Twitter, the edges will be directed. Depending on the edges’ directionality, a graph can be directed or undirected.</p>
<p>Graphs can be either homogeneous or heterogeneous. <strong>In a homogeneous graph, all the nodes represent instances of the same type and all the edges represent relations of the same type.</strong> For instance, a social network is a graph consisting of people and their connections, all representing the same entity type. <strong>In contrast, in a heterogeneous graph, the nodes and edges can be of different types.</strong> For instance, the graph for encoding the information in a marketplace will have buyer, seller, and product nodes that are connected via wants-to-buy, has-bought, is-customer-of, and is-selling edges.</p>
<p>Finally, another class of graphs that is especially important for knowledge graphs are multigraphs. <strong>These are graphs that can have multiple (directed) edges between the same pair of nodes and can also contain loops. These multiple edges are typically of different types and as such most multigraphs are heterogeneous.</strong> Note that graphs that do not allow these multiple edges and self-loops are called simple graphs.</p>
<h3 id="What-is-a-Knowledge-Graph"><a href="#What-is-a-Knowledge-Graph" class="headerlink" title="What is a Knowledge Graph"></a>What is a Knowledge Graph</h3><p>In the earlier marketplace graph example, <code>the labels assigned to the different node types (buyer, seller, product) and the different relation types (wants-to-buy, has-bought, is-customer-of, is-selling) convey precise information (often called semantics) about what the nodes and relations represent for that particular domain.</code> Once this graph is populated, it will encode the knowledge that we have about that marketplace as it relates to types of nodes and relations included. Such a graph is an example of a knowledge graph.</p>
<p><code>A knowledge graph (KG) is a directed heterogeneous multigraph whose node and relation types have domain-specific semantics.</code> <strong>KGs allow us to encode the knowledge into a form that is human interpretable and amenable to automated analysis and inference.</strong> KGs are becoming a popular approach to represent diverse types of information in the form of different types of entities connected via different types of relations.</p>
<p>When working with KGs, we adopt a different terminology than the traditional vertices and edges used in graphs. <code>The vertices of the knowledge graph are often called entities and the directed edges are often called triplets and are represented as a (h, r, t) tuple, where h is the head entity, t is the tail entity, and r is the relation associating the head with the tail entities.</code> Note that the term relation here refers to the type of the relation (e.g., one of wants-to-buy, has-bought, is-customer-of, and is-selling).</p>
<p>Let us examine a directed multigraph in an example, which includes a cast of characters and the world in which they live.</p>
<p><strong>Scenario</strong>:</p>
<p><strong>Mary</strong> and <strong>Tom</strong> are <em>siblings</em> and they both are are <em>vegetarians</em>, who like <strong>potatoes</strong> and <strong>cheese</strong>. Mary and Tom both work at <strong>Amazon</strong>. <strong>Joe</strong> is a bloke who is <em>a colleague of</em> Tom. To make the matter complicated, Joe loves Mary, but we do not know if the feeling is reciprocated.</p>
<p>Joe is from <strong>Quebec</strong> and is proud of his native dish of <strong>Poutine</strong>, which is composed of potato, cheese, and <strong>gravy</strong>. We also know that gravy contains <strong>meat</strong> in some form.</p>
<p>Joe is excited to invite Tom for dinner and has sneakily included his sibling, Mary, in the invitation. His plans are doomed from get go as he is planning to serve the vegetarian siblings his favourite Quebecois dish, Poutine.</p>
<p>Oh! by the way, a piece of geography trivia: Quebec is located in a <strong>province</strong> of the same name which in turn is located in <strong>Canada</strong>.</p>
<p>There are several relationships in this scenario that are not explicitly mentioned but we can simply infer from what we are given:</p>
<ul>
<li><p>Mary is a colleague of Tom.</p>
</li>
<li><p>Tom is a colleague of Mary.</p>
</li>
<li><p>Mary is Tom’s sister.</p>
</li>
<li><p>Tom is Mary’s brother.</p>
</li>
<li><p>Poutine has meat.</p>
</li>
<li><p>Poutine is not a vegetarian dish.</p>
</li>
<li><p>Mary and Tom would not eat Poutine.</p>
</li>
<li><p>Poutine is a Canadian dish.</p>
</li>
<li><p>Joe is Canadian.</p>
</li>
<li><p>Amazon is a workplace for Mary, Tom, and Joe.</p>
</li>
</ul>
<p>There are also some interesting negative conclusions that seem intuitive to us, but not to the machine:</p>
<ul>
<li><p>Potato does not like Mary.</p>
</li>
<li><p>Canada is not from Joe.</p>
</li>
<li><p>Canada is not located in Quebec.</p>
</li>
</ul>
<p>What we have examined is a knowledge graph, a set of nodes with different types of relations:</p>
<ul>
<li><p><code>1-to-1</code>: Mary is a sibling of Tom.</p>
</li>
<li><p><code>1-to-N</code>: Amazon is a workplace for Mary, Tom, and Joe.</p>
</li>
<li><p><code>N-to-1</code>: Joe, Tom, and Mary work at Amazon.</p>
</li>
<li><p><code>N-to-N</code>: Joe, Mary, and Tom are colleagues.</p>
</li>
</ul>
<p>There are other categorization perspectives on the relationships as well:</p>
<ul>
<li><p>Symmetric: Joe is a colleague of Tom entails Tom is also a colleague of Joe.</p>
</li>
<li><p>Antisymmetric: Quebec is located in Canada entails that Canada cannot be located in Quebec.</p>
</li>
</ul>
<p><code>Figure 1</code> visualizes a knowledge-base that describes World of Mary. For more information on how to use the examples, please refer to the <a href="https://github.com/cyrusmvahid/GNNTrainingMaterial/blob/master/March2020/supportingexamples/examples.py">code</a> that draws the examples.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/kg_example.png"></p>
<h3 id="What-is-the-task-of-Knowledge-Graph-Embedding"><a href="#What-is-the-task-of-Knowledge-Graph-Embedding" class="headerlink" title="What is the task of Knowledge Graph Embedding?"></a>What is the task of Knowledge Graph Embedding?</h3><p><code>Knowledge graph embedding is the task of completing the knowledge graphs by probabilistically inferring the missing arcs from the existing graph structure.</code> KGE differs from ordinary relation inference as the information in a knowledge graph is multi-relational and more complex to model and computationally expensive. For this rest of this blog, we examine fundamentals of KGE.</p>
<h3 id="Score-Function"><a href="#Score-Function" class="headerlink" title="Score Function"></a>Score Function</h3><p>There are different flavours of KGE that have been developed over the course of the past few years. What most of them have in common is a score function. <code>The score function measures how distant two nodes relative to its relation type.</code> As we are setting the stage to introduce the reader to DGL-KE, an open source knowledge graph embedding library, we limit the scope only to those methods that are implemented by DGL-KE and are listed in Figure 2.</p>
<p>Figure2: A list of score functions for KE papers implemented by DGL-KE</p>
<p><img src="https://cos.luyf-lemon-love.space/images/kge_scores.png"></p>
<h3 id="A-short-explanation-of-the-score-functions"><a href="#A-short-explanation-of-the-score-functions" class="headerlink" title="A short explanation of the score functions"></a>A short explanation of the score functions</h3><p>Knowledge graphs that are beyond toy examples are always large, high dimensional, and sparse. High dimensionality and sparsity result from the amount of information that the KG holds that can be represented with 1-hot or n-hot vectors. The fact that most of the items have no relationship with one another is another major contributor to sparsity of KG representations. We, therefore, <code>desire to project the sparse and high dimensional graph representation vector space into a lower dimensional dense space.</code> This is similar to the process used to generate word embeddings and reduce dimensions in recommender systems based on matrix factorization models. I will provide a detailed account of all the methods in a different post, but here I will shortly explain <code>how projections differ in each paper</code>, <code>what the score functions do</code>, and <code>what consequences the choices have for relationship inference</code> and <code>computational complexity</code>.</p>
<h4 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h4><p><strong>TransE is a representative translational distance model that represents entities and relations as vectors in the same semantic space of dimension $\mathbb{R}^d$, where $d$ is the dimension of the target space with reduced dimension.</strong> A fact in the source space is represented as a triplet $(h,r,t)$ where $h$ is short for head, $r$ is for relation, and $t$ is for tail. <strong>The relationship is interpreted as a translation vector so that the embedded entities are connected by relation $r$ have a short distance.</strong> In terms of vector computation it could mean adding a head to a relation should approximate to the relation’s tail, or $h+r \approx t$. For example if $h_1&#x3D;emb(“Ottawa”),\ h_2&#x3D;emb(“Berlin”), t_1&#x3D;emb(“Canada”), t_2&#x3D;(“Germany”)$, and finally $r&#x3D;”CapilatOf”$, then $h_1 + r$ and $h_2+r$ should approximate $t_1$ and $t_2$  respectively. <strong>TransE performs linear transformation and the scoring function is negative distance between $h+r$ and $t$, or $f&#x3D;-|h+r-t|_{\frac{1}{2}}$</strong></p>
<p>Figure 3: TransE</p>
<p><img src="https://cos.luyf-lemon-love.space/images/transe.png"></p>
<h4 id="TransR"><a href="#TransR" class="headerlink" title="TransR"></a>TransR</h4><p>TransE cannot cover a relationship that is not 1-to-1 as it learns only one aspect of similarity. <strong>TransR addresses this issue with separating relationship space from entity space where $h, t \in \mathbb{R}^k$ and $r \in \mathbb{R}^d$.</strong> The semantic spaces do not need to be of the same dimension. <strong>In the multi-relationship modeling we learn a projection matrix $M\in \mathbb{R}^{k \times d}$ for each relationship that can project an entity to different relationship semantic spaces.</strong> Each of these spaces capture a different aspect of an entity that is related to a distinct relationship. <strong>In this case a head node $h$ and a tail node $t$ in relation to relationship $r$ is projected into the relationship space using the learned projection matrix $M_r$ as $h_r&#x3D;hM_r$ and $t_r&#x3D;tM_r$ respectively.</strong> Figure 5 illustrates this projection.</p>
<p>Let us explore this using an example. Mary and Tom are siblings and colleagues. They both are vegetarians. Joe also works for Amazon and is a colleague of Mary and Tom. TransE might end up learning very similar embeddings for Mary, Tom, and Joe because they are colleagues but cannot recognize the (not) sibling relationship. Using TransR, we learn projection matrices: <strong>$M_{sib},\ M_{clg}$ and $M_{vgt}$ that perform better at learning relationship like (not)sibling.</strong></p>
<p>The score function in TransR is similar to the one used in TransE and measures <strong>euclidean distance between $h+r$ and $t$, but the distance measure is per relationship space.</strong> More formally: $f_r&#x3D;|h_r+r-t_r|_2^2$</p>
<p>Figure 4: TransR projecting different aspects of an entity to a relationship space.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/transr.png"></p>
<p><strong>Another advantage of TransR over TransE is its ability to extract compositional rules.</strong> Ability to extract rules has two major benefits. It offers richer information and has a smaller memory space as we can infer some rules from others.</p>
<hr>
<p><strong>Drawbacks</strong></p>
<p>The benefits from more expressive projections in TransR adds to the complexity of the model and a higher rate of data transfer, which has adversely affected distributed training. TransE requires $O(d)$ parameters per relation, where $d$ is the dimension of semantic space in TransE and includes both entities and relationships. <strong>As TransR projects entities to a relationship space of dimension $k$, it will require $O(kd)$  parameters per relation.</strong> Depending on the size of k, this could potentially increase the number of parameters drastically. In exploring DGL-KE, we will examine benefits of DGL-KE in making computation of knowledge embedding significantly more efficient.</p>
<p>TransE and its variants such as TransR are generally called translational distance models as they translate the entities, relationships and measure distance in the target semantic spaces. <strong>A second category of KE models is called semantic matching that includes models such as RESCAL, DistMult, and ComplEx.These models make use of a similarity-based scoring function.</strong></p>
<p>The first of semantic matching models we explore is RESCAL.</p>
<h4 id="RESCAL"><a href="#RESCAL" class="headerlink" title="RESCAL"></a>RESCAL</h4><p>RESCAL is a <strong>bilinear</strong> model that captures latent semantics of a knowledge graph through associate entities with vectors and represents each relation as a matrix that <strong>models pairwise interaction</strong> between entities.</p>
<p>Multiple relations of any order can be represented as tensors. In fact $n-dimensional$ tensors are by definition representations of multi-dimensional vector spaces. <strong>RESCAL, therefore, proposes to capture entities and relationships as multidimensional tensors as illustrated in figure 5.</strong></p>
<p>RESCAL uses semantic web’s RDF formation where relationships are modeled as $(subject, predicate, object)$. <strong>Tensor $\mathcal{X}$ contains such relationships as $\mathcal{X}_{ijk}$ between $i$th and $j$th entities through $k$th relation.</strong> Value of $\mathcal{X}_{ijk}$ is determined as:</p>
<p>$$<br>\begin{split}\mathcal{X}_{ijk} &#x3D;<br>     \begin{cases}<br>       1\  &amp;\quad\text{if }(e_i, r_k, e_j)\text{ holds}\<br>       0\  &amp;\quad\text{if }(e_i, r_k, e_j)\text{ does not hold}<br>     \end{cases}\end{split}<br>$$</p>
<p>Figure 5: RESCAL captures entities and their relations as multi-dimensional tensor</p>
<p><img src="https://cos.luyf-lemon-love.space/images/rescal.png"></p>
<p><strong>As entity relationship tensors tend to be sparse, the authors of RESCAL, propose a dyadic decomposition to capture the inherent structure of the relations in the form of a latent vector representation of the entities and an asymmetric square matrix that captures the relationships.</strong> More formally each slice of $\mathcal{X}_k$ is decomposed as a rank$-r$ factorization:</p>
<p>$$<br>\mathcal{X}_k \approx AR_k\mathbf{A}^\top, \text{ for } k&#x3D;1, \dots, m<br>$$</p>
<p>where A is an $n\times r$ matrix of latent-component representation of entities and asymmetrical $r\times r$ square matrix $R_k$ that models interaction for $k_th$ predicate component in $\mathcal{X}$. To make sense of it all, let’s take a look at an example:</p>
<p>$$<br>\begin{gather}<br>   Entities&#x3D;{\text{Mary :}0, \text{Tom :}1, \text{Joe :}2} \<br>   Relationships&#x3D;{\text{sibling, colleague}} \<br>   Relation_{k&#x3D;0}^{sibling}: \text{Mary and Tom are siblings but Joe is not their sibling.} \<br>   Relations_{k&#x3D;1}^{colleague}: \text{Mary,Tom, and Joe are colleagues}\<br>   \text{relationship matrices will model: }\mathcal{X_k}&#x3D;<br>   \begin{bmatrix}<br>   Mary &amp; Tom  &amp; Joe \<br>   Tom  &amp; Joe &amp; Mary \<br>   Joe  &amp; Mary  &amp; Tom<br>   \end{bmatrix}\<br>   {\mathcal{X}}<em>{0:sibling}&#x3D;<br>   \begin{bmatrix}<br>   0 &amp; 1 &amp; 0\<br>   0 &amp; 0 &amp; 1\<br>   0 &amp; 0 &amp; 0<br>   \end{bmatrix}\<br>   \mathcal{X}</em>{1:colleague}&#x3D;<br>   \begin{bmatrix}<br>   0 &amp; 1 &amp; 1\<br>   1 &amp; 0 &amp; 1\<br>   1 &amp; 1 &amp; 0<br>   \end{bmatrix}<br>\end{gather}<br>$$</p>
<p><strong>Note that even in such a small knowledge graph where two of the three entities have even a symmetrical relationship, matrices $\mathcal{X}_k$ are sparse and asymmetrical.</strong> Obviously colleague relationship in this example is not representative of a real world problem. Even though such relationships can be created, they contain no information as probability of occurring is high. For instance if we are creating a knowledge graph for registered members of a website is a specific country, we do not model relations like “is countryman of” as it contains little information and has very low entropy.</p>
<p><strong>Next step in RESCAL is decomposing matrices $\mathcal{X}_k$ using a rank_k decomposition as illustrated in figure 6.</strong></p>
<p>Figure 6: Each of the $k$ slices of martix $\mathcal{X}$ is factorized to its k-rank components in form of a $n\times r$ entity-latent component and an asymmetric $r\times r$ that specifies interactions of entity-latent components per relation.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/rescal2.png"></p>
<p><strong>$A$ and $R_k$ are computed through solving an optimization problem that is correlated to minimizing the distance between $\mathcal{X}_k$ and $AR_k\mathbf{A}^\top$.</strong></p>
<p>Now that the structural decomposition of entities and their relationships are modeled, we need to create a score function that can predict existence of relationship for those entities we lack their mutual connection information.</p>
<p><strong>The score function $f_r(h,t)$ for $h,t\in \mathbb{R}^d$, where $h$ and $t$ are representations of head and tail entities, captures pairwise interactions between entities in $h$ and $t$ through relationship matrix $M_r$ that is the collection of all individual $R_k$ matrices and is of dimension $d\times d$.</strong></p>
<p>$$<br>f_r(h, t) &#x3D; \mathbf{h}^\top M_rt &#x3D; \sum_{i&#x3D;0}^{d-1}\sum_{j&#x3D;0}^{d-1}[M_r]_{ij}.[h]_i.[t]_j<br>$$</p>
<p>Figure 7 illustrates computation of the the score for RESCAL method.</p>
<p>Figure 7: RESCAL</p>
<p><img src="https://cos.luyf-lemon-love.space/images/rescal3.png"></p>
<p>Score function $f$ requires $O(d^2)$ parameters per relation.</p>
<h4 id="DistMult"><a href="#DistMult" class="headerlink" title="DistMult"></a>DistMult</h4><p>If we want to speed up the computation of RESCAL and <strong>limit the relationships only to symmetric relations, then we can take advantage of the proposal put forth by DistMult, which simplifies RESCAL by restricting $M_r$ from a general asymmetric $r\times r$ matrix to a diagonal square matrix, thus reducing the number of parameters per relation to $O(d)$.</strong> DistMulti introduces vector embedding $r \in \mathcal{R}^d$, the score function for DistMult where $M_r&#x3D;diag(r)$ is computed as:</p>
<p>$$<br>f_r(h,t) &#x3D; \mathbf{h}^\top diag(r) t &#x3D; \sum_{i&#x3D;0}^{d-1}[r]_i.[h]_i.[t]_i<br>$$</p>
<p>Figure 8 illustrates how DistMulti computes the score by capturing the pairwise interaction only along the same dimensions of components of h and t.</p>
<p>Figure 8: DistMulti</p>
<p><img src="https://cos.luyf-lemon-love.space/images/distmult.png"></p>
<p><strong>A basic refresher on linear algebra</strong></p>
<p>$$<br>\begin{split}if\ A&#x3D;[a_{ij}]<em>{m\times n}&#x3D;<br>\begin{bmatrix}<br>a</em>{11} &amp; a_{12} &amp; \dots  &amp; a_{1n} \<br>a_{21} &amp; a_{22} &amp; \dots  &amp; a_{2n} \<br>\vdots &amp; \vdots &amp; \ddots &amp; \dots  \<br>a_{m1} &amp; a_{m2} &amp; \dots  &amp; a_{mn} \<br>\end{bmatrix}<em>{m\times n} \text{ and }<br>B&#x3D;[b</em>{ij}]<em>{n\times k}&#x3D;<br>\begin{bmatrix}<br>b</em>{11} &amp; b_{12} &amp; \dots  &amp; b_{1k} \<br>b_{21} &amp; b_{22} &amp; \dots  &amp; b_{2k} \<br>\vdots &amp; \vdots &amp; \ddots &amp; \dots  \<br>b_{n1} &amp; b_{n2} &amp; \dots  &amp; b_{nk} \<br>\end{bmatrix}<em>{n\times k}\        \<br>then<br>C&#x3D;[c</em>{mk}]<em>{m\times k}\ such\ that\  c</em>{mk}&#x3D;\sum_{p&#x3D;1}^{k}a_{mp}b_{pk}, thus: \<br>C_{m\times k} &#x3D; \begin{bmatrix}<br>a_{11}b_{11} + \dots + a_{1n}b_{n1} &amp; a_{11}b_{12} + \dots + a_{1n}b_{n2} &amp; \dots  &amp; a_{11}b_{1k} + \dots + a_{1n}b_{nk} \<br>a_{21}b_{11} + \dots + a_{2n}b_{n1} &amp; a_{21}b_{12} + \dots + a_{2n}b_{n2} &amp; \dots  &amp; a_{21}b_{1k} + \dots + a_{2n}b_{nk} \<br>\vdots &amp; \vdots &amp; \ddots &amp; \dots  \<br>a_{m1}b_{11} + \dots + a_{mn}b_{n1} &amp; a_{m1}b_{12} + \dots + a_{mn}b_{n2} &amp; \dots  &amp; a_{m1}b_{1k} + \dots + a_{mn}b_{nk} \<br>\end{bmatrix}_{n\times k}\end{split}<br>$$</p>
<p>We know that a diagonal matrix is a matrix in which all non diagonal elements, $(i \neq j)$, are zero. This reduces complexity of matrix multiplication as for diagonal matrix multiplication for diagonal matrices $A_{m\times n}$ and $B_{n\times k}$, $C&#x3D;AB&#x3D; [c_{mk}]_{m\times k}$ where</p>
<p>$$<br>\begin{split}c_{mk} &#x3D;<br>\begin{cases}<br>0&amp; \text{for }m \neq k \<br>a_mb_k&amp; \text{for }m &#x3D; k<br>\end{cases}\end{split}<br>$$</p>
<p>This is basically multiplying to numbers $a_{ii}$ and $b_{ii}$ to get the value for the corresponding diagonal element on $C$.</p>
<p><strong>This complexity reduction is the reason that whenever possible we would like to reduce matrices to diagonal matrices.</strong></p>
<h4 id="ComplEx"><a href="#ComplEx" class="headerlink" title="ComplEx"></a>ComplEx</h4><p><strong>In order to model a KG effectively, models need to be able to identify most common relationship patters as laid out earlier in this blog. relations can be reflexive&#x2F;irreflexive, symmetric&#x2F;antisymmetric, and transitive&#x2F;intransitive.</strong> We have also seen two classes of semantic matching models, RESCAL and DistMulti. RESCAL is expressive but has an exponential complexity, while DistMulti has linear complexity but is limited to symmetric relations.</p>
<p>An ideal model needs to keep linear complexity while being able to capture antisymmetric relations. Let us go back to what is good at DistMulti. It is using a rank-decomposition based on a diagonal matrix. <strong>We know that dot product of embedding scale well and handles symmetry, reflexity, and irreflexivity effectively.</strong> Matrix factorization (MF) methods have been very successful in recommender systems. MF works based on factorizing a relation matrix to dot product of lower dimensional matrices $\mathbf{U}\mathbf{V}^\top$ where $\mathbf{U}\mathbf{V} \in \mathbb{R}^{n\times K}$. <strong>The underlying assumption here is that the same entity would be taken to be different depending on whether it appears as a subject or an object in a relationship.</strong> For instance “Quebec” in “Quebec is located in Canada” and “Joe is from Quebec” appears as subject and object respectively. <strong>In many link prediction tasks the same entity can assume both roles as we perform graph embedding through adjacency matrix computation.</strong> Dealing with antisymmetric relationships, consequently, has resulted in an explosion of parameters and increased complexity and memory requirements.</p>
<p>The goal ComplEx is set to achieve is performing embedding while reducing the number of required parameters, to scale well, and to capture antisymmetric relations. <strong>One essential strategy is to compute a joint representation for the entities regardless of their role as subject or object and perform dot product on those embeddings.</strong></p>
<p><strong>Such embeddings cannot be achieved in the real vector spaces, so the ComplEx authors propose complex embedding.</strong></p>
<p>But first a quick reminder about complex vectors.</p>
<hr>
<p>Complex Vector Space 1 is the unit for real numbers, $i&#x3D;\sqrt{-1}$ is the imaginary unit of complex numbers. <strong>Each complex number has two parts, a real and an imaginary part and is represented as $c &#x3D; a + bi \in \mathbb{C}$.</strong> As expected, the complex plane has a horizontal and a vertical axis. Real numbers are placed on the horizontal axis and the vertical axis represents the imaginary part of a number. This is done in much the same way as in $x$ and $y$ are represented on Cartesian plane. An n-dimensional complex vector $\mathcal{V}\in \mathbb{C}^n$ is a vector whose elements $v_i\in \mathbb{C}$ are complex numbers.</p>
<p>Example:</p>
<p>$$<br>\begin{split}V_1 &#x3D; \begin{bmatrix}<br>2 + 3i \<br>1 + 5i<br>\end{bmatrix}<br>\text{ and }<br>V_2 &#x3D; \begin{bmatrix}<br>2 + 3i \<br>1 + 5i \<br>3<br>\end{bmatrix}<br>\text{ are in } \mathbb{C}^2\text{ and }\mathbb{C}^3\text{ respectively.}\end{split}<br>$$</p>
<p>$\mathbb{R} \subset \mathbb{C}$ and $\mathbb{R}^n \subset \mathbb{C}^n$. Basically a real number is a complex number whose imaginary part has a coefficient of zero.</p>
<p><strong>modulus of a complex number</strong> $z$ is a complex number as is given by $z&#x3D;a+bi$, modulus $z$ is analogous to size in vector space and is given by $\mid z\mid &#x3D; \sqrt{a^2 + b^2}$</p>
<p><strong>Complex Conjugate</strong> The conjugate of complex number $z&#x3D;a+bi$ is denoted by $\bar{z}$ and is given by $\bar{z}&#x3D;a-bi$.</p>
<p>Example:</p>
<p>$$<br>\begin{split}\bar{V}_1 &#x3D; \begin{bmatrix}<br>2 - 3i \<br>1 - 5i<br>\end{bmatrix}<br>\text{ and }<br>\bar{V}_2 &#x3D; \begin{bmatrix}<br>2 - 3i \<br>1 - 5i \<br>3<br>\end{bmatrix}<br>\text{ are in } \mathbb{C}^2\text{ and }\mathbb{C}^3\text{ respectively.}\end{split}<br>$$</p>
<p><strong>Conjugate Transpose</strong> The conjugate transpose of a complex matrix $\mathcal{A}$, is denoted as $\mathcal{A}^*$ and is given by $\mathcal{A}^* &#x3D; \mathbf{\bar{\mathcal{A}}}^\top$ where elements of $\bar{\mathcal{A}}$ are complex conjugates of $\mathcal{A}.$</p>
<p>Example:</p>
<p>$$<br>V^*_1 &#x3D; \begin{bmatrix}<br>2 - 3i &amp;<br>1 - 5i<br>\end{bmatrix}<br>\text{ and }<br>V^*_2 &#x3D; \begin{bmatrix}<br>2 - 3i &amp;<br>1 - 5i &amp;<br>3<br>\end{bmatrix}<br>\text{ are in } \mathbb{C}^2\text{ and }\mathbb{C}^3\text{ respectively.}<br>$$</p>
<p><strong>Complex dot product. aka Hermitian inner product</strong> if $\mathbf{u}$ and $\mathbf{c}$ are complex vectors, then their inner product is defined as $\langle \mathbf{u}, \mathbf{v} \rangle &#x3D; \mathbf{u}^*\mathbf{v}$.</p>
<p>Example:</p>
<p>$$<br>\begin{split}u &#x3D; \begin{bmatrix}<br>2 + 3i \<br>1 + 5i<br>\end{bmatrix}<br>\text{ and }<br>v &#x3D; \begin{bmatrix}<br>1 + i \<br>2 + 2i<br>\end{bmatrix}<br>\text{ are in } \mathbb{C}^2\text{ and }\mathbb{C}^3\text{ respectively.} \<br>\text{ then }u^*&#x3D; \begin{bmatrix}<br>2 - 3i &amp;<br>1 - 5i<br>\end{bmatrix}<br>\text{ and } \<br>\langle u,v \rangle &#x3D; u^*v &#x3D; \begin{bmatrix}<br>2 - 3i &amp;<br>1 - 5i<br>\end{bmatrix}<br>\begin{bmatrix}<br>1 + i \<br>2 + 2i<br>\end{bmatrix}<br>&#x3D; (2-3i)(1+i)+(1-5i)(2+2i)&#x3D;[4-13i]\end{split}<br>$$</p>
<p><strong>Definition</strong>: A complex matrix $A$ us <strong>unitary</strong> when $A^{-1} &#x3D; A^*$</p>
<p>Example: $A &#x3D; \frac{1}{2}\begin{bmatrix}1+i &amp; 1-i \1-i &amp; 1+i\end{bmatrix}$</p>
<p><strong>Theorem</strong>: An $n \times n$ complex matrix $A$ is unitary $\iff$ its rows or columns form an orthanormal set in $\mathcal{C}^n$</p>
<p><strong>Definition</strong>: A square matrix $A$ is <strong>Hermitian</strong> when $A&#x3D;A^*$</p>
<p>Example: $A &#x3D; \begin{bmatrix}a_1 &amp; b_1+b_2i \b_1+b_2i &amp; d+1\end{bmatrix}$</p>
<p><strong>Theorem</strong>: Matrix $A$ is <strong>Hermitian</strong> $\iff$:</p>
<ol>
<li><p>$a_{ii} \in \mathbb{R}$</p>
</li>
<li><p>$a_{ij}$ is complex conjugate of $a_{ji}$</p>
</li>
</ol>
<p><strong>Theorem</strong>: If $A$ is a Hermirian matrix, then its eigenvalues are real numbers.</p>
<p><strong>Theorem</strong>: Hermitian matrices are <strong>unitarity diagonizable</strong>.</p>
<p><strong>Definitions</strong>: A squared matrix A is unitarily diagonizable when there exists a unitary matrix $P$ such that $P^{-1}AP$.</p>
<p><strong>Diagonizability can be extended to a larger class of matrices, called normal matrices.</strong></p>
<p><strong>Definition</strong>: A square complex matrix A is called normal when it commutes with its conjugate transpose. $AA^*&#x3D;A^*A$.</p>
<p><strong>Theorem</strong>: A complex matrix $A$ is <strong>normal</strong> $\iff A$ is <strong>diagonizable</strong>.</p>
<p>This theorem plays a crucial role in ComplEx paper.</p>
<hr>
<p><strong>Eigen decomposition for entity embedding</strong></p>
<p>The matrix decomposition methods have a long history in machine learning. Using embeddings based decomposition in the form of $X&#x3D;EWE^{-1}$ for square symmetric matrices can be represented as eigen decomposition $X&#x3D;Q\Lambda Q^{-1}$ where $Q$ is orthogonal $(Q^{-1} &#x3D; Q^\top)$ and $\Lambda &#x3D; diag(\lambda)$ and $\lambda_i$ is an eigenvector of $X$.</p>
<p>As ComplEx targets to learn antisymmetric relations, and eigen decomposition for asymmetric matrices does not exist in real space, the authors extend the embedding representation to complex numbers, where they can factorize complex matrices and benefit from efficient scaling and distribution of matrix multiplication while being able to capture antisymmetric relations. <strong>This asymmetry is resulted from the fact that dot product of complex matrices involves conjugate transpose.</strong></p>
<p>We are not done yet. Do you remember in RESCAL the number of parameters was $O(d^2)$ and DistMulti reduce that to a linear relation of $O(d)$ by limiting matrix $M_r$ to be diagonal?. Here even with complex eigenvectors $E \in \mathcal{C}^{n \times n}$, inversion of $E$ in $X&#x3D;EWE^{<em>}$ explodes the number of parameters. As a result we need to find a solutions in which W is a diagonal matrix, and $E &#x3D; E^</em>$, and $X$ is asymmetric, so that we</p>
<ol>
<li><p><strong>computation is minimized</strong>,</p>
</li>
<li><p><strong>there is no need to compute inverse of $E$</strong>, and</p>
</li>
<li><p><strong>antisymmetric relations can be captures. We have already seen the solution in the complex vector space section.</strong> The paper does construct the decomposition in a normal space, a vector space composed of complex normal vectors.</p>
</li>
</ol>
<hr>
<p><strong>The Score Function</strong></p>
<p>A relation between two entities can be modeled as a sign function, meaning that if there is a relation between a subject and an object, then the score is 1, otherwise it is -1. More formally, $Y_{so}\in {-1, 1}$. The probability of a relation between two edntities to exist is then given by sigmoid function: $P(Y_{so}&#x3D;1) &#x3D; \sigma(X_{so})$.</p>
<p>This probability score requires $X$ to be real, while $EWE^*$ includes both real and imaginary components. <em><em>We can simply project the decomposition to the real space so that $X &#x3D;Re(EWE^</em>)$.</em>* the score function of ComlEx, therefore is given by:</p>
<p>$$<br>f_r(h, t) &#x3D; Re(h^\top diag(r) \bar{t}) &#x3D; Re(\sum_{i&#x3D;0}^{d-1}[r]_i.[h]_i.[\bar{t}]_i)<br>$$</p>
<p>and since there are no nested loops, the number of parameters is linear and is given by $O(d)$.</p>
<h4 id="RotateE"><a href="#RotateE" class="headerlink" title="RotateE"></a>RotateE</h4><p>Let us reexamine translational distance models with the ones in latest publications on relational embedding models (RotateE). <strong>Inspired by TransE, RotateE veers into complex vector space and is motivated by Euler’s identity, defines relations as rotation from head to tail.</strong></p>
<hr>
<p><strong>Euler’s Formula</strong></p>
<p>$e^x$ can be computed using the infinite series below:</p>
<p>$$<br>e^x &#x3D; 1 + \frac{x}{1!} +\frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!}+ \frac{x^5}{5!} + \frac{x^6}{6!} + \frac{x^7}{7!} + \frac{x^8}{8!} + \dots<br>$$</p>
<p>replacing $x$ with $ix$ entails:</p>
<p>$$<br>\begin{split}e^{(ix)} &#x3D; 1 + \frac{ix}{1!} - \frac{x^2}{2!} - \frac{ix^3}{3!} + \frac{x^2}{4!} + \frac{ix^5}{5!} - \frac{x^6}{6!} - \frac{ix^7}{3!} + \frac{x^8}{8!} + \dots\\end{split}<br>$$</p>
<p>Computing $i$ to a sequence of powers and replacing the values in $e^{ix}$, the results in:</p>
<p>$$<br>\begin{split}i^2&#x3D;-1,\ i^3&#x3D;i^2i&#x3D;-i,\ i^4&#x3D;ii^3&#x3D;-1^2&#x3D;1,\ i^5&#x3D;i^4i&#x3D;i,\ i^6&#x3D;i^5i&#x3D;i^2&#x3D;-1,\ \dots\<br>e^{(ix)} &#x3D; 1 + \frac{ix}{1!} +\frac{i^2x^2}{2!} + \frac{i^3x^3}{3!} + \frac{i^4x^4}{4!} + \frac{i^5x^5}{5!} + \frac{i^6x^6}{6!} + \dots\\end{split}<br>$$</p>
<p>rearranging the series and factoring $i$ in terms that include it:</p>
<p>$$<br>\begin{split}1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \frac{x^8}{8!} +i\left(\frac{x}{1!} - \frac{x^3}{3!} + \frac{x^5}{5!} -  \frac{x^7}{7!}  \right)\text{ (1)}\\end{split}<br>$$</p>
<p>$sin$ and $cosin$ representation as series are given by:</p>
<p>$$<br>\begin{split}sin(x) &#x3D; \frac{x}{1!} - \frac{x^3}{3!} + \frac{x^5}{5!} -  \frac{x^7}{7!} + \dots\<br>cos(x) &#x3D; 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \frac{x^8}{8!} + \dots\\end{split}<br>$$</p>
<p>Finally replacing terms in equation (1) with $sin$ and $cosin$, we have:</p>
<p>$$<br>\large e^{i\theta} &#x3D; cos(\theta) + isin(\theta)\ (2)<br>$$</p>
<p><strong>Equation 2 is called Euler’s formula and has interesting consequences in a way that we can represent complex numbers as rotation on the unit circle.</strong></p>
<hr>
<p><strong>Modeling Relations as Rotation</strong></p>
<p><strong>Given a triplet $(h,r,t), t &#x3D; h \circ r$, where $h$, $r$, and $t \in \mathbb{C}^k$ are the embeddings. modulus $\mid r_i\mid&#x3D;1$ (as we are in the unit circle thanks to Euler’s formula), and $\circ$ is the element-wise product.</strong> We, therefore, for each dimension expect to have:</p>
<p>$$<br>t_i&#x3D;h_ir_i,\text{ where } h_i, r_i, t_i \in \mathbb{C}, and \mid r_i\mid&#x3D;1.<br>$$</p>
<p>Restricting $\mid r_i\mid &#x3D; 1\ r_i$ will be of form $e^{i\theta_{r,i}}$. Intuitively $r_i$ corresponds to a counterclockwise rotation by $\theta_{r,i}$ based on Eurler’s formula.</p>
<p>Under these conditions:</p>
<ul>
<li><p><strong>$r$ is symmetric $\iff \forall i \in (0,k]: r_i&#x3D;e^{\frac{0}{i\pi}}&#x3D;\pm 1$.</strong></p>
</li>
<li><p><strong>$r_1$ and $r_2$ are inverse $\iff r_2&#x3D;\bar{r}_1$ (embeddings of relations are complex conjugates)</strong></p>
</li>
<li><p><strong>$r_3&#x3D;e^{i\theta_3}$ is a combination of $r_1&#x3D;e^{i\theta_1}$ and $r_2&#x3D;e^{i\theta_2} \iff r_3&#x3D;r_1\circ r_2.\text(i.e)\theta_3&#x3D;\theta1+\theta2$ or a rotation is a combination of two smaller rotations sum of whose angles is the angle of the third relation.</strong></p>
</li>
</ul>
<p>Figure 9: RotateE vs. TransE</p>
<p><img src="https://cos.luyf-lemon-love.space/images/rotate.png"></p>
<p><strong>Score Function</strong></p>
<p>score function of RotateE measures the angular distance between head and tail elements and is defined as:</p>
<p>$$<br>d_r(h, t)&#x3D;|h\circ r-t|<br>$$</p>
<h3 id="Training-KE"><a href="#Training-KE" class="headerlink" title="Training KE"></a>Training KE</h3><h4 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h4><p>Generally to train a KE, all the models we have investigated apply a variation of negative sampling by corrupting triplets $(h,r,t)$. They corrupt either $h$, or $t$ by sampling from set of head or tail entities for heads and tails respectively. The corrupted triples can be of wither forms $(h’, r, t)$ or $(h, r, t’)$, where $h’$ and $t’$ are the negative samples.</p>
<h4 id="Loss-functions"><a href="#Loss-functions" class="headerlink" title="Loss functions"></a>Loss functions</h4><p>Most commonly <strong>logistic loss</strong> and <strong>pairwise ranking loss</strong> are employed. The logistic loss returns -1 for negative samples and +1 for the positive samples. So if $\mathbb{D}^+$ and $\mathbb{D}^-$ are negative and positive data, $y&#x3D;\pm 1$ is the label for positive and negative triplets and $f$(figure 2) is <strong>the ranking function</strong>, then the logistic loss is computed as:</p>
<p>$$<br>minimize\ \sum_{(h,r,t)\in \mathbb{D}^+\cup \mathbb{D}^-}log(1+e^{-y\times f(h,r,t)})<br>$$</p>
<p>The second commonly use loss function is <strong>margin based pairwise ranking loss</strong>, which minimizes the rank for positive triplets($(h,r,t)$ does hold). The lower the rank, the higher the probability. Ranking loss is give by:</p>
<p>$$<br>minimize \sum_{(h,r,t)\in \mathbb{D}^+}\sum_{(h,r,t)\in \mathbb{D}^-}max(0, \gamma - f(h,r,t)+f(h’,r’, t’)).<br>$$</p>
<table>
<thead>
<tr>
<th align="center">Method</th>
<th align="center">Ent. Embedding</th>
<th align="center">Rel. Emebedding</th>
<th align="center">Score Function</th>
<th align="center">Complexity</th>
<th align="center">symm</th>
<th align="center">Anti</th>
<th align="center">Inv</th>
<th align="center">Comp</th>
</tr>
</thead>
<tbody><tr>
<td align="center">TransE</td>
<td align="center">$h,t \in \mathbb{R}^d$</td>
<td align="center">$r \in \mathbb{R}^d$</td>
<td align="center">$-||h+r-t||$</td>
<td align="center">$O(d)$</td>
<td align="center">$-$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$-$</td>
</tr>
<tr>
<td align="center">TransR</td>
<td align="center">$h,t \in \mathbb{R}^d$</td>
<td align="center">$r \in \mathbb{R}^k,M_r\in\mathbb{R}^{k\times d}$</td>
<td align="center">$-||M_rh+r-M_rt||_2^2$</td>
<td align="center">$O(d^2)$</td>
<td align="center">$-$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
</tr>
<tr>
<td align="center">RESCAL</td>
<td align="center">$h,t \in \mathbb{R}^d$</td>
<td align="center">$M_r\in\mathbb{R}^{d\times d}$</td>
<td align="center">$h^\top M_rt$</td>
<td align="center">$O(d^2)$</td>
<td align="center">$\checkmark$</td>
<td align="center">$-$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
</tr>
<tr>
<td align="center">DistMulti</td>
<td align="center">$h,t \in \mathbb{R}^d$</td>
<td align="center">$r\in\mathbb{R}^d$</td>
<td align="center">$h^\top diag(r)t$</td>
<td align="center">$O(d)$</td>
<td align="center">$\checkmark$</td>
<td align="center">$-$</td>
<td align="center">$-$</td>
<td align="center">$-$</td>
</tr>
<tr>
<td align="center">ComplEx</td>
<td align="center">$h,t \in \mathbb{C}^d$</td>
<td align="center">$r\in\mathbb{C}^d$</td>
<td align="center">$h^\top Re(diag(r)t)$</td>
<td align="center">$O(d)$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$-$</td>
</tr>
<tr>
<td align="center">RotateE</td>
<td align="center">$h,t \in \mathbb{C}^d$</td>
<td align="center">$r\in\mathbb{C}^d$</td>
<td align="center">$||h\circ r-t||$</td>
<td align="center">$O(d)$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
</tr>
</tbody></table>
<h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ol>
<li><p><a href="http://semantic-web-journal.net/system/files/swj1167.pdf">http://semantic-web-journal.net/system/files/swj1167.pdf</a></p>
</li>
<li><p>Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. RotatE: Knowledge graph embedding by relational rotation in complex space. CoRR, abs&#x2F;1902.10197, 2019.</p>
</li>
<li><p>Knowledge Graph Embedding: A Survey of Approaches and Applications Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. DOI 10.1109&#x2F;TKDE.2017.2754499, IEEE Transactions on Knowledge and Data Engineering</p>
</li>
<li><p>transE: Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, JasonWeston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems 26. 2013. 5.TransR: Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015.</p>
</li>
<li><p>RESCAL: Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th International Conference on International Conference on Machine Learning, ICML’11, 2011.</p>
</li>
<li><p>Survey paper: Q. Wang, Z. Mao, B. Wang and L. Guo, “Knowledge Graph Embedding: A Survey of Approaches and Applications,” in IEEE Transactions on Knowledge and Data Engineering, vol. 29, no. 12, pp. 2724-2743, 1 Dec. 2017.</p>
</li>
<li><p>DistMult: Bishan Yang, Scott Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and relations for learning and inference in knowledge bases. In Proceedings of the International Conference on Learning Representations (ICLR) 2015, May 2015.</p>
</li>
<li><p>ComplEx: Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier, and Guillaume Bouchard. Complex embeddings for simple link prediction. CoRR, abs&#x2F;1606.06357, 2016.</p>
</li>
<li><p>Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. RotatE: Knowledge graph embedding by relational rotation in complex space. CoRR, abs&#x2F;1902.10197, 2019.</p>
</li>
</ol>
<h2 id="DGL-KE-Command-Lines"><a href="#DGL-KE-Command-Lines" class="headerlink" title="DGL-KE Command Lines"></a>DGL-KE Command Lines</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/commands.html">https://dglke.dgl.ai/doc/commands.html</a> .</p>
<p>DGL-KE provides a set of command line tools to <strong>train knowledge graph embeddings</strong> and <strong>make prediction with the embeddings</strong> easily.</p>
<h3 id="Commands-for-Training"><a href="#Commands-for-Training" class="headerlink" title="Commands for Training"></a>Commands for Training</h3><p>DGL-KE provides commands to support training on CPUs, GPUs in <strong>a single machine</strong> and <strong>a cluster of machines</strong>.</p>
<p><code>dglke_train</code> trains KG embeddings on CPUs or GPUs in <strong>a single machine</strong> and saves the trained node embeddings and relation embeddings on disks.</p>
<p><code>dglke_dist_train</code> trains knowledge graph embeddings on <strong>a cluster of machines</strong>. This command launches a set of processes to perform distributed training automatically.</p>
<p>To support distributed training, DGL-KE provides a command to partition a knowledge graph before training.</p>
<p><code>dglke_partition</code> partitions the given knowledge graph into <code>N</code> parts by the METIS partition algorithm. Different partitions will be stored on different machines in distributed training. You can find more details about the METIS partition algorithm in this <a href="http://glaros.dtc.umn.edu/gkhome/metis/metis/overview">link</a>.</p>
<p>In addition, DGL-kE provides a command to evaluate the quality of pre-trained embeddings.</p>
<p><code>dglke_eval</code> reads the pre-trained embeddings and evaluates the quality of the embeddings with a link prediction task on the test set.</p>
<h3 id="Commands-for-Inference"><a href="#Commands-for-Inference" class="headerlink" title="Commands for Inference"></a>Commands for Inference</h3><p>DGL-KE supports two types of inference tasks using pretained embeddings (We recommand using DGL-KE to generate these embedding).</p>
<ul>
<li><p><strong>Predicting entities&#x2F;relations in a triplet</strong> <code>Given entities and/or relations, predict which entities or relations are likely to connect with the existing entities for given relations.</code> For example, given a head entity and a relation, predict which entities are likely to connect to the head entity via the given relation.</p>
</li>
<li><p><strong>Finding similar embeddings</strong> Given entity&#x2F;relation embeddings, find the most similar entity&#x2F;relation embeddings for some pre-defined similarity functions.</p>
</li>
</ul>
<p>The ranking result will be automatically stored in the output file (<code>result.tsv</code> by default) using the tsv format. DGL-KE provides two commands for the inference tasks:</p>
<ul>
<li><p><code>dglke_predict</code> predicts missing entities&#x2F;relations in triplets using the pre-trained embeddings.</p>
</li>
<li><p><code>dglke_emb_sim</code> computes similarity scores on the entity embeddings or relation embeddings.</p>
</li>
</ul>
<h2 id="Format-of-Input-Data"><a href="#Format-of-Input-Data" class="headerlink" title="Format of Input Data"></a>Format of Input Data</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/format_kg.html">https://dglke.dgl.ai/doc/format_kg.html</a> .</p>
<p>DGL-KE toolkits provide commands for training, evaluation and inference. Different commands require different kinds of input data, including:</p>
<ul>
<li><p><strong>Knowledge Graph</strong> The knowledge graph used in train, evaluation and inference.</p>
</li>
<li><p><strong>Trained Embeddings</strong> The embedding generated by <strong>dglke_train</strong> or <strong>dglke_dist_train</strong>.</p>
</li>
<li><p><strong>Other Data</strong> Extra input data that used by inference tools.</p>
</li>
</ul>
<p>A knowledge graph is usually stored in the form of triplets <code>(head, relation, tail)</code>. Heads and tails are entities in the knowledge graph. All of them can be identified with unique IDs. In general, there exists <strong>two types</strong> of IDs for entities and relations in DGL-KE:</p>
<ul>
<li><p><strong>Raw ID</strong> The entities and relations can be identified by names, usually in the format of <strong>strings</strong>.</p>
</li>
<li><p><strong>KGE ID</strong> They are used during knowledge graph training, evaluation and inference. Both entities and relations are identified with <strong>integers</strong> and should start from 0 and be contiguous.</p>
</li>
</ul>
<p><strong>If the input file of a knowledge graph uses Raw IDs for entities and relations and does not provide a mapping between Raw IDs and KGE Ids, DGL-KE will generate an ID mapping automatically.</strong></p>
<p>The following table gives the overview of the input data for different toolkits. (Y for necessary and N for no-usage)</p>
<table border="1" class="docutils">
<colgroup>
<col width="23%" />
<col width="13%" />
<col width="16%" />
<col width="27%" />
<col width="21%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">DGL-KE Toolkit</th>
<th class="head" colspan="2">Knowledge Graph</th>
<th class="head">Trained Embeddings</th>
<th class="head">Other Data</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>&#160;</td>
<td>Triplets</td>
<td>ID Mapping</td>
<td>Embeddings</td>
<td>&#160;</td>
</tr>
<tr class="row-odd"><td>dglke_train</td>
<td>Y</td>
<td>Y</td>
<td>N</td>
<td>N</td>
</tr>
<tr class="row-even"><td>dglke_eval</td>
<td>Y</td>
<td>N</td>
<td>Y</td>
<td>N</td>
</tr>
<tr class="row-odd"><td>dglke_partition</td>
<td>Y</td>
<td>Y</td>
<td>N</td>
<td>N</td>
</tr>
<tr class="row-even"><td>dglke_dist_train</td>
<td colspan="4">Use data generated by dglke_partition</td>
</tr>
<tr class="row-odd"><td>dglke_predict</td>
<td>N</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
</tr>
<tr class="row-even"><td>dglke_emb_sim</td>
<td>N</td>
<td>Y</td>
<td>Y</td>
<td>Y</td>
</tr>
</tbody>
</table>

<h3 id="Format-of-Knowledge-Graph-Used-by-DGL-KE"><a href="#Format-of-Knowledge-Graph-Used-by-DGL-KE" class="headerlink" title="Format of Knowledge Graph Used by DGL-KE"></a>Format of Knowledge Graph Used by DGL-KE</h3><p>DGL-KE support three kinds of Knowledge Graph Input:</p>
<ul>
<li><p><code>Built-in Knowledge Graph</code> Built-in knowledge graphs are preprocessed datasets provided by DGL-KE package. There are five built-in datasets: <strong>FB15k</strong>, <strong>FB15k-237</strong>, <strong>wn18</strong>, <strong>wn18rr</strong>, <strong>Freebase</strong>.</p>
</li>
<li><p><code>Raw User Defined Knowledge Graph</code> Raw user defined knowledge graph dataset uses the Raw IDs. Necessary ID convertion is needed before training a KGE model on the dataset. <code>dglke_train, dglke_eval and dglke_partition provides the basic ability to do the ID convertion automatically.</code></p>
</li>
<li><p><code>KGE User Defined Knowledge Graph</code> KGE user defined knowledge graph dataset already uses KGE IDs. The entities and relations in triplets are integers.</p>
</li>
</ul>
<h4 id="Format-of-Built-in-Knowledge-Graph"><a href="#Format-of-Built-in-Knowledge-Graph" class="headerlink" title="Format of Built-in Knowledge Graph"></a>Format of Built-in Knowledge Graph</h4><p>DGL-KE provides five built-in knowledge graphs:</p>
<table border="1" class="docutils">
<colgroup>
<col width="24%" />
<col width="24%" />
<col width="27%" />
<col width="24%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Dataset</th>
<th class="head">nodes</th>
<th class="head">edges</th>
<th class="head">relations</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>FB15k</td>
<td>14,951</td>
<td>592,213</td>
<td>1,345</td>
</tr>
<tr class="row-odd"><td>FB15k-237</td>
<td>14,541</td>
<td>310,116</td>
<td>237</td>
</tr>
<tr class="row-even"><td>wn18</td>
<td>40,943</td>
<td>151,442</td>
<td>18</td>
</tr>
<tr class="row-odd"><td>wn18rr</td>
<td>40,943</td>
<td>93,003</td>
<td>11</td>
</tr>
<tr class="row-even"><td>Freebase</td>
<td>86,054,151</td>
<td>338,586,276</td>
<td>14,824</td>
</tr>
</tbody>
</table>

<p>Each of these built-in datasets contains five files:</p>
<ul>
<li><p><strong>train.txt</strong>: training set, each line contains a triplet [h, r, t]</p>
</li>
<li><p><strong>valid.txt</strong>: validation set, each line contains a triplet [h, r, t]</p>
</li>
<li><p><strong>test.txt</strong>: test set, each line contains a triplet [h, r, t]</p>
</li>
<li><p><strong>entities.dict</strong>: ID mapping of entities</p>
</li>
<li><p><strong>relations.dict</strong>: ID mapping of relations</p>
</li>
</ul>
<h4 id="Format-of-Raw-User-Defined-Knowledge-Graph"><a href="#Format-of-Raw-User-Defined-Knowledge-Graph" class="headerlink" title="Format of Raw User Defined Knowledge Graph"></a>Format of Raw User Defined Knowledge Graph</h4><p>Raw user defined knowledge graph dataset uses the Raw IDs. The knowledge graph can be stored in a single file (only providing the <strong>trainset</strong>) or in three files (<strong>trainset</strong>, <strong>validset</strong> and <strong>testset</strong>). Each file stores the triplets of the knowledge graph. The order of head, relation and tail can be <strong>arbitry</strong>, e.g. [h, r, t]. A delimiter should be used to seperate them. The recommended <strong>delimiter</strong> includes <code>\t</code>, <code>|</code>, <code>,</code> and <code>;</code>. The ID mapping is automatically generated by DGL-KE toolkits for raw user defined knowledge graphs.</p>
<p>Following gives an example of Raw User Defined Knowledge Graph files:</p>
<p>train.txt:</p>
<pre class="line-numbers language-none"><code class="language-none">&quot;Beijing&quot;,&quot;is_capital_of&quot;,&quot;China&quot;
&quot;Pairs&quot;,&quot;is_capital_of&quot;,&quot;France&quot;
&quot;London&quot;,&quot;is_capital_of&quot;,&quot;UK&quot;
&quot;UK&quot;,&quot;located_at&quot;,&quot;Europe&quot;
&quot;China&quot;,&quot;located_at&quot;,&quot;Asia&quot;
&quot;Tokyo&quot;,&quot;is_capital_of&quot;,&quot;Japan&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>valid.txt:</p>
<pre class="line-numbers language-none"><code class="language-none">&quot;France&quot;,&quot;located_at&quot;,&quot;Europe&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>test.txt:</p>
<pre class="line-numbers language-none"><code class="language-none">&quot;Japan&quot;,&quot;located_at&quot;,&quot;Asia&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="Format-of-User-Defined-Knowledge-Graph"><a href="#Format-of-User-Defined-Knowledge-Graph" class="headerlink" title="Format of User Defined Knowledge Graph"></a>Format of User Defined Knowledge Graph</h4><p>User Defined Knowledge Graph uses the KGE IDs, which means both the entities and relations have already been remapped. The entity IDs and relation IDs are both start from 0 and be contiguous. <strong>The knowledge graph can be stored in a single file (only providing the trainset) or in three files (trainset, validset and testset) along with two ID mapping files (one for entity ID mapping and another for relation ID mapping). The knowledge graph is stored as triplets in files.</strong> The order of head, relation and tail can be arbitry, e.g. [h, r, t]. A delimiter should be used to seperate them. The recommended delimiter includes <code>\t</code>, <code>|</code>, <code>,</code> and <code>;</code>. The ID mapping information is stored as pairs in mapping files <code>with pair[0] as the integer ID and pair[1] as the original raw ID</code>. The <code>dglke_train</code> and <code>dglke_dist_train</code> will do some integrity check of the IDs according to the mapping files.</p>
<p>Following gives an example of User Defined Knowledge Graph files:</p>
<p>train.txt:</p>
<pre class="line-numbers language-none"><code class="language-none">0,0,1
2,0,3
4,0,5
5,1,6
1,1,7
8,0,9<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>valid.txt:</p>
<pre class="line-numbers language-none"><code class="language-none">3,1,6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>test.txt:</p>
<pre class="line-numbers language-none"><code class="language-none">9,1,7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>Following gives an example of entity ID mapping file:</p>
<p>entities.dict:</p>
<pre class="line-numbers language-none"><code class="language-none">0,&quot;Beijing&quot;
1,&quot;China&quot;
2,&quot;Pairs&quot;
3,&quot;France&quot;
4,&quot;London&quot;
5,&quot;UK&quot;
6,&quot;Europe&quot;
7,&quot;Asia&quot;
8,&quot;Tokyo&quot;
9,&quot;Japan&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Following gives an example of relation ID mapping file:</p>
<p>relations.dict:</p>
<pre class="line-numbers language-none"><code class="language-none">0,&quot;is_capital_of&quot;
1,&quot;located_at&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h3 id="Format-of-Trained-Embeddings"><a href="#Format-of-Trained-Embeddings" class="headerlink" title="Format of Trained Embeddings"></a>Format of Trained Embeddings</h3><p>The trained embeddings are generated by <code>dglke_train</code> or <code>dglke_dist_train</code> CMD. The trained embeddings are stored in npy format. Usually there are two files:</p>
<ul>
<li><p><strong>Entity embeddings</strong> Entity embeddings are stored in a file named in format of <code>dataset_name&gt;_&lt;model&gt;_entity.npy</code> and can be loaded through <code>numpy.load()</code>.</p>
</li>
<li><p><strong>Relation embeddings</strong> Relation embeddings are stored in a file named in format of <code>dataset_name&gt;_&lt;model&gt;_relation.npy</code> and can be loaded through <code>numpy.load()</code>.</p>
</li>
</ul>
<h3 id="Format-of-Input-Data-Used-by-DGL-KE-Inference-Tools"><a href="#Format-of-Input-Data-Used-by-DGL-KE-Inference-Tools" class="headerlink" title="Format of Input Data Used by DGL-KE Inference Tools"></a>Format of Input Data Used by DGL-KE Inference Tools</h3><p>Both <code>dglke_predict</code> and <code>dglke_emb_sim</code> require user provied list of inferencing object.</p>
<h4 id="Format-of-Raw-Input-Data"><a href="#Format-of-Raw-Input-Data" class="headerlink" title="Format of Raw Input Data"></a>Format of Raw Input Data</h4><p>Raw Input Data uses the Raw IDs. Thus <code>the input file contains objects in raw IDs and necessary ID mapping file(s) are required.</code> Each line of the input file contains only one object and it can contains multiple lines. The ID mapping file store mapping information in pairs <code>with pair[0] as the integer ID and pair[1] as the original raw ID.</code></p>
<p>Following gives an example of raw input files for <code>dglke_predict</code>:</p>
<p>head.list:</p>
<pre class="line-numbers language-none"><code class="language-none">&quot;Beijing&quot;
&quot;London&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>rel.list:</p>
<pre class="line-numbers language-none"><code class="language-none">&quot;is_capital_of&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>tail.list:</p>
<pre class="line-numbers language-none"><code class="language-none">&quot;China&quot;
&quot;France&quot;
&quot;UK&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>entities.dict:</p>
<pre class="line-numbers language-none"><code class="language-none">0,&quot;Beijing&quot;
1,&quot;China&quot;
2,&quot;Pairs&quot;
3,&quot;France&quot;
4,&quot;London&quot;
5,&quot;UK&quot;
6,&quot;Europe&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>relations.dict:</p>
<pre class="line-numbers language-none"><code class="language-none">0,&quot;is_capital_of&quot;
1,&quot;located_at&quot;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h4 id="Format-of-KGE-Input-Data"><a href="#Format-of-KGE-Input-Data" class="headerlink" title="Format of KGE Input Data"></a>Format of KGE Input Data</h4><p>KGE Input Data uses the KGE IDs. Thus the input file contains objects in KGE IDs, i.e., intergers. Each line of the input file contains only one object and it can contains multiple lines.</p>
<p>Following gives an example of raw input files for <code>dglke_predict</code>:</p>
<p>head.list:</p>
<pre class="line-numbers language-none"><code class="language-none">0
4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>rel.list:</p>
<pre class="line-numbers language-none"><code class="language-none">0<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>tail.list:</p>
<pre class="line-numbers language-none"><code class="language-none">1
3
5<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h2 id="Format-of-Output"><a href="#Format-of-Output" class="headerlink" title="Format of Output"></a>Format of Output</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/format_out.html">https://dglke.dgl.ai/doc/format_out.html</a> .</p>
<p>Different DGL-KE command line toolkits has different output data. Basically they have following dependency:</p>
<ul>
<li><p><code>dglke_dist_train</code> depends on the output of <code>dglke_partition</code></p>
</li>
<li><p><code>dglke_eval</code> depends on the output (Trained Embeddings) of the training CMD <code>dglke_train</code> or <code>dglke_dist_train</code></p>
</li>
<li><p><code>dglke_predict</code> and <code>dglke_emb_sim</code> depends on the the output (Trained Embeddings) of the training CMD <code>dglke_train</code> or <code>dglke_dist_train</code> as well as the ID mapping file.</p>
</li>
</ul>
<h3 id="Output-format-of-dglke-partition"><a href="#Output-format-of-dglke-partition" class="headerlink" title="Output format of dglke_partition"></a>Output format of dglke_partition</h3><p><code>dglke_partition</code> parititions a graph into parts. It generates N partition directories according to the input argument <code>-k N</code>. For example, when we set <code>-k</code> to 4, it will generate 4 directories: <code>partition_0</code>, <code>partition_1</code>, <code>partition_2</code>, and <code>partition_3</code>.</p>
<p>The detailed format of each <code>partition_n</code> is used by <code>dglke_dist_train</code> only and is out of the current scope. Please refer to distributed train section for more details.</p>
<h3 id="Output-format-of-dglke-train-and-dglke-dist-train"><a href="#Output-format-of-dglke-train-and-dglke-dist-train" class="headerlink" title="Output format of dglke_train and dglke_dist_train"></a>Output format of dglke_train and dglke_dist_train</h3><p>The output of <code>dglke_train</code> and <code>dglke_dist_train</code> are almost the same. Here we explain the output of <code>dglke_train</code> in this paragraph.</p>
<p>Basically there are four outputs:</p>
<ul>
<li><p><code>Trained Embeddings</code>: The saved model. For most of models like <code>TransE</code>, <code>RESCAL</code>, <code>DistMult</code>, <code>ComplEx</code>, and <code>RotatE</code>, there will be two files: <code>&lt;dataset_name&gt;_&lt;model&gt;_entity.npy</code> for entity embedding and <code>&lt;dataset_name&gt;_&lt;model&gt;_relation.npy</code> for relation embedding. There are all saved numpy tensor objects. For <code>TransR</code>, there is one additional output for <code>saving the projection matrix</code>.</p>
</li>
<li><p><code>config.json</code>: The config file records all the details of the training configurations as well as the locations of ID mapping files generated by <code>dgl_train</code>. The fields of the config file are shown below:</p>
</li>
</ul>
<table border="1" class="docutils">
<colgroup>
<col width="36%" />
<col width="64%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>Field Name</td>
<td>Explanation</td>
</tr>
<tr class="row-even"><td>neg_sample_size</td>
<td>int value of param –neg_sample_size</td>
</tr>
<tr class="row-odd"><td>max_train_step</td>
<td>int value of param –max_step</td>
</tr>
<tr class="row-even"><td>double_ent</td>
<td>bool value of param –double_ent</td>
</tr>
<tr class="row-odd"><td>rmap_file</td>
<td><strong>relation ID mapping file name</strong></td>
</tr>
<tr class="row-even"><td>lr</td>
<td>float value of param –lr</td>
</tr>
<tr class="row-odd"><td>neg_adversarial_sampling</td>
<td>bool value of param –neg_adversarial_sampling</td>
</tr>
<tr class="row-even"><td>gamma</td>
<td>float value of param – gamma</td>
</tr>
<tr class="row-odd"><td>adversarial_temperature</td>
<td>float value of param – adversarial_temperature</td>
</tr>
<tr class="row-even"><td>batch_size</td>
<td>int value of param – batch_size</td>
</tr>
<tr class="row-odd"><td>regularization_coef</td>
<td>float value of param –regularization_coef</td>
</tr>
<tr class="row-even"><td>model</td>
<td>model name</td>
</tr>
<tr class="row-odd"><td>dataset</td>
<td>dataset name</td>
</tr>
<tr class="row-even"><td>emb_size</td>
<td>embedding dimention size</td>
</tr>
<tr class="row-odd"><td>regularization_norm</td>
<td>int value of param –regularization_norm</td>
</tr>
<tr class="row-even"><td>double_rel</td>
<td>bool value of param –double_rel</td>
</tr>
<tr class="row-odd"><td>emap_file</td>
<td><strong>entity ID mapping file name</strong></td>
</tr>
</tbody>
</table>

<ul>
<li><p><code>Training Log</code>: The output log printed to stdout. If <code>--test</code> is set. The final test result is also output (<code>MR</code>, <code>MRR</code>, <code>Hit@1</code>, <code>Hit@3</code>, <code>Hit@10</code>).</p>
</li>
<li><p><code>ID mapping Files (Optional)</code>: The the input data is in format of <code>Raw User Defined Knowledge Graph</code>, that is all triplets use the Raw ID space. The training script will do the ID convertion and generate two ID mapping files:</p>
<ul>
<li><code>entities.tsv</code>, for entity ID mapping in format of <code>KGE_entity_ID\tRaw_entity_Name</code>, for example:</li>
</ul>
 <pre class="line-numbers language-none"><code class="language-none">0\tBeijing
1\tChina<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<ul>
<li><code>relations.tsv</code>, for relation ID mapping in format of <code>KGE_relation_ID\tRaw_relation_name</code>, for example:</li>
</ul>
 <pre class="line-numbers language-none"><code class="language-none">0\tis_capital_of
1\tlocated_at<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
</ul>
<h3 id="Output-format-of-dglke-eval"><a href="#Output-format-of-dglke-eval" class="headerlink" title="Output format of dglke_eval"></a>Output format of dglke_eval</h3><p>There will be only one output of <code>dglke_eval</code>, the testing result including <code>MR</code>, <code>MRR</code>, <code>Hit@1</code>, <code>Hit@3</code>, <code>Hit@10</code>.</p>
<h3 id="Output-format-of-dglke-predict"><a href="#Output-format-of-dglke-predict" class="headerlink" title="Output format of dglke_predict"></a>Output format of dglke_predict</h3><p>The output of <code>dglke_predict</code> is a list of top ranked candidate (h, r, t) triplets as well as their prediction scores. The output is by default written into <code>result.tsv</code> and in the format of <code>src\trel\tdst\tscore</code>.</p>
<p>The example output is as:</p>
<pre class="line-numbers language-none"><code class="language-none">src  rel  dst  score
6    0    15   -2.39380
8    0    14   -2.65297
2    0    14   -2.67331
9    0    18   -2.86985
8    0    20   -2.89651<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>If the input data of <code>dglke_predict</code> is in Raw IDs, <code>dglke_predict</code> will also convert the output result in Raw IDs.</p>
<h3 id="Output-format-of-dglke-emb-sim"><a href="#Output-format-of-dglke-emb-sim" class="headerlink" title="Output format of dglke_emb_sim"></a>Output format of dglke_emb_sim</h3><p>The output of <code>dglke_emb_sim</code> is a list of top ranked candidate (left, right) pairs as well as their embedding similarity scores. The output is by default written into <code>result.tsv</code> and in the format of <code>left\tright\tscore</code>.</p>
<p>The example output is as:</p>
<pre class="line-numbers language-none"><code class="language-none">left    right   score
6       15      0.55512
1       12      0.33153
7       20      0.27706
7       19      0.25631
7       13      0.21372<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>If the input data of <code>dglke_emb_sim</code> is in Raw IDs, <code>dglke_emb_sim</code> will also convert the output result in Raw IDs.</p>
<p>The example output is as:</p>
<pre class="line-numbers language-none"><code class="language-none">left                          right                           score
_hyponym                      _hyponym                        0.99999
_derivationally_related_form  _derivationally_related_form    0.99999
_hyponym                      _also_see                       0.58408
_hyponym                      _member_of_domain_topic         0.44027
_hyponym                      _member_of_domain_region        0.30975<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Training-in-a-single-machine"><a href="#Training-in-a-single-machine" class="headerlink" title="Training in a single machine"></a>Training in a single machine</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/train.html">https://dglke.dgl.ai/doc/train.html</a> .</p>
<p><code>dglke_train</code> trains KG embeddings on CPUs or GPUs in a single machine and saves the trained node embeddings and relation embeddings on disks.</p>
<h3 id="Arguments"><a href="#Arguments" class="headerlink" title="Arguments"></a>Arguments</h3><p>The command line provides the following arguments:</p>
<ul>
<li><p><code>--model_name &#123;TransE, TransE_l1, TransE_l2, TransR, RESCAL, DistMult, ComplEx, RotatE&#125;</code> The models provided by DGL-KE.</p>
</li>
<li><p><code>--data_path DATA_PATH</code> The path of the directory where DGL-KE loads knowledge graph data.</p>
</li>
<li><p><code>--dataset DATA_SET</code> The name of the knowledge graph stored under data_path. If it is one of the builtin knowledge grpahs such as <code>FB15k</code>, <code>FB15k-237</code>, <code>wn18</code>, <code>wn18rr</code>, and <code>Freebase</code>, DGL-KE will automatically download the knowledge graph and keep it under data_path.</p>
</li>
<li><p><code>--format FORMAT</code> The format of the dataset. For builtin knowledge graphs, the format is determined automatically. For users own knowledge graphs, it needs to be <code>raw_udd_&#123;htr&#125;</code> or <code>udd_&#123;htr&#125;</code>. <code>raw_udd_</code> indicates that the user’s data use <code>raw ID</code> for entities and relations and <code>udd_</code> indicates that the user’s data uses <code>KGE ID</code>. <code>&#123;htr&#125;</code> indicates the location of the head entity, tail entity and relation in a triplet. For example, <code>htr</code> means the head entity is the first element in the triplet, the tail entity is the second element and the relation is the last element.</p>
</li>
<li><p><code>--data_files [DATA_FILES ...]</code> A list of data file names. This is required for training KGE on their own datasets. If the format is <code>raw_udd_&#123;htr&#125;</code>, users need to provide <code>train_file</code> <code>[valid_file]</code> <code>[test_file]</code>. If the format is <code>udd_&#123;htr&#125;</code>, users need to provide <code>entity_file</code> <code>relation_file</code> <code>train_file</code> <code>[valid_file]</code> <code>[test_file]</code>. In both cases, <code>valid_file</code> and <code>test_file</code> are optional.</p>
</li>
<li><p><code>--delimiter DELIMITER</code> Delimiter used in data files. Note all files should use <code>the same delimiter</code>.</p>
</li>
<li><p><code>--save_path SAVE_PATH</code> The path of the directory where models and logs are saved.</p>
</li>
<li><p><code>--no_save_emb</code> Disable saving the embeddings under save_path.</p>
</li>
<li><p><code>--max_step MAX_STEP</code> The maximal number of steps to train the model in a single process. A step trains the model with a batch of data. In the case of <code>multiprocessing training</code>, the total number of training steps is <code>MAX_STEP * NUM_PROC</code>.</p>
</li>
<li><p><code>--batch_size BATCH_SIZE</code> The batch size for training.</p>
</li>
<li><p><code>--batch_size_eval BATCH_SIZE_EVAL</code> The batch size used for validation and test.</p>
</li>
<li><p><code>--neg_sample_size NEG_SAMPLE_SIZE</code> The number of negative samples we use for each positive sample in the training.</p>
</li>
<li><p><code>--neg_deg_sample</code> Construct negative samples proportional to vertex degree in the training. When this option is turned on, the number of negative samples per positive edge will be doubled. Half of the negative samples are generated uniformly while the other half are generated proportional to vertex degree.</p>
</li>
<li><p><code>--neg_deg_sample_eval</code> Construct negative samples proportional to vertex degree in the evaluation.</p>
</li>
<li><p><code>--neg_sample_size_eval NEG_SAMPLE_SIZE_EVAL</code> The number of negative samples we use to evaluate a positive sample.</p>
</li>
<li><p><code>--eval_percent EVAL_PERCENT</code> Randomly sample some percentage of edges for evaluation.</p>
</li>
<li><p><code>--no_eval_filter</code> Disable filter positive edges from randomly constructed negative edges for evaluation.</p>
</li>
<li><p><code>--log_interval LOG_INTERVAL</code> Print runtime of different components every <code>LOG_INTERVAL</code> steps.</p>
</li>
<li><p><code>--eval_interval EVAL_INTERVAL</code> Print evaluation results on the validation dataset every <code>EVAL_INTERVAL</code> steps if validation is turned on.</p>
</li>
<li><p><code>--test</code> Evaluate the model on the test set after the model is trained.</p>
</li>
<li><p><code>--num_proc NUM_PROC</code> The number of processes to train the model in parallel. In multi-GPU training, the number of processes by default is the number of GPUs. If it is specified explicitly, the number of processes needs to be divisible by the number of GPUs.</p>
</li>
<li><p><code>--num_thread NUM_THREAD</code> The number of CPU threads to train the model in each process. This argument is used for multi-processing training.</p>
</li>
<li><p><code>--force_sync_interval FORCE_SYNC_INTERVAL</code> We force a synchronization between processes every <code>FORCE_SYNC_INTERVAL</code> steps for multiprocessing training. This potentially stablizes the training process to get a better performance. For multiprocessing training, it is set to 1000 by default.</p>
</li>
<li><p><code>--hidden_dim HIDDEN_DIM</code> The embedding size of relations and entities.</p>
</li>
<li><p><code>--lr LR</code> The learning rate. DGL-KE uses <code>Adagrad</code> to optimize the model parameters.</p>
</li>
<li><p><code>-g GAMMA</code> or <code>--gamma GAMMA</code> The margin value in the score function. It is used by TransX and RotatE.</p>
</li>
<li><p><code>-de</code> or <code>--double_ent</code> Double entitiy dim for complex number It is used by RotatE.</p>
</li>
<li><p><code>-dr</code> or <code>--double_rel</code> Double relation dim for complex number.</p>
</li>
<li><p><code>-adv</code> or <code>--neg_adversarial_sampling</code> Indicate whether to use negative adversarial sampling. It will weight negative samples with higher scores more.</p>
</li>
<li><p><code>-a ADVERSARIAL_TEMPERATURE</code> or <code>--adversarial_temperature ADVERSARIAL_TEMPERATURE</code> The temperature used for negative adversarial sampling.</p>
</li>
<li><p><code>-rc REGULARIZATION_COEF</code> or <code>--regularization_coef REGULARIZATION_COEF</code> The coefficient for regularization.</p>
</li>
<li><p><code>-rn REGULARIZATION_NORM</code> or <code>--regularization_norm REGULARIZATION_NORM</code> norm used in regularization.</p>
</li>
<li><p><code>--gpu [GPU ...]</code> A list of gpu ids, e.g. 0 1 2 4</p>
</li>
<li><p><code>--mix_cpu_gpu</code> Training a knowledge graph embedding model with both CPUs and GPUs.The embeddings are stored in CPU memory and the training is performed in GPUs.This is usually used for training large knowledge graph embeddings.</p>
</li>
<li><p><code>--valid</code> Evaluate the model on the validation set in the training.</p>
</li>
<li><p><code>--rel_part</code> Enable relation partitioning for multi-GPU training.</p>
</li>
<li><p><code>--async_update</code> Allow asynchronous update on node embedding for multi-GPU training. This overlaps CPU and GPU computation to speed up.</p>
</li>
</ul>
<h3 id="Training-on-Multi-Core"><a href="#Training-on-Multi-Core" class="headerlink" title="Training on Multi-Core"></a>Training on Multi-Core</h3><p>Multi-core processors are very common and widely used in modern computer architecture. DGL-KE is optimized on multi-core processors. <code>In DGL-KE, we uses multi-processes instead of multi-threads for parallel training.</code> In this design, <strong>the enity embeddings and relation embeddings will be stored in a global shared-memory and all the trainer processes can read and write it</strong>. All the processes will train the global model in a <strong>Hogwild style</strong>.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/multi-core.png"></p>
<p>The following command trains the <code>transE</code> model on <code>FB15k</code> dataset on <code>a multi-core machine</code>. Note that, the total number of steps to train the model in this case is <code>24000</code>:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--max_step</span> <span class="token number">3000</span> <span class="token parameter variable">--log_interval</span> <span class="token number">100</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">--test</span> <span class="token parameter variable">-adv</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--regularization_coef</span> <span class="token number">1</span>.00E-09 <span class="token parameter variable">--num_thread</span> <span class="token number">1</span> <span class="token parameter variable">--num_proc</span> <span class="token number">8</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>After training, you will see the following messages:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">-------------- Test result --------------
Test average MRR <span class="token builtin class-name">:</span> <span class="token number">0.6520483281422476</span>
Test average MR <span class="token builtin class-name">:</span> <span class="token number">43.725415178344704</span>
Test average HITS@1 <span class="token builtin class-name">:</span> <span class="token number">0.5257063533713666</span>
Test average HITS@3 <span class="token builtin class-name">:</span> <span class="token number">0.7524081190431853</span>
Test average HITS@10 <span class="token builtin class-name">:</span> <span class="token number">0.8479202993008413</span>
-----------------------------------------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Training-on-single-GPU"><a href="#Training-on-single-GPU" class="headerlink" title="Training on single GPU"></a>Training on single GPU</h3><p>Training knowledge graph embeddings requires a large number of tensor computation, which can be accelerated by GPU. DGL-KE can run on <code>a single GPU</code>, as well as <code>a multi-GPU machine</code>. Also, it can run in <code>a mix-gpu-cpu setting</code>, where the embedding data cannot fit in GPU memory.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/multi-gpu.png"></p>
<p>The following command trains the <code>transE</code> model on <code>FB15k</code> on a single GPU:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token parameter variable">--log_interval</span> <span class="token number">100</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--regularization_coef</span><span class="token operator">=</span>1e-9 <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">--test</span> <span class="token parameter variable">-adv</span> <span class="token parameter variable">--gpu</span> <span class="token number">0</span> <span class="token parameter variable">--max_step</span> <span class="token number">24000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>Most of the options here we have already seen in the previous section. The only difference is that we add <code>--gpu 0</code> to indicate that we will use 1 GPU to train our model. Compared to the cpu training, every 100 steps only takes <code>0.72</code> seconds on the Nvidia v100 GPU, which is much faster than <code>8.9</code> second in CPU training:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.165</span>, forward: <span class="token number">0.282</span>, backward: <span class="token number">0.217</span>, update: <span class="token number">0.087</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">1900</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.32798981070518496</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">1900</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.45353577584028243</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">1900</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.3907627931237221</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">1900</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0012039361777715384</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.726</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.137</span>, forward: <span class="token number">0.282</span>, backward: <span class="token number">0.218</span>, update: <span class="token number">0.087</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2000</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.31407852172851564</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2000</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.44177248477935793</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2000</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.3779255014657974</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2000</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0012163800827693194</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.760</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.171</span>, forward: <span class="token number">0.282</span>, backward: <span class="token number">0.218</span>, update: <span class="token number">0.087</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2100</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.309254549741745</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2100</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.43288875490427015</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2100</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.37107165187597274</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2100</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0012251652684062719</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.726</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.136</span>, forward: <span class="token number">0.283</span>, backward: <span class="token number">0.219</span>, update: <span class="token number">0.087</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2200</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.3109792047739029</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2200</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.4351910164952278</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2200</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.3730851110816002</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">2200</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0012286945607047528</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.732</span> seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Mix-CPU-GPU-training"><a href="#Mix-CPU-GPU-training" class="headerlink" title="Mix CPU-GPU training"></a>Mix CPU-GPU training</h3><p>By default, DGL-KE keeps all node and relation embeddings in GPU memory for single-GPU training. It cannot train embeddings of large knowledge graphs because the capacity of GPU memory typically is much smaller than the CPU memory. <code>So if your KG embedding is too large to fit in the GPU memory, you can use the mix_cpu_gpu training</code>:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token parameter variable">--log_interval</span> <span class="token number">100</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--regularization_coef</span><span class="token operator">=</span>1e-9 <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">--test</span> <span class="token parameter variable">-adv</span> <span class="token parameter variable">--gpu</span> <span class="token number">0</span> <span class="token parameter variable">--max_step</span> <span class="token number">24000</span> <span class="token parameter variable">--mix_cpu_gpu</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><code>The mix_cpu_gpu training keeps node and relation embeddings in CPU memory and performs batch computation in GPU.</code> In this way, you can train very large KG embeddings as long as your cpu memory can handle it even though the training speed of mix_cpu_gpu training is slower than pure GPU training:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8200</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.2720812517404556</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8200</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.4004567116498947</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8200</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.3362689846754074</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8200</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0014934110222384334</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.958</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.133</span>, forward: <span class="token number">0.339</span>, backward: <span class="token number">0.185</span>, update: <span class="token number">0.301</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8300</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.27434037417173385</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8300</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.40289842933416364</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8300</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.33861940175294875</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8300</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.001497904829448089</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.970</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.145</span>, forward: <span class="token number">0.339</span>, backward: <span class="token number">0.185</span>, update: <span class="token number">0.300</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8400</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.27482498317956927</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8400</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.40262984931468965</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8400</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.3387274172902107</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">8400</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0015005254035349936</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.958</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.132</span>, forward: <span class="token number">0.338</span>, backward: <span class="token number">0.185</span>, update: <span class="token number">0.301</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>As we can see, the <code>mix_cpu_gpu</code> training takes <code>0.95</code> seconds on every 100 steps. It is slower than pure GPU training (<code>0.73</code>) but still much faster than CPU (<code>8.9</code>).</p>
<p>Users can speed up the <code>mix_cpu_gpu</code> training by using <code>--async_update</code> option. When using this option, <code>the GPU device will not wait for the CPU to finish its job when it performs update operation</code>:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token parameter variable">--log_interval</span> <span class="token number">100</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--regularization_coef</span><span class="token operator">=</span>1e-9 <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">--test</span> <span class="token parameter variable">-adv</span> <span class="token parameter variable">--gpu</span> <span class="token number">0</span> <span class="token parameter variable">--max_step</span> <span class="token number">24000</span> <span class="token parameter variable">--mix_cpu_gpu</span> <span class="token parameter variable">--async_update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>We can see that the training time goes down from 0.95 to 0.84 seconds on every 100 steps:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22500</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.2683987358212471</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22500</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.3919999450445175</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22500</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.33019934087991715</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22500</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0017611468932591378</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.842</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.161</span>, forward: <span class="token number">0.381</span>, backward: <span class="token number">0.200</span>, update: <span class="token number">0.099</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22600</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.2682730385661125</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22600</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.39290413081645964</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22600</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.3305885857343674</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22600</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0017612565110903234</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.838</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.159</span>, forward: <span class="token number">0.379</span>, backward: <span class="token number">0.200</span>, update: <span class="token number">0.098</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22700</span>/24000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.2688949206471443</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22700</span>/24000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.3927029174566269</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22700</span>/24000<span class="token punctuation">)</span> average loss: <span class="token number">0.33079892098903657</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">22700</span>/24000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0017607113404665142</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">0.859</span> seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Training-on-Multi-GPU"><a href="#Training-on-Multi-GPU" class="headerlink" title="Training on Multi-GPU"></a>Training on Multi-GPU</h3><p><code>DGL-KE also supports multi-GPU training to accelerate training.</code> The following figure depicts 4 GPUs on a single machine and connected to the CPU through a PCIe switch. Multi-GPU training automatically keeps node and relation embeddings on CPUs and dispatch batches to different GPUs.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/multi-gpu.svg"></p>
<p>The following command shows how to training our <code>transE</code> model using 4 Nvidia v100 GPUs jointly:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token parameter variable">--log_interval</span> <span class="token number">1000</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--regularization_coef</span><span class="token operator">=</span>1e-9 <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">--test</span> <span class="token parameter variable">-adv</span> <span class="token parameter variable">--gpu</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token parameter variable">--max_step</span> <span class="token number">6000</span> <span class="token parameter variable">--async_update</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>Compared to single-GPU training, we change <code>--gpu 0</code> to <code>--gpu 0 1 2 3</code>, and also we change <code>--max_step</code> from <code>24000</code> to <code>6000</code>:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5800</span>/6000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.2675808426737785</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5800</span>/6000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.3915132364630699</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5800</span>/6000<span class="token punctuation">)</span> average loss: <span class="token number">0.3295470401644707</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5800</span>/6000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0017635633377358318</span>
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">1.123</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">0</span><span class="token punctuation">]</span>sample: <span class="token number">0.237</span>, forward: <span class="token number">0.472</span>, backward: <span class="token number">0.215</span>, update: <span class="token number">0.198</span>
<span class="token punctuation">[</span>proc <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5800</span>/6000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.26807423621416093</span>
<span class="token punctuation">[</span>proc <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5800</span>/6000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.3898271417617798</span>
<span class="token punctuation">[</span>proc <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5800</span>/6000<span class="token punctuation">)</span> average loss: <span class="token number">0.32895069003105165</span>
<span class="token punctuation">[</span>proc <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5800</span>/6000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0017631534475367515</span>
<span class="token punctuation">[</span>proc <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">1.157</span> seconds
<span class="token punctuation">[</span>proc <span class="token number">3</span><span class="token punctuation">]</span>sample: <span class="token number">0.248</span>, forward: <span class="token number">0.489</span>, backward: <span class="token number">0.217</span>, update: <span class="token number">0.202</span>
<span class="token punctuation">[</span>proc <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5900</span>/6000<span class="token punctuation">)</span> average pos_loss: <span class="token number">0.267591707110405</span>
<span class="token punctuation">[</span>proc <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5900</span>/6000<span class="token punctuation">)</span> average neg_loss: <span class="token number">0.3929813900589943</span>
<span class="token punctuation">[</span>proc <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5900</span>/6000<span class="token punctuation">)</span> average loss: <span class="token number">0.3302865487337112</span>
<span class="token punctuation">[</span>proc <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">5900</span>/6000<span class="token punctuation">)</span> average regularization: <span class="token number">0.0017678673949558287</span>
<span class="token punctuation">[</span>proc <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>Train<span class="token punctuation">]</span> <span class="token number">100</span> steps take <span class="token number">1.140</span> seconds<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>As we can see, using 4 GPUs we have almost 3x end-to-end performance speedup.</p>
<p>Note that <code>--async_update</code> can increase system performance but it could also slow down the model convergence. So DGL-KE provides another option called <code>--force_sync_interval</code> that forces all GPU sync their model on every <code>N</code> steps. For example, the following command will sync model across GPUs on every 1000 steps:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token parameter variable">--log_interval</span> <span class="token number">1000</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--regularization_coef</span><span class="token operator">=</span>1e-9 <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">--test</span> <span class="token parameter variable">-adv</span> <span class="token parameter variable">--gpu</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token parameter variable">--async_update</span> <span class="token parameter variable">--max_step</span> <span class="token number">6000</span> <span class="token parameter variable">--force_sync_interval</span> <span class="token number">1000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h3 id="Save-embeddings"><a href="#Save-embeddings" class="headerlink" title="Save embeddings"></a>Save embeddings</h3><p>By default, <code>dglke_train</code> saves the embeddings in the <code>ckpts</code> folder. Each run creates a new folder in <code>ckpts</code> to store the training results. The new folder is named after <code>xxxx_yyyy_zz</code>, where <code>xxxx</code> is the model name, <code>yyyy</code> is the dataset name, <code>zz</code> is a sequence number that ensures a unique name for each run.</p>
<p>The saved embeddings are stored as numpy ndarrays. The node embedding is saved as <code>XXX_YYY_entity.npy</code>. The relation embedding is saved as <code>XXX_YYY_relation.npy</code>. <code>XXX</code> is the dataset name and <code>YYY</code> is the model name.</p>
<p>A user can disable saving embeddings with <code>--no_save_emb</code>. This might be useful for some cases, such as <code>hyperparameter tuning</code>.</p>
<h2 id="Partition-a-Knowledge-Graph"><a href="#Partition-a-Knowledge-Graph" class="headerlink" title="Partition a Knowledge Graph"></a>Partition a Knowledge Graph</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/partition.html">https://dglke.dgl.ai/doc/partition.html</a> .</p>
<p>For distributed training, a user needs to partition a graph beforehand. DGL-KE provides a partition tool <code>dglke_partition</code>, which partitions a given knowledge graph into <code>N</code> parts with <a href="http://glaros.dtc.umn.edu/gkhome/metis/metis/overview">the METIS partition algorithm</a>. This partition algorithm reduces the number of edge cuts between partitions to reduce network communication in the distributed training. For a cluster of <code>P</code> machines, we usually split a graph into <code>P</code> partitions and assign a partition to a machine as shown in the figure below.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/metis.png"></p>
<h3 id="Arguments-1"><a href="#Arguments-1" class="headerlink" title="Arguments"></a>Arguments</h3><p>The command line provides the following arguments:</p>
<ul>
<li><p><code>--data_path DATA_PATH</code> The name of the knowledge graph stored under data_path. If it is one ofthe builtin knowledge grpahs such as FB15k, DGL-KE will automatically download the knowledge graph and keep it under data_path.</p>
</li>
<li><p><code>--dataset DATA_SET</code> The name of the knowledge graph stored under data_path. If it is one of the builtin knowledge grpahs such as <code>FB15k</code>, <code>FB15k-237</code>, <code>wn18</code>, <code>wn18rr</code>, and <code>Freebase</code>, DGL-KE will automatically download the knowledge graph and keep it under data_path.</p>
</li>
<li><p><code>--format FORMAT</code> The format of the dataset. For builtin knowledge graphs, the format is determined automatically. For users own knowledge graphs, it needs to be <code>raw_udd_&#123;htr&#125;</code> or <code>udd_&#123;htr&#125;</code>. <code>raw_udd_</code> indicates that the user’s data use <code>raw ID</code> for entities and relations and <code>udd_</code> indicates that the user’s data uses <code>KGE ID</code>. <code>&#123;htr&#125;</code> indicates the location of the head entity, tail entity and relation in a triplet. For example, <code>htr</code> means the head entity is the first element in the triplet, the tail entity is the second element and the relation is the last element.</p>
</li>
<li><p><code>--data_files [DATA_FILES ...]</code> A list of data file names. This is required for training KGE on their own datasets. If the format is <code>raw_udd_&#123;htr&#125;</code>, users need to provide <code>train_file</code> <code>[valid_file]</code> <code>[test_file]</code>. If the format is <code>udd_&#123;htr&#125;</code>, users need to provide <code>entity_file</code> <code>relation_file</code> <code>train_file</code> <code>[valid_file]</code> <code>[test_file]</code>. In both cases, <code>valid_file</code> and <code>test_file</code> are optional.</p>
</li>
<li><p><code>--delimiter DELIMITER</code> Delimiter used in data files. Note all files should use the same delimiter.</p>
</li>
<li><p><code>-k NUM_PARTS</code> or <code>--num-parts NUM_PARTS</code> The number of partitions.</p>
</li>
</ul>
<h2 id="Distributed-Training-on-Large-Data"><a href="#Distributed-Training-on-Large-Data" class="headerlink" title="Distributed Training on Large Data"></a>Distributed Training on Large Data</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/dist_train.html">https://dglke.dgl.ai/doc/dist_train.html</a> .</p>
<p><code>dglke_dist_train</code> trains knowledge graph embeddings on a cluster of machines. DGL-KE adopts the <code>parameter-server</code> architecture for distributed training.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/dist_train.png"></p>
<p>In this architecture, the entity embeddings and relation embeddings are stored in DGL KVStore. <code>The trainer processes pull the latest model from KVStore and push the calculated gradient to the KVStore to update the model.</code> All the processes trains the KG embeddings with asynchronous <code>SGD</code>.</p>
<h3 id="Arguments-2"><a href="#Arguments-2" class="headerlink" title="Arguments"></a>Arguments</h3><p>The command line provides the following arguments:</p>
<ul>
<li><p><code>--model_name &#123;TransE, TransE_l1, TransE_l2, TransR, RESCAL, DistMult, ComplEx, RotatE&#125;</code> The models provided by DGL-KE.</p>
</li>
<li><p><code>--data_path DATA_PATH</code> The path of the directory where DGL-KE loads knowledge graph data.</p>
</li>
<li><p><code>--dataset DATA_SET</code> The name of the knowledge graph stored under data_path. The knowledge graph should be generated by Partition script.</p>
</li>
<li><p><code>--format FORMAT</code> The format of the dataset. For builtin knowledge graphs,the foramt should be built_in. For users own knowledge graphs,it needs to be <code>raw_udd_&#123;htr&#125;</code> or <code>udd_&#123;htr&#125;</code>.</p>
</li>
<li><p><code>--save_path SAVE_PATH</code> The path of the directory where models and logs are saved.</p>
</li>
<li><p><code>--no_save_emb</code> Disable saving the embeddings under save_path.</p>
</li>
<li><p><code>--max_step MAX_STEP</code> The maximal number of steps to train the model in a single process. A step trains the model with a batch of data. In the case of multiprocessing training, the total number of training steps is <code>MAX_STEP</code> * <code>NUM_PROC</code>.</p>
</li>
<li><p><code>--batch_size BATCH_SIZE</code> The batch size for training.</p>
</li>
<li><p><code>--batch_size_eval BATCH_SIZE_EVAL</code> The batch size used for validation and test.</p>
</li>
<li><p><code>--neg_sample_size NEG_SAMPLE_SIZE</code> The number of negative samples we use for each positive sample in the training.</p>
</li>
<li><p><code>--neg_deg_sample</code> Construct negative samples proportional to vertex degree in the training. When this option is turned on, the number of negative samples per positive edge will be doubled. Half of the negative samples are generated uniformly whilethe other half are generated proportional to vertex degree.</p>
</li>
<li><p><code>--neg_deg_sample_eval</code> Construct negative samples proportional to vertex degree in the evaluation.</p>
</li>
<li><p><code>--neg_sample_size_eval NEG_SAMPLE_SIZE_EVAL</code> The number of negative samples we use to evaluate a positive sample.</p>
</li>
<li><p><code>--eval_percent EVAL_PERCENT</code> Randomly sample some percentage of edges for evaluation.</p>
</li>
<li><p><code>--no_eval_filter</code> Disable filter positive edges from randomly constructed negative edges for evaluation.</p>
</li>
<li><p><code>-log LOG_INTERVAL</code> Print runtime of different components every x steps.</p>
</li>
<li><p><code>--test</code> Evaluate the model on the test set after the model is trained.</p>
</li>
<li><p><code>--num_proc NUM_PROC</code> The number of processes to train the model in parallel.</p>
</li>
<li><p><code>--num_thread NUM_THREAD</code> The number of CPU threads to train the model in each process. This argument is used for multi-processing training.</p>
</li>
<li><p><code>--force_sync_interval FORCE_SYNC_INTERVAL</code> We force a synchronization between processes every x steps formultiprocessing training. This potentially stablizes the training processto get a better performance. For multiprocessing training, it is set to 1000 by default.</p>
</li>
<li><p><code>--hidden_dim HIDDEN_DIM</code> The embedding size of relation and entity.</p>
</li>
<li><p><code>--lr LR</code> The learning rate. DGL-KE uses Adagrad to optimize the model parameters.</p>
</li>
<li><p><code>-g GAMMA</code> or <code>--gamma GAMMA</code> The margin value in the score function. It is used by TransX and RotatE.</p>
</li>
<li><p><code>-de</code> or <code>--double_ent</code> Double entitiy dim for complex number It is used by RotatE.</p>
</li>
<li><p><code>-dr</code> or <code>--double_rel</code> Double relation dim for complex number.</p>
</li>
<li><p><code>-adv</code> or <code>--neg_adversarial_sampling</code> Indicate whether to use negative adversarial sampling.It will weight negative samples with higher scores more.</p>
</li>
<li><p><code>-a ADVERSARIAL_TEMPERATURE</code> or <code>--adversarial_temperature ADVERSARIAL_TEMPERATURE</code> The temperature used for negative adversarial sampling.</p>
</li>
<li><p><code>-rc REGULARIZATION_COEF</code> or <code>--regularization_coef REGULARIZATION_COEF</code> The coefficient for regularization.</p>
</li>
<li><p><code>-rn REGULARIZATION_NORM</code> or <code>--regularization_norm REGULARIZATION_NORM</code> norm used in regularization.</p>
</li>
<li><p><code>--path PATH</code> Path of distributed workspace.</p>
</li>
<li><p><code>--ssh_key SSH_KEY</code> ssh private key.</p>
</li>
<li><p><code>--ip_config IP_CONFIG</code> Path of IP configuration file.</p>
</li>
<li><p><code>--num_client_proc NUM_CLIENT_PROC</code> Number of worker processes on each machine.</p>
</li>
</ul>
<h3 id="The-Steps-for-Distributed-Training"><a href="#The-Steps-for-Distributed-Training" class="headerlink" title="The Steps for Distributed Training"></a>The Steps for Distributed Training</h3><p>Distributed training on DGL-KE usually involves three steps:</p>
<ol>
<li><p>Partition a knowledge graph.</p>
</li>
<li><p>Copy partitioned data to remote machines.</p>
</li>
<li><p>Invoke the distributed training job by <code>dglke_dist_train</code>.</p>
</li>
</ol>
<p>Here we demonstrate how to training KG embedding on <code>FB15k</code> dataset using 4 machines. Note that, the <code>FB15k</code> is just a small dataset as our toy demo. An interested user can try it on <code>Freebase</code>, which contains 86M nodes and 338M edges.</p>
<p><strong>Step 1: Prepare your machines</strong></p>
<p>Assume that we have four machines with the following IP addresses:</p>
<pre class="line-numbers language-none"><code class="language-none">machine_0: 172.31.24.245
machine_1: 172.31.24.246
machine_2: 172.31.24.247
machine_3: 172.32.24.248<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>Make sure that <code>machine_0</code> has the permission to <code>ssh</code> to all the other machines.</p>
<p><strong>Step 2: Prepare your data</strong></p>
<p>Create a new directory called <code>my_task</code> on machine_0:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">mkdir</span> my_task<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>We use built-in <code>FB15k</code> as demo and paritition it into <code>4</code> parts:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_partition <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">-k</span> <span class="token number">4</span> <span class="token parameter variable">--data_path</span> ~/my_task<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>Note that, in this demo, we have 4 machines so we set <code>-k</code> to 4. After this step, we can see 4 new directories called <code>partition_0</code>, <code>partition_1</code>, <code>partition_2</code>, and <code>partition_3</code> in your <code>FB15k</code> dataset folder.</p>
<p>Create a new file called <code>ip_config.txt</code> in <code>my_task</code>, and write the following contents into it:</p>
<pre class="line-numbers language-none"><code class="language-none">172.31.24.245 30050 8
172.31.24.246 30050 8
172.31.24.247 30050 8
172.32.24.248 30050 8<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>Each line in <code>ip_config.txt</code> is the KVStore configuration on each machine. For example, <code>172.31.24.245 30050 8</code> represents that, on <code>machine_0</code>, the IP is <code>172.31.24.245</code>, the base port is <code>30050</code>, and we start <code>8</code> servers on this machine. Note that, you can change the number of servers on each machine based on your machine capabilities. In our environment, the instance has <code>48</code> cores, and we set <code>8</code> cores to KVStore and <code>40</code> cores for worker processes.</p>
<p>After that, we can copy the <code>my_task</code> directory to all the remote machines:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">scp</span> <span class="token parameter variable">-r</span> ~/my_task <span class="token number">172.31</span>.24.246:~
<span class="token function">scp</span> <span class="token parameter variable">-r</span> ~/my_task <span class="token number">172.31</span>.24.247:~
<span class="token function">scp</span> <span class="token parameter variable">-r</span> ~/my_task <span class="token number">172.31</span>.24.248:~<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><strong>Step 3: Launch distributed jobs</strong></p>
<p>Run the following command on <code>machine_0</code> to start a distributed task:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_dist_train <span class="token parameter variable">--path</span> ~/my_task <span class="token parameter variable">--ip_config</span> ~/my_task/ip_config.txt <span class="token punctuation">\</span>
<span class="token parameter variable">--num_client_proc</span> <span class="token number">16</span> <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--data_path</span> ~/my_task <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--max_step</span> <span class="token number">500</span> <span class="token parameter variable">--log_interval</span> <span class="token number">100</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">--test</span> <span class="token parameter variable">-adv</span> <span class="token parameter variable">--regularization_coef</span> <span class="token number">1</span>.00E-09 <span class="token parameter variable">--num_thread</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>Most of the options we have already seen in previous sections. Here are some new options we need to know.</p>
<ul>
<li><p><code>--path</code> indicates the absolute path of our workspace. All the logs and trained embedding will be stored in this path.</p>
</li>
<li><p><code>--ip_config</code> is the absolute path of <code>ip_config.txt</code>.</p>
</li>
<li><p><code>--num_client_proc</code> has the same behaviors to <code>--num_proc</code> in single-machine training.</p>
</li>
</ul>
<p>All the other options are the same as single-machine training. For some EC2 users, you can also set <code>--ssh_key</code> for right ssh permission.</p>
<p>If you don’t set <code>--no_save_embed</code> option. The trained KG embeddings will be stored in <code>machine_0/my_task/ckpts</code> by default.</p>
<h2 id="Evaluation-on-Pre-Trained-Embeddings"><a href="#Evaluation-on-Pre-Trained-Embeddings" class="headerlink" title="Evaluation on Pre-Trained Embeddings"></a>Evaluation on Pre-Trained Embeddings</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/eval.html">https://dglke.dgl.ai/doc/eval.html</a> .</p>
<p><code>dglke_eval</code> reads the pre-trained embeddings and evaluates the quality of the embeddings with a link prediction task on the test set.</p>
<h3 id="Arguments-3"><a href="#Arguments-3" class="headerlink" title="Arguments"></a>Arguments</h3><p>The command line provides the following arguments:</p>
<ul>
<li><p><code>--model_name &#123;TransE, TransE_l1, TransE_l2, TransR, RESCAL, DistMult, ComplEx, RotatE&#125;</code> The models provided by DGL-KE.</p>
</li>
<li><p><code>--data_path DATA_PATH</code> The name of the knowledge graph stored under data_path. If it is one ofthe builtin knowledge grpahs such as FB15k, DGL-KE will automatically download the knowledge graph and keep it under data_path.</p>
</li>
<li><p><code>--dataset DATASET</code> The name of the knowledge graph stored under data_path. If it is one ofthe builtin knowledge grpahs such as FB15k, DGL-KE will automatically download the knowledge graph and keep it under data_path.</p>
</li>
<li><p><code>--format FORMAT</code> The format of the dataset. For builtin knowledge graphs, the format is determined automatically. For users own knowledge graphs, it needs to be <code>raw_udd_&#123;htr&#125;</code> or <code>udd_&#123;htr&#125;</code>. <code>raw_udd_</code> indicates that the user’s data use <code>raw ID</code> for entities and relations and <code>udd_</code> indicates that the user’s data uses <code>KGE ID</code>. <code>&#123;htr&#125;</code> indicates the location of the head entity, tail entity and relation in a triplet. For example, <code>htr</code> means the head entity is the first element in the triplet, the tail entity is the second element and the relation is the last element.</p>
</li>
<li><p><code>--data_files [DATA_FILES ...]</code> A list of data file names. This is used if users want to train KGE on their own datasets. If the format is <code>raw_udd_&#123;htr&#125;</code>, users need to provide <code>train_file</code> <code>[valid_file]</code> <code>[test_file]</code>. If the format is udd_<code>&#123;htr&#125;</code>, users need to provide <code>entity_file</code> <code>relation_file</code> <code>train_file</code> <code>[valid_file]</code> <code>[test_file]</code>. In both cases, <code>valid_file</code> and <code>test_file</code> are optional.</p>
</li>
<li><p><code>--delimiter DELIMITER</code> Delimiter used in data files. Note all files should use the same delimiter.</p>
</li>
<li><p><code>--model_path MODEL_PATH</code> The place where models are saved.</p>
</li>
<li><p><code>--batch_size_eval BATCH_SIZE_EVAL</code> Batch size used for eval and test</p>
</li>
<li><p><code>--neg_sample_size_eval NEG_SAMPLE_SIZE_EVAL</code> Negative sampling size for testing</p>
</li>
<li><p><code>--neg_deg_sample_eval</code> Negative sampling proportional to vertex degree for testing.</p>
</li>
<li><p><code>--hidden_dim HIDDEN_DIM</code> Hidden dim used by relation and entity</p>
</li>
<li><p><code>-g GAMMA</code> or <code>--gamma GAMMA</code> The margin value in the score function. It is used by TransX and RotatE.</p>
</li>
<li><p><code>--eval_percent EVAL_PERCENT</code> Randomly sample some percentage of edges for evaluation.</p>
</li>
<li><p><code>--no_eval_filter</code> Disable filter positive edges from randomly constructed negative edges for evaluation.</p>
</li>
<li><p><code>--gpu [GPU ...]</code> A list of gpu ids, e.g. 0 1 2 4</p>
</li>
<li><p><code>--mix_cpu_gpu</code> Training a knowledge graph embedding model with both CPUs and GPUs.The embeddings are stored in CPU memory and the training is performed in GPUs.This is usually used for training a large knowledge graph embeddings.</p>
</li>
<li><p><code>-de</code> or <code>--double_ent</code> Double entitiy dim for complex number It is used by RotatE.</p>
</li>
<li><p><code>-dr</code> or <code>--double_rel</code> Double relation dim for complex number.</p>
</li>
<li><p><code>--num_proc NUM_PROC</code> The number of processes to train the model in parallel.In multi-GPU training, the number of processes by default is set to match the number of GPUs. If set explicitly, the number of processes needs to be divisible by the number of GPUs.</p>
</li>
<li><p><code>--num_thread NUM_THREAD</code> The number of CPU threads to train the model in each process. This argument is used for multi-processing training.</p>
</li>
</ul>
<h3 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h3><p>The following command evaluates the pre-trained KG embedding on <code>multi-cores</code>:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_eval <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--num_thread</span> <span class="token number">1</span> <span class="token parameter variable">--num_proc</span> <span class="token number">8</span> <span class="token parameter variable">--model_path</span> ~/my_task/ckpts/TransE_l2_FB15k_0/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>We can also use <code>GPUs</code> in our evaluation tasks:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">dglke_eval <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--gpu</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span> <span class="token number">5</span> <span class="token number">6</span> <span class="token number">7</span> <span class="token parameter variable">--model_path</span> ~/my_task/ckpts/TransE_l2_FB15k_0/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<h2 id="Predict-entities-relations-in-triplets"><a href="#Predict-entities-relations-in-triplets" class="headerlink" title="Predict entities&#x2F;relations in triplets"></a>Predict entities&#x2F;relations in triplets</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/predict.html">https://dglke.dgl.ai/doc/predict.html</a> .</p>
<p><code>dglke_predict</code> predicts missing entities or relations in a triplet. Blow shows an example that predicts <code>top 5</code> most likely destination entities for every given source node and relation:</p>
<pre class="line-numbers language-none"><code class="language-none">src  rel  dst   score
 1    0    12   -5.11393
 1    0    18   -6.10925
 1    0    13   -6.66778
 1    0    17   -6.81532
 1    0    19   -6.83329
 2    0    17   -5.09325
 2    0    18   -5.42972
 2    0    20   -5.61894
 2    0    12   -5.75848
 2    0    14   -5.94183<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Currently, it supports six models: <code>TransE_l1</code>, <code>TransE_l2</code>, <code>RESCAL</code>, <code>DistMult</code>, <code>ComplEx</code>, and <code>RotatE</code>.</p>
<h3 id="Arguments-4"><a href="#Arguments-4" class="headerlink" title="Arguments"></a>Arguments</h3><p>Four arguments are required to provide basic information for predicting missing entities or relations:</p>
<ul>
<li><p><code>--model_path</code>, The path containing the pretrained model, including the embedding files (.npy) and a config.json containing the configuration of training the model.</p>
</li>
<li><p><code>--format</code>, The format of the input data, specified in <code>h_r_t</code>. Ideally, user should provides three files, one for head entities, one for relations and one for tail entities. But we also allow users to use <code>*</code> to represent all of the entities or relations. For example, <code>h_r_*</code> requires users to provide files containing head entities and relation entities and use all entities as tail entities; <code>*_*_t</code> requires users to provide a single file containing tail entities and use all entities as head entities and all relations. The supported formats include <code>h_r_t</code>, <code>h_r_*</code>, <code>h_*_t</code>, <code>*_r_t</code>, <code>h_*_*</code>, <code>*_r_*</code>, <code>*_*_t</code>.</p>
</li>
<li><p><code>--data_files</code> A list of data file names. This is used to provide necessary files containing the input data according to the format, e.g., for <code>h_r_t</code>, the three input files are required and they contain a list of head entities, a list of relations and a list of tail entities. For <code>h_*_t</code>, two files are required, which contain a list of head entities and a list of tail entities.</p>
</li>
<li><p><code>--raw_data</code>, A flag indicates whether the input data specified by –data_files use the raw Ids or KGE Ids. If True, the input data uses Raw IDs and the command translates IDs according to ID mapping. If False, the data use KGE IDs. Default False.</p>
</li>
</ul>
<p>Task related arguments:</p>
<ul>
<li><p><code>--exec_mode</code>, How to calculate scores for triplets and calculate topK. Default ‘all’.</p>
<ul>
<li><p><code>triplet_wise</code>: head, relation and tail lists have the same length N, and we calculate the similarity triplet by triplet: <code>result = topK([score(h_i, r_i, t_i) for i in N])</code>, the result shape will be (K,).</p>
</li>
<li><p><code>all</code>: three lists of head, relation and tail ids are provided as H, R and T, and we calculate all possible combinations of all triplets (h_i, r_j, t_k): <code>result = topK([[[score(h_i, r_j, t_k) for each h_i in H] for each r_j in R] for each t_k in T])</code>, and find top K from the triplets</p>
</li>
<li><p><code>batch_head</code>: three lists of head, relation and tail ids are provided as H, R and T, and we calculate topK for each element in head: <code>result = topK([[score(h_i, r_j, t_k) for each r_j in R] for each t_k in T]) for each h_i in H</code>. It returns (sizeof(H) * K) triplets.</p>
</li>
<li><p><code>batch_rel</code>: three lists of head, relation and tail ids are provided as H, R and T, and we calculate topK for each element in relation: <code>result = topK([[score(h_i, r_j, t_k) for each h_i in H] for each t_k in T]) for each r_j in R</code>. It returns (sizeof(R) * K) triplets.</p>
</li>
<li><p><code>batch_tail</code>: three lists of head, relation and tail ids are provided as H, R and T, and we calculate topK for each element in tail: <code>result = topK([[score(h_i, r_j, t_k) for each h_i in H] for each r_j in R]) for each t_k in T</code>. It returns (sizeof(T) * K) triplets.</p>
</li>
</ul>
</li>
<li><p><code>--topk</code>, How many results are returned. Default: <code>10</code>.</p>
</li>
<li><p><code>--score_func</code>, What kind of score is used in ranking. Currently, we support two functions: <code>none</code> (score &#x3D; $x$) and <code>logsigmoid</code> ($score &#x3D; log(sigmoid(x))$). Default: <code>none</code>.</p>
</li>
<li><p><code>--gpu</code>, GPU device to use in inference. Default: <code>-1</code> (CPU)</p>
</li>
</ul>
<p>Input&#x2F;Output related arguments:</p>
<ul>
<li><p><code>--output</code>, the output file to store the result. By default it is stored in <code>result.tsv</code>.</p>
</li>
<li><p><code>--entity_mfile</code>, The entity ID mapping file. <code>Required if Raw ID is used</code>.</p>
</li>
<li><p><code>--rel_mfile</code>, The relation ID mapping file. <code>Required if Raw ID is used</code>.</p>
</li>
</ul>
<h3 id="Examples-1"><a href="#Examples-1" class="headerlink" title="Examples"></a>Examples</h3><p>The following command <code>predicts the K most likely relations and tail entities for each head entity in the list using a pretrained TransE_l2 model (–exec_mode ‘batch_head’)</code>. In this example, the candidate relations and the candidate tail entities are given by the user.:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Using PyTorch Backend</span>
dglke_predict <span class="token parameter variable">--model_path</span> ckpts/TransE_l2_wn18_0/ <span class="token parameter variable">--format</span> <span class="token string">'h_r_t'</span> <span class="token parameter variable">--data_files</span> head.list rel.list tail.list <span class="token parameter variable">--score_func</span> logsigmoid <span class="token parameter variable">--topK</span> <span class="token number">5</span> <span class="token parameter variable">--exec_mode</span> <span class="token string">'batch_head'</span>

<span class="token comment"># Using MXNet Backend</span>
<span class="token assign-left variable">MXNET_ENGINE_TYPE</span><span class="token operator">=</span>NaiveEngine <span class="token assign-left variable">DGLBACKEND</span><span class="token operator">=</span>mxnet dglke_predict <span class="token parameter variable">--model_path</span> ckpts/TransE_l2_wn18_0/ <span class="token parameter variable">--format</span> <span class="token string">'h_r_t'</span> <span class="token parameter variable">--data_files</span> head.list rel.list tail.list <span class="token parameter variable">--score_func</span> logsigmoid <span class="token parameter variable">--topK</span> <span class="token number">5</span>  <span class="token parameter variable">--exec_mode</span> <span class="token string">'batch_head'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The output is as:</p>
<pre class="line-numbers language-none"><code class="language-none">src  rel  dst  score
1    0    12   -5.11393
1    0    18   -6.10925
1    0    13   -6.66778
1    0    17   -6.81532
1    0    19   -6.83329
2    0    17   -5.09325
2    0    18   -5.42972
2    0    20   -5.61894
2    0    12   -5.75848
2    0    14   -5.94183
...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The following command finds the most likely combinations of head entities, relations and tail entities from the input lists using a pretrained <code>DistMult</code> model:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Using PyTorch Backend</span>
dglke_predict <span class="token parameter variable">--model_path</span> ckpts/DistMult_wn18_0/ <span class="token parameter variable">--format</span> <span class="token string">'h_r_t'</span> <span class="token parameter variable">--data_files</span> head.list rel.list tail.list <span class="token parameter variable">--score_func</span> none <span class="token parameter variable">--topK</span> <span class="token number">5</span>

<span class="token comment"># Using MXNet Backend</span>
<span class="token assign-left variable">MXNET_ENGINE_TYPE</span><span class="token operator">=</span>NaiveEngine <span class="token assign-left variable">DGLBACKEND</span><span class="token operator">=</span>mxnet dglke_predict <span class="token parameter variable">--model_path</span> ckpts/DistMult_wn18_0/ <span class="token parameter variable">--format</span> <span class="token string">'h_r_t'</span> <span class="token parameter variable">--data_files</span> head.list rel.list tail.list <span class="token parameter variable">--score_func</span> none <span class="token parameter variable">--topK</span> <span class="token number">5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The output is as:</p>
<pre class="line-numbers language-none"><code class="language-none">src  rel  dst  score
6    0    15   -2.39380
8    0    14   -2.65297
2    0    14   -2.67331
9    0    18   -2.86985
8    0    20   -2.89651<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The following command finds the most likely combinations of head entities, relations and tail entities from the input lists using a pretrained <code>TransE_l2</code> model and uses <code>Raw ID</code> (turn on <code>–raw_data</code>):</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Using PyTorch Backend</span>
dglke_predict <span class="token parameter variable">--model_path</span> ckpts/TransE_l2_wn18_0/ <span class="token parameter variable">--format</span> <span class="token string">'h_r_t'</span> <span class="token parameter variable">--data_files</span> raw_head.list raw_rel.list raw_tail.list <span class="token parameter variable">--topK</span> <span class="token number">5</span> <span class="token parameter variable">--raw_data</span> <span class="token parameter variable">--entity_mfile</span> data/wn18/entities.dict <span class="token parameter variable">--rel_mfile</span> data/wn18/relations.dict

<span class="token comment"># Using MXNet Backend</span>
<span class="token assign-left variable">MXNET_ENGINE_TYPE</span><span class="token operator">=</span>NaiveEngine <span class="token assign-left variable">DGLBACKEND</span><span class="token operator">=</span>mxnet dglke_predict <span class="token parameter variable">--model_path</span> ckpts/TransE_l2_wn18_0/ <span class="token parameter variable">--format</span> <span class="token string">'h_r_t'</span> <span class="token parameter variable">--data_files</span> raw_head.list raw_rel.list raw_tail.list <span class="token parameter variable">--topK</span> <span class="token number">5</span> <span class="token parameter variable">--raw_data</span> <span class="token parameter variable">--entity_mfile</span> data/wn18/entities.dict <span class="token parameter variable">--rel_mfile</span> data/wn18/relations.dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The output is as:</p>
<pre class="line-numbers language-none"><code class="language-none">head      rel                           tail      score
08847694  _derivationally_related_form  09440400  -7.41088
08847694  _hyponym                      09440400  -8.99562
02537319  _derivationally_related_form  01490112  -9.08666
02537319  _hyponym                      01490112  -9.44877
00083809  _derivationally_related_form  05940414  -9.88155<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Find-similar-embeddings"><a href="#Find-similar-embeddings" class="headerlink" title="Find similar embeddings"></a>Find similar embeddings</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/emb_sim.html">https://dglke.dgl.ai/doc/emb_sim.html</a> .</p>
<p><code>dglke_emb_sim</code> finds the most similar entity&#x2F;relation embeddings for some <code>pre-defined similarity functions</code> given a set of entities or relations. An example of the output for top5 similar entities are as follows:</p>
<pre class="line-numbers language-none"><code class="language-none">left     right    score
0        0        0.99999
0        18470    0.91855
0        2105     0.89916
0        13605    0.83187
0        36762    0.76978<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>Currently we support five different similarity functions: <code>cosine</code>, <code>l2 distance</code>, <code>l1 distance</code>, <code>dot product</code> and <code>extended jaccard</code>.</p>
<h3 id="Arguments-5"><a href="#Arguments-5" class="headerlink" title="Arguments"></a>Arguments</h3><p>Four arguments are required to provide basic information for finding similar embeddings:</p>
<ul>
<li><p><code>--emb_file</code>, The numpy file that contains the embeddings of all entities&#x2F;relations in a knowledge graph.</p>
</li>
<li><p><code>--format</code>, The format of the input objects (entities&#x2F;relations).</p>
<ul>
<li><p><code>l_r</code>: two list of objects are provided as left objects and right objects.</p>
</li>
<li><p><code>l_*</code>: one list of objects is provided as left objects and all objects in emb_file are right objects. This is to find most similar objects to the ones on the left.</p>
</li>
<li><p><code>*_r</code>: one list of objects is provided as right objects list and treat all objects in emb_file as left objects.</p>
</li>
<li><p><code>*</code>: all objects in the emb_file are both left objects and right objects. The option finds the most similar objects in the graph.</p>
</li>
</ul>
</li>
<li><p><code>--data_files</code> A list of data file names. It provides necessary files containing the requried data according to the format, e.g., for <code>l_r</code>, two files are required as left_data and right_data, while for <code>l_*</code>, one file is required as left_data, and for <code>*</code> this argument will be omited.</p>
</li>
<li><p><code>--raw_data</code>, A flag indicates whether the data in data_files are raw IDs or KGE IDs. If True, the data are the Raw IDs and the command will map the raw IDs to KGE Ids automatically using the ID mapping file provided through <code>--mfile</code>. If False, the data are KGE IDs. Default: False.</p>
</li>
</ul>
<p>Task related arguments:</p>
<ul>
<li><p><code>--exec_mode</code>, Indicate how to calculate scores for element pairs and calculate topK. Default: ‘all’</p>
<ul>
<li><p><code>pairwise</code>: The same number (N) of left and right objects are provided. It calculates the similarity pair by pair: <code>result = topK([score(l_i, r_i) for i in N])</code> and output the K most similar pairs.</p>
</li>
<li><p><code>all</code>: both left objects and right objects are provided as L and R. It calculates similarity scores of all possible combinations of (l_i, r_j): <code>result = topK([[score(l_i, rj) for l_i in L] for r_j in R])</code>, and outputs the K most similar pairs.</p>
</li>
<li><p><code>batch_left</code>: left objects and right objects are provided as L and R. It finds the K most similar objects from the right objects for each object in L: <code>result = topK([score(l_i, r_j) for r_j in R]) for l_j in L</code>. It outputs (len(L) * K) most similar pairs.</p>
</li>
</ul>
</li>
<li><p><code>--topk</code>, How many results are returned. Default: <code>10</code>.</p>
</li>
<li><p><code>--sim_func</code>, the function to define the similarity score between a pair of objects. It support five functions. Default: <code>cosine</code></p>
<ul>
<li><p><code>cosine</code>: use cosine similarity; score &#x3D; $\frac{x \cdot y}{||x||_2||y||_2}$</p>
</li>
<li><p><code>l2</code>: use <code>l2 similarity</code>; score &#x3D; $-||x - y||_2$</p>
</li>
<li><p><code>l1</code>: use <code>l1 similarity</code>; score &#x3D; $-||x - y||_1$</p>
</li>
<li><p><code>dot</code>: use <code>dot product similarity</code>; score &#x3D; $x \cdot y$</p>
</li>
<li><p><code>ext_jaccard</code>: use extended jaccard similarity. score &#x3D; $\frac{x \cdot y}{||x||<em>{2}^{2} + ||y||</em>{2}^{2} - x \cdot y}$</p>
</li>
</ul>
</li>
<li><p><code>--gpu</code>, GPU device to use in inference. Default: -1 (CPU).</p>
</li>
</ul>
<p>Input&#x2F;Output related arguments:</p>
<ul>
<li><p><code>--output</code>, the output file that stores the result. By default it is stored in <code>result.tsv</code>.</p>
</li>
<li><p><code>--mfile</code>, The ID mapping file.</p>
</li>
</ul>
<h3 id="Examples-2"><a href="#Examples-2" class="headerlink" title="Examples"></a>Examples</h3><p>The following command finds similar entities based on <code>cosine distance</code>:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Using PyTorch Backend</span>
dglke_emb_sim <span class="token parameter variable">--emb_file</span> ckpts/TransE_l2_wn18_0/wn18_TransE_l2_entity.npy <span class="token parameter variable">--format</span> <span class="token string">'l_r'</span> <span class="token parameter variable">--data_files</span> head.list tail.list  <span class="token parameter variable">--topK</span> <span class="token number">5</span>

<span class="token comment"># Using MXNet Backend</span>
<span class="token assign-left variable">MXNET_ENGINE_TYPE</span><span class="token operator">=</span>NaiveEngine <span class="token assign-left variable">DGLBACKEND</span><span class="token operator">=</span>mxnet dglke_emb_sim <span class="token parameter variable">--emb_file</span> ckpts/TransE_l2_wn18_0/wn18_TransE_l2_entity.npy <span class="token parameter variable">--format</span> <span class="token string">'l_r'</span> <span class="token parameter variable">--data_files</span> head.list tail.list <span class="token parameter variable">--topK</span> <span class="token number">5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The output is as:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">left    right   score
<span class="token number">6</span>       <span class="token number">15</span>      <span class="token number">0.55512</span>
<span class="token number">1</span>       <span class="token number">12</span>      <span class="token number">0.33153</span>
<span class="token number">7</span>       <span class="token number">20</span>      <span class="token number">0.27706</span>
<span class="token number">7</span>       <span class="token number">19</span>      <span class="token number">0.25631</span>
<span class="token number">7</span>       <span class="token number">13</span>      <span class="token number">0.21372</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The following command finds topK most similar entities for each element on the left using <code>l2 distance</code> (–exec_mode batch_left):</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Using PyTorch Backend</span>
dglke_emb_sim <span class="token parameter variable">--emb_file</span> ckpts/TransE_l2_wn18_0/wn18_TransE_l2_entity.npy <span class="token parameter variable">--format</span> <span class="token string">'l_*'</span> <span class="token parameter variable">--data_files</span> head.list <span class="token parameter variable">--sim_func</span> l2 <span class="token parameter variable">--topK</span> <span class="token number">5</span> <span class="token parameter variable">--exec_mode</span> <span class="token string">'batch_left'</span>

<span class="token comment"># Using MXNet Backend</span>
<span class="token assign-left variable">MXNET_ENGINE_TYPE</span><span class="token operator">=</span>NaiveEngine <span class="token assign-left variable">DGLBACKEND</span><span class="token operator">=</span>mxnet dglke_emb_sim <span class="token parameter variable">--emb_file</span> ckpts/TransE_l2_wn18_0/wn18_TransE_l2_entity.npy <span class="token parameter variable">--format</span> <span class="token string">'l_*'</span> <span class="token parameter variable">--data_files</span> head.list <span class="token parameter variable">--sim_func</span> l2 <span class="token parameter variable">--topK</span> <span class="token number">5</span> <span class="token parameter variable">--exec_mode</span> <span class="token string">'batch_left'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The output is as:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">left    right   score
<span class="token number">0</span>       <span class="token number">0</span>       <span class="token number">0.0</span>
<span class="token number">0</span>       <span class="token number">18470</span>   <span class="token number">3.1008</span>
<span class="token number">0</span>       <span class="token number">24408</span>   <span class="token number">3.1466</span>
<span class="token number">0</span>       <span class="token number">2105</span>    <span class="token number">3.3411</span>
<span class="token number">0</span>       <span class="token number">13605</span>   <span class="token number">4.1587</span>
<span class="token number">1</span>       <span class="token number">1</span>       <span class="token number">0.0</span>
<span class="token number">1</span>       <span class="token number">26231</span>   <span class="token number">4.9025</span>
<span class="token number">1</span>       <span class="token number">2617</span>    <span class="token number">5.0204</span>
<span class="token number">1</span>       <span class="token number">12672</span>   <span class="token number">5.2221</span>
<span class="token number">1</span>       <span class="token number">38633</span>   <span class="token number">5.3221</span>
<span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The following command finds similar relations using cosine distance and use <code>Raw ID</code> (turn on –raw_data):</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># Using PyTorch Backend</span>
dglke_emb_sim <span class="token parameter variable">--mfile</span> data/wn18/relations.dict <span class="token parameter variable">--emb_file</span> ckpts/TransE_l2_wn18_0/wn18_TransE_l2_relation.npy  <span class="token parameter variable">--format</span> <span class="token string">'l_*'</span> <span class="token parameter variable">--data_files</span> raw_rel.list <span class="token parameter variable">--topK</span> <span class="token number">5</span> <span class="token parameter variable">--raw_data</span>

<span class="token comment"># Using MXNet Backend</span>
<span class="token assign-left variable">MXNET_ENGINE_TYPE</span><span class="token operator">=</span>NaiveEngine <span class="token assign-left variable">DGLBACKEND</span><span class="token operator">=</span>mxnet dglke_emb_sim <span class="token parameter variable">--mfile</span> data/wn18/relations.dict <span class="token parameter variable">--emb_file</span> ckpts/TransE_l2_wn18_0/wn18_TransE_l2_relation.npy  <span class="token parameter variable">--format</span> <span class="token string">'l_*'</span> <span class="token parameter variable">--data_files</span> raw_rel.list <span class="token parameter variable">--topK</span> <span class="token number">5</span> <span class="token parameter variable">--raw_data</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>The output is as:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">left                          right                           score
_hyponym                      _hyponym                        <span class="token number">0.99999</span>
_derivationally_related_form  _derivationally_related_form    <span class="token number">0.99999</span>
_hyponym                      _also_see                       <span class="token number">0.58408</span>
_hyponym                      _member_of_domain_topic         <span class="token number">0.44027</span>
_hyponym                      _member_of_domain_region        <span class="token number">0.30975</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Train-User-Defined-Knowledage-Graphs"><a href="#Train-User-Defined-Knowledage-Graphs" class="headerlink" title="Train User-Defined Knowledage Graphs"></a>Train User-Defined Knowledage Graphs</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/train_user_data.html">https://dglke.dgl.ai/doc/train_user_data.html</a> .</p>
<p>Users can use DGL-KE to train embeddings on their own knowledge graphs. In this case, users need to use <code>--data_path</code> to specify the path to the knowledge graph dataset, <code>--data_files</code> to specify the triplets of a knowledge graph as well as node&#x2F;relation ID mapping, <code>--format</code> to specify the input format of the knowledge graph.</p>
<h3 id="The-input-format-of-users’-knowledge-graphs"><a href="#The-input-format-of-users’-knowledge-graphs" class="headerlink" title="The input format of users’ knowledge graphs"></a>The input format of users’ knowledge graphs</h3><p>Users need to store all the data associated with a knowledge graph in the same directory. DGL-KE supports two knowledge graph input formats:</p>
<ul>
<li><strong>Raw user-defined knowledge graphs: user only needs to provide triplets, both entities and relations in the triplets can be arbitrary strings. The dataloader will automatically generate the id mappings for entities and relations in the triplets.</strong> An example of triplets:</li>
</ul>
<dd><table border="1" class="colwidths-given first last docutils align-center">
<colgroup>
<col width="27%" />
<col width="45%" />
<col width="27%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">&#160;</th>
<th class="head">train.tsv</th>
<th class="head">&#160;</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Beijing</td>
<td>is_capital_of</td>
<td>China</td>
</tr>
<tr class="row-odd"><td>London</td>
<td>is_capital_of</td>
<td>UK</td>
</tr>
<tr class="row-even"><td>UK</td>
<td>located_at</td>
<td>Europe</td>
</tr>
<tr class="row-odd"><td>…</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
</dd>

<ul>
<li><strong>User-defined knowledge graphs: user need to provide the id mapping for entities and relations as well as the triplets of the knowledge graph. The triplets should only contains entities ids and relation ids. Here we assume the both the entities ids and relation ids start from 0 and should be contineous.</strong> An example of mapping and triplets files:</li>
</ul>
<dd><table border="1" class="colwidths-given first last docutils align-center">
<colgroup>
<col width="36%" />
<col width="39%" />
<col width="24%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">entities.dict</th>
<th class="head">relation.dict</th>
<th class="head">train.tsv</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>Beijing  0</td>
<td>is_capital_of  0</td>
<td>0   0   2</td>
</tr>
<tr class="row-odd"><td>London   1</td>
<td>located_at     1</td>
<td>1   0   3</td>
</tr>
<tr class="row-even"><td>China    2</td>
<td>&#160;</td>
<td>3   1   4</td>
</tr>
<tr class="row-odd"><td>UK       3</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td>Europe   4</td>
<td>&#160;</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
</dd>

<h4 id="Using-raw-user-defined-knowledge-graph-format"><a href="#Using-raw-user-defined-knowledge-graph-format" class="headerlink" title="Using raw user-defined knowledge graph format"></a>Using raw user-defined knowledge graph format</h4><p>Users need to store all the data associated with a knowledge graph in the same directory. DGL-KE supports two knowledge graph input formats:</p>
<p><code>raw_udd_[h|r|t]</code>: In this format, <code>users only need to provide triplets and the dataloader generates the id mappings for entities and relations in the triplets</code>. The dataloader outputs two files: entities.tsv for entity id mapping and relations.tsv for relation id mapping while loading data. The order of head, relation and tail entities are described in <code>[h|r|t]</code>, for example, raw_udd_trh means the triplets are stored in the order of tail, relation and head. The directory contains three files:</p>
<ul>
<li><p><code>train stores the triplets in the training set</code>. The format of a triplet, e.g., <code>[src_name, rel_name, dst_name]</code>, should follow the order specified in <code>[h|r|t]</code></p>
</li>
<li><p><code>valid stores the triplets in the validation set</code>. The format of a triplet, e.g., <code>[src_name, rel_name, dst_name]</code>, should follow the order specified in <code>[h|r|t]</code>. This is optional.</p>
</li>
<li><p><code>test stores the triplets in the test set</code>. The format of a triplet, e.g., <code>[src_name, rel_name, dst_name]</code>, should follow the order specified in <code>[h|r|t]</code>. This is optional.</p>
</li>
</ul>
<h4 id="Using-user-defined-knowledge-graph-format"><a href="#Using-user-defined-knowledge-graph-format" class="headerlink" title="Using user-defined knowledge graph format"></a>Using user-defined knowledge graph format</h4><p><code>udd_[h|r|t]</code>: In this format, <code>user should provide the id mapping for entities and relations</code>. The order of head, relation and tail entities are described in <code>[h|r|t]</code>, for example, raw_udd_trh means the triplets are stored in the order of tail, relation and head. The directory should contains five files:</p>
<ul>
<li><p>entities stores the mapping between entity name and entity Id</p>
</li>
<li><p>relations stores the mapping between relation name relation Id</p>
</li>
<li><p>train stores the triplets in the training set. The format of a triplet, e.g., <code>[src_id, rel_id, dst_id]</code>, should follow the order specified in <code>[h|r|t]</code></p>
</li>
<li><p>valid stores the triplets in the validation set. The format of a triplet, e.g., <code>[src_id, rel_id, dst_id]</code>, should follow the order specified in <code>[h|r|t]</code></p>
</li>
<li><p>test stores the triplets in the test set. The format of a triplet, e.g., <code>[src_id, rel_id, dst_id]</code>, should follow the order specified in <code>[h|r|t]</code></p>
</li>
</ul>
<h2 id="Benchmarks-on-Built-in-Knowledage-Graphs"><a href="#Benchmarks-on-Built-in-Knowledage-Graphs" class="headerlink" title="Benchmarks on Built-in Knowledage Graphs"></a>Benchmarks on Built-in Knowledage Graphs</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/benchmarks.html">https://dglke.dgl.ai/doc/benchmarks.html</a> .</p>
<p>DGL-KE provides five built-in knowledge graphs:</p>
<table border="1" class="docutils">
<colgroup>
<col width="26%" />
<col width="26%" />
<col width="23%" />
<col width="26%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Dataset</th>
<th class="head">nodes</th>
<th class="head">edges</th>
<th class="head">relations</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>FB15k</td>
<td>14951</td>
<td>592213</td>
<td>1345</td>
</tr>
<tr class="row-odd"><td>FB15k-237</td>
<td>14541</td>
<td>310116</td>
<td>237</td>
</tr>
<tr class="row-even"><td>wn18</td>
<td>40943</td>
<td>151442</td>
<td>18</td>
</tr>
<tr class="row-odd"><td>wn18rr</td>
<td>40943</td>
<td>93003</td>
<td>11</td>
</tr>
<tr class="row-even"><td>Freebase</td>
<td>86054151</td>
<td>338586276</td>
<td>14824</td>
</tr>
</tbody>
</table>

<p>Users can specify one of the datasets with <code>--dataset</code> option in their tasks.</p>
<p>DGL-KE provides benchmark results on <code>FB15k</code>, <code>wn18</code>, as well as <code>Freebase</code>. Users can go to the corresponded folder to check out the scripts and results. All the benchmark results are done by AWS EC2. For multi-cpu and distributed training, the target instance is <code>r5dn.24xlarge</code>, which has 48 CPU cores and 768 GB memory. Also, <code>r5dn.xlarge</code> has 100Gbit network throughput, which is powerful for distributed training. For GPU training, our target instance is <code>p3.16xlarge</code>, which has 64 CPU cores and 8 Nvidia v100 GPUs. For users, you can choose your own instance by your demand and tune the hyper-parameters for the best performance.</p>
<p>All the scripts can be found on this <a href="https://github.com/awslabs/dgl-ke/tree/master/examples">page</a>.</p>
<h3 id="FB15k"><a href="#FB15k" class="headerlink" title="FB15k"></a>FB15k</h3><p>One-GPU training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l1</td>
<td>47.34</td>
<td>0.672</td>
<td>0.557</td>
<td>0.763</td>
<td>0.849</td>
<td>201</td>
</tr>
<tr class="row-odd"><td>TransE_l2</td>
<td>47.04</td>
<td>0.649</td>
<td>0.525</td>
<td>0.746</td>
<td>0.844</td>
<td>167</td>
</tr>
<tr class="row-even"><td>DistMult</td>
<td>61.43</td>
<td>0.696</td>
<td>0.586</td>
<td>0.782</td>
<td>0.873</td>
<td>150</td>
</tr>
<tr class="row-odd"><td>ComplEx</td>
<td>64.73</td>
<td>0.757</td>
<td>0.672</td>
<td>0.826</td>
<td>0.886</td>
<td>171</td>
</tr>
<tr class="row-even"><td>RESCAL</td>
<td>124.5</td>
<td>0.661</td>
<td>0.589</td>
<td>0.704</td>
<td>0.787</td>
<td>1252</td>
</tr>
<tr class="row-odd"><td>TransR</td>
<td>59.99</td>
<td>0.670</td>
<td>0.585</td>
<td>0.728</td>
<td>0.808</td>
<td>530</td>
</tr>
<tr class="row-even"><td>RotatE</td>
<td>43.85</td>
<td>0.726</td>
<td>0.632</td>
<td>0.799</td>
<td>0.873</td>
<td>1405</td>
</tr>
</tbody>
</table>

<p>8-GPU training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l1</td>
<td>48.59</td>
<td>0.662</td>
<td>0.542</td>
<td>0.756</td>
<td>0.846</td>
<td>53</td>
</tr>
<tr class="row-odd"><td>TransE_l2</td>
<td>47.52</td>
<td>0.627</td>
<td>0.492</td>
<td>0.733</td>
<td>0.838</td>
<td>49</td>
</tr>
<tr class="row-even"><td>DistMult</td>
<td>59.44</td>
<td>0.679</td>
<td>0.566</td>
<td>0.764</td>
<td>0.864</td>
<td>47</td>
</tr>
<tr class="row-odd"><td>ComplEx</td>
<td>64.98</td>
<td>0.750</td>
<td>0.668</td>
<td>0.814</td>
<td>0.883</td>
<td>49</td>
</tr>
<tr class="row-even"><td>RESCAL</td>
<td>133.3</td>
<td>0.643</td>
<td>0.570</td>
<td>0.685</td>
<td>0.773</td>
<td>179</td>
</tr>
<tr class="row-odd"><td>TransR</td>
<td>66.51</td>
<td>0.666</td>
<td>0.581</td>
<td>0.724</td>
<td>0.803</td>
<td>90</td>
</tr>
<tr class="row-even"><td>RotatE</td>
<td>50.04</td>
<td>0.685</td>
<td>0.581</td>
<td>0.763</td>
<td>0.851</td>
<td>120</td>
</tr>
</tbody>
</table>

<p>Multi-CPU training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l1</td>
<td>48.32</td>
<td>0.645</td>
<td>0.521</td>
<td>0.741</td>
<td>0.838</td>
<td>140</td>
</tr>
<tr class="row-odd"><td>TransE_l2</td>
<td>45.28</td>
<td>0.633</td>
<td>0.501</td>
<td>0.735</td>
<td>0.840</td>
<td>58</td>
</tr>
<tr class="row-even"><td>DistMult</td>
<td>62.63</td>
<td>0.647</td>
<td>0.529</td>
<td>0.733</td>
<td>0.846</td>
<td>58</td>
</tr>
<tr class="row-odd"><td>ComplEx</td>
<td>67.83</td>
<td>0.694</td>
<td>0.590</td>
<td>0.772</td>
<td>0.863</td>
<td>69</td>
</tr>
</tbody>
</table>

<p>Distributed training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l1</td>
<td>38.26</td>
<td>0.691</td>
<td>0.591</td>
<td>0.765</td>
<td>0.853</td>
<td>104</td>
</tr>
<tr class="row-odd"><td>TransE_l2</td>
<td>34.84</td>
<td>0.645</td>
<td>0.510</td>
<td>0.754</td>
<td>0.854</td>
<td>31</td>
</tr>
<tr class="row-even"><td>DistMult</td>
<td>51.85</td>
<td>0.661</td>
<td>0.532</td>
<td>0.762</td>
<td>0.864</td>
<td>57</td>
</tr>
<tr class="row-odd"><td>ComplEx</td>
<td>62.52</td>
<td>0.667</td>
<td>0.567</td>
<td>0.737</td>
<td>0.836</td>
<td>65</td>
</tr>
</tbody>
</table>

<h3 id="wn18"><a href="#wn18" class="headerlink" title="wn18"></a>wn18</h3><p>One-GPU training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l1</td>
<td>355.4</td>
<td>0.764</td>
<td>0.602</td>
<td>0.928</td>
<td>0.949</td>
<td>327</td>
</tr>
<tr class="row-odd"><td>TransE_l2</td>
<td>209.4</td>
<td>0.560</td>
<td>0.306</td>
<td>0.797</td>
<td>0.943</td>
<td>223</td>
</tr>
<tr class="row-even"><td>DistMult</td>
<td>419.0</td>
<td>0.813</td>
<td>0.702</td>
<td>0.921</td>
<td>0.948</td>
<td>133</td>
</tr>
<tr class="row-odd"><td>ComplEx</td>
<td>318.2</td>
<td>0.932</td>
<td>0.914</td>
<td>0.948</td>
<td>0.959</td>
<td>144</td>
</tr>
<tr class="row-even"><td>RESCAL</td>
<td>563.6</td>
<td>0.848</td>
<td>0.792</td>
<td>0.898</td>
<td>0.928</td>
<td>308</td>
</tr>
<tr class="row-odd"><td>TransR</td>
<td>432.8</td>
<td>0.609</td>
<td>0.452</td>
<td>0.736</td>
<td>0.850</td>
<td>906</td>
</tr>
<tr class="row-even"><td>RotatE</td>
<td>451.6</td>
<td>0.944</td>
<td>0.940</td>
<td>0.945</td>
<td>0.950</td>
<td>671</td>
</tr>
</tbody>
</table>

<p>8-GPU training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l1</td>
<td>348.8</td>
<td>0.739</td>
<td>0.553</td>
<td>0.927</td>
<td>0.948</td>
<td>111</td>
</tr>
<tr class="row-odd"><td>TransE_l2</td>
<td>198.9</td>
<td>0.559</td>
<td>0.305</td>
<td>0.798</td>
<td>0.942</td>
<td>71</td>
</tr>
<tr class="row-even"><td>DistMult</td>
<td>798.8</td>
<td>0.806</td>
<td>0.705</td>
<td>0.903</td>
<td>0.932</td>
<td>66</td>
</tr>
<tr class="row-odd"><td>ComplEx</td>
<td>535.0</td>
<td>0.938</td>
<td>0.931</td>
<td>0.944</td>
<td>0.949</td>
<td>53</td>
</tr>
<tr class="row-even"><td>RotatE</td>
<td>487.7</td>
<td>0.943</td>
<td>0.939</td>
<td>0.945</td>
<td>0.951</td>
<td>127</td>
</tr>
</tbody>
</table>

<p>Multi-CPU training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l1</td>
<td>376.3</td>
<td>0.593</td>
<td>0.264</td>
<td>0.926</td>
<td>0.949</td>
<td>925</td>
</tr>
<tr class="row-odd"><td>TransE_l2</td>
<td>218.3</td>
<td>0.528</td>
<td>0.259</td>
<td>0.777</td>
<td>0.939</td>
<td>210</td>
</tr>
<tr class="row-even"><td>DistMult</td>
<td>837.4</td>
<td>0.791</td>
<td>0.675</td>
<td>0.904</td>
<td>0.933</td>
<td>362</td>
</tr>
<tr class="row-odd"><td>ComplEx</td>
<td>806.3</td>
<td>0.904</td>
<td>0.881</td>
<td>0.926</td>
<td>0.937</td>
<td>281</td>
</tr>
</tbody>
</table>

<p>Distributed training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l1</td>
<td>136.0</td>
<td>0.848</td>
<td>0.768</td>
<td>0.927</td>
<td>0.950</td>
<td>759</td>
</tr>
<tr class="row-odd"><td>TransE_l2</td>
<td>85.04</td>
<td>0.797</td>
<td>0.672</td>
<td>0.921</td>
<td>0.958</td>
<td>144</td>
</tr>
<tr class="row-even"><td>DistMult</td>
<td>278.5</td>
<td>0.872</td>
<td>0.816</td>
<td>0.926</td>
<td>0.939</td>
<td>275</td>
</tr>
<tr class="row-odd"><td>ComplEx</td>
<td>333.8</td>
<td>0.838</td>
<td>0.796</td>
<td>0.870</td>
<td>0.906</td>
<td>273</td>
</tr>
</tbody>
</table>

<h3 id="Freebase"><a href="#Freebase" class="headerlink" title="Freebase"></a>Freebase</h3><p>8-GPU training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l2</td>
<td>23.56</td>
<td>0.736</td>
<td>0.663</td>
<td>0.782</td>
<td>0.873</td>
<td>4767</td>
</tr>
<tr class="row-odd"><td>DistMult</td>
<td>46.19</td>
<td>0.833</td>
<td>0.813</td>
<td>0.842</td>
<td>0.869</td>
<td>4281</td>
</tr>
<tr class="row-even"><td>ComplEx</td>
<td>46.70</td>
<td>0.834</td>
<td>0.815</td>
<td>0.843</td>
<td>0.869</td>
<td>8356</td>
</tr>
<tr class="row-odd"><td>TransR</td>
<td>49.68</td>
<td>0.696</td>
<td>0.653</td>
<td>0.716</td>
<td>0.773</td>
<td>14235</td>
</tr>
<tr class="row-even"><td>RotatE</td>
<td>93.20</td>
<td>0.769</td>
<td>0.748</td>
<td>0.779</td>
<td>0.804</td>
<td>9060</td>
</tr>
</tbody>
</table>

<p>Multi-CPU training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l2</td>
<td>30.82</td>
<td>0.815</td>
<td>0.766</td>
<td>0.848</td>
<td>0.902</td>
<td>6993</td>
</tr>
<tr class="row-odd"><td>DistMult</td>
<td>44.16</td>
<td>0.834</td>
<td>0.815</td>
<td>0.843</td>
<td>0.869</td>
<td>7146</td>
</tr>
<tr class="row-even"><td>ComplEx</td>
<td>45.62</td>
<td>0.835</td>
<td>0.817</td>
<td>0.843</td>
<td>0.870</td>
<td>8732</td>
</tr>
</tbody>
</table>

<p>Distributed training</p>
<table border="1" class="docutils">
<colgroup>
<col width="20%" />
<col width="13%" />
<col width="13%" />
<col width="14%" />
<col width="14%" />
<col width="16%" />
<col width="11%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Models</th>
<th class="head">MR</th>
<th class="head">MRR</th>
<th class="head">HITS-1</th>
<th class="head">HITS-3</th>
<th class="head">HITS-10</th>
<th class="head">TIME</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>TransE_l2</td>
<td>34.25</td>
<td>0.764</td>
<td>0.705</td>
<td>0.802</td>
<td>0.869</td>
<td>1633</td>
</tr>
<tr class="row-odd"><td>DistMult</td>
<td>75.15</td>
<td>0.769</td>
<td>0.751</td>
<td>0.779</td>
<td>0.801</td>
<td>1679</td>
</tr>
<tr class="row-even"><td>ComplEx</td>
<td>77.83</td>
<td>0.771</td>
<td>0.754</td>
<td>0.779</td>
<td>0.802</td>
<td>2293</td>
</tr>
</tbody>
</table>

<h2 id="Profile-DGL-KE"><a href="#Profile-DGL-KE" class="headerlink" title="Profile DGL-KE"></a>Profile DGL-KE</h2><p>原文档地址: <a href="https://dglke.dgl.ai/doc/profile.html">https://dglke.dgl.ai/doc/profile.html</a> .</p>
<p>This document is mainly for developing the DGL-KE models and accelerating their training.</p>
<p>To analyze MXNet version of KE models, please enable MXNet_PROFILER environment variable when running the training job:</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token assign-left variable">MXNET_PROFILER</span><span class="token operator">=</span><span class="token number">1</span> dglke_train <span class="token parameter variable">--model_name</span> TransE_l2 <span class="token parameter variable">--dataset</span> FB15k <span class="token parameter variable">--batch_size</span> <span class="token number">1000</span> <span class="token parameter variable">--neg_sample_size</span> <span class="token number">200</span> <span class="token parameter variable">--hidden_dim</span> <span class="token number">400</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--gamma</span> <span class="token number">19.9</span> <span class="token parameter variable">--lr</span> <span class="token number">0.25</span> <span class="token parameter variable">--max_step</span> <span class="token number">3000</span> <span class="token parameter variable">--log_interval</span> <span class="token number">100</span> <span class="token parameter variable">--batch_size_eval</span> <span class="token number">16</span> <span class="token parameter variable">--test</span> <span class="token parameter variable">-adv</span> <span class="token punctuation">\</span>
<span class="token parameter variable">--regularization_coef</span> <span class="token number">1</span>.00E-09 <span class="token parameter variable">--num_thread</span> <span class="token number">1</span> <span class="token parameter variable">--num_proc</span> <span class="token number">8</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>第四十五篇博文写完，开心！！！！</p>
<p>今天，也是充满希望的一天。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">LuYF-Lemon-love</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://luyf-lemon-love.space/2023/01/27/00045-dgl-ke-xue-xi-bi-ji/">https://luyf-lemon-love.space/2023/01/27/00045-dgl-ke-xue-xi-bi-ji/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">LuYF-Lemon-love</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                                    <span class="chip bg-color">知识图谱</span>
                                </a>
                            
                                <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/">
                                    <span class="chip bg-color">知识图谱补全</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">谢谢小主！</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162303.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162220.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/02/07/00046-da-bao-python-xiang-mu-ubuntu/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/001-美女_黒丝_粉色.png" class="responsive-img" alt="00046-打包 Python 项目">
                        
                        <span class="card-title">00046-打包 Python 项目</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-02-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Python/" class="post-category">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/12/19/00044-bai-du-fan-yi-tong-yong-fan-yi-api-jie-ru-wen-dang-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/0437605176.webp" class="responsive-img" alt="00044-百度翻译通用翻译 API 接入文档学习笔记">
                        
                        <span class="card-title">00044-百度翻译通用翻译 API 接入文档学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-12-19
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/" class="post-category">
                                    实用技巧
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022-2025</span>
            
            <a href="/about" target="_blank">LuYF-Lemon-love</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "5";
                        var startDate = "7";
                        var startHour = "4";
                        var startMinute = "53";
                        var startSecond = "32";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
                <span id="icp"><img src="/medias/icp.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="https://beian.miit.gov.cn" target="_blank">冀ICP备2022012632号-1</a>
            </span>
            
            <br>
            
                <span id="gongan"><img src="https://cos.luyf-lemon-love.space/images/备案图标.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32011502011618" target="_blank">苏公网安备 32011502011618号</a>
            </span>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/LuYF-Lemon-love" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:luyanfeng_nlp@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
