<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="00057-读的 KGE 论文--PDF版本, NLP LLM DeepLearning LuYF-Lemon-love 自然语言处理 深度学习 大语言模型">
    <meta name="description" content="前言知识图谱嵌入（Knowledge Graph Embedding, KGE）是一种将实体和关系表示成低维稠密向量的技术，进而 KG 被建模成低维向量空间，在这个向量空间内，头实体 $h$ 和尾实体 $t$ 是一个单独的向量，每个关系 $">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>00057-读的 KGE 论文--PDF版本 | LuYF-Lemon-love の Blog</title>
    <link rel="icon" type="image/jpeg" href="https://cos.luyf-lemon-love.space/images/苏苏1.jpeg">
    
    <style>
        body{
            background-image: url(https://cos.luyf-lemon-love.space/images/016-%E6%8A%A5%E7%BA%B8%E5%A2%99%E9%BA%BB%E8%A1%A3%E5%AD%A6%E5%A7%90.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <span class="logo-span">LuYF-Lemon-love の Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>List</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/galleries">
          
          <i class="fas fa-image" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Image</span>
        </a>
      </li>
      
      <li>
        <a href="/verse">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Verse</span>
        </a>
      </li>
      
      <li>
        <a href="/bilibili">
          
          <i class="fas fa-video" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Bilibili</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>Server</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="https://luyf-lemon-love.space">
          
          <i class="fas fa-cloud" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Github</span>
        </a>
      </li>
      
      <li>
        <a href="https://server.luyf-lemon-love.space">
          
          <i class="fas fa-cloud" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Cloud</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <div class="logo-name">LuYF-Lemon-love の Blog</div>
        <div class="logo-desc">
            
            天之道，损有余而补不足，人之道则不然，损不足以奉有余。
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			List
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/galleries " style="margin-left:75px">
				  
				   <i class="fa fas fa-image" style="position: absolute;left:50px" ></i>
			      
		          <span>Image</span>
                  </a>
                </li>
              
                <li>

                  <a href="/verse " style="margin-left:75px">
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Verse</span>
                  </a>
                </li>
              
                <li>

                  <a href="/bilibili " style="margin-left:75px">
				  
				   <i class="fa fas fa-video" style="position: absolute;left:50px" ></i>
			      
		          <span>Bilibili</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			Server
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="https://luyf-lemon-love.space " style="margin-left:75px">
				  
				   <i class="fa fas fa-cloud" style="position: absolute;left:50px" ></i>
			      
		          <span>Github</span>
                  </a>
                </li>
              
                <li>

                  <a href="https://server.luyf-lemon-love.space " style="margin-left:75px">
				  
				   <i class="fa fas fa-cloud" style="position: absolute;left:50px" ></i>
			      
		          <span>Cloud</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/LuYF-Lemon-love/paper-is-all-you-need" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/LuYF-Lemon-love/paper-is-all-you-need" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cos.luyf-lemon-love.space/images/015-白丝.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">00057-读的 KGE 论文--PDF版本</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                                <span class="chip bg-color">知识图谱</span>
                            </a>
                        
                            <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/">
                                <span class="chip bg-color">知识图谱补全</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Paper/" class="post-category">
                                Paper
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2023-03-17
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-28
                </div>
                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>知识图谱嵌入（Knowledge Graph Embedding, KGE）是一种将实体和关系表示成低维稠密向量的技术，进而 KG 被建模成低维向量空间，在这个向量空间内，头实体 $h$ 和尾实体 $t$ 是一个单独的向量，每个关系 $r$ 是头实体 $h$ 和尾实体 $t$ 之间的一个运算操作。</p>
<p>记录读过的 PDF 版本的 KGE 论文.</p>
<p>操作系统：<strong>Windows 10 专业版</strong></p>
<h2 id="RESCAL"><a href="#RESCAL" class="headerlink" title="RESCAL"></a>RESCAL</h2><p>论文: A Three-Way Model for Collective Learning on Multi-Relational Data .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Relational learning is becoming increasingly important in many areas of application. Here, we present a novel approach to relational learning based on the factorization of a three-way tensor. We show that unlike other tensor approaches, our method is able to perform collective learning via the latent components of the model and provide an efficient algorithm to compute the factorization. We substantiate our theoretical considerations regarding the collective learning capabilities of our model by the means of experiments on both a new dataset and a dataset commonly used in entity resolution. Furthermore, we show on common benchmark datasets that our approach achieves better or on-par results, if compared to current state-of-the-art relational learning solutions, while it is significantly faster to compute.</p>
</blockquote>
<p>论文地址: <a href="http://www.icml-2011.org/papers.php">http://www.icml-2011.org/papers.php</a> .</p>
<p>PDF 地址: </p>
<ol>
<li><p><a href="https://icml.cc/Conferences/2011/papers/438_icmlpaper.pdf">https://icml.cc/Conferences/2011/papers/438_icmlpaper.pdf</a> .</p>
</li>
<li><p><a href="http://www.icml-2011.org/papers/438_icmlpaper.pdf">http://www.icml-2011.org/papers/438_icmlpaper.pdf</a> .</p>
</li>
</ol>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">@InProceedings&#123;ICML2011Nickel_438,
  author &#x3D;    &#123;Maximilian Nickel and Volker Tresp and Hans-Peter Kriegel&#125;,
  title &#x3D;     &#123;A Three-Way Model for Collective Learning on Multi-Relational Data&#125;,
  booktitle &#x3D; &#123;Proceedings of the 28th International Conference on Machine Learning (ICML-11)&#125;,
  series &#x3D;    &#123;ICML &#39;11&#125;,
  year &#x3D;      &#123;2011&#125;,
  editor &#x3D;    &#123;Lise Getoor and Tobias Scheffer&#125;,
  location &#x3D;  &#123;Bellevue, Washington, USA&#125;,
  isbn &#x3D;      &#123;978-1-4503-0619-5&#125;,
  month &#x3D;     &#123;June&#125;,
  publisher &#x3D; &#123;ACM&#125;,
  address &#x3D;   &#123;New York, NY, USA&#125;,
  pages&#x3D;      &#123;809--816&#125;,
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/09-RESCAL.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/09-RESCAL.pdf</a> .</p>
<h2 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a>TransE</h2><p>论文: Translating Embeddings for Modeling Multi-relational Data .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose, TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.</p>
</blockquote>
<p>论文地址: <a href="https://proceedings.neurips.cc/paper_files/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html">https://proceedings.neurips.cc/paper_files/paper/2013/hash/1cecc7a77928ca8133fa24680a88d2f9-Abstract.html</a> .</p>
<p>PDF 地址: <a href="https://proceedings.neurips.cc/paper_files/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">@inproceedings&#123;NIPS2013_1cecc7a7,
 author &#x3D; &#123;Bordes, Antoine and Usunier, Nicolas and Garcia-Duran, Alberto and Weston, Jason and Yakhnenko, Oksana&#125;,
 booktitle &#x3D; &#123;Advances in Neural Information Processing Systems&#125;,
 editor &#x3D; &#123;C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger&#125;,
 pages &#x3D; &#123;&#125;,
 publisher &#x3D; &#123;Curran Associates, Inc.&#125;,
 title &#x3D; &#123;Translating Embeddings for Modeling Multi-relational Data&#125;,
 url &#x3D; &#123;https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper_files&#x2F;paper&#x2F;2013&#x2F;file&#x2F;1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf&#125;,
 volume &#x3D; &#123;26&#125;,
 year &#x3D; &#123;2013&#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/06-TransE.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/06-TransE.pdf</a> .</p>
<h2 id="TransH"><a href="#TransH" class="headerlink" title="TransH"></a>TransH</h2><p>论文: Knowledge Graph Embedding by Translating on Hyperplanes .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>We deal with embedding a large scale knowledge graph composed of entities and relations into a continuous vector space. TransE is a promising method proposed recently, which is very efficient while achieving state-of-the-art predictive performance. We discuss some mapping properties of relations which should be considered in embedding, such as reflexive, one-to-many, many-to-one, and many-to-many. We note that TransE does not do well in dealing with these properties. Some complex models are capable of preserving these mapping properties but sacrifice efficiency in the process. To make a good trade-off between model capacity and efficiency, in this paper we propose TransH which models a relation as a hyperplane together with a translation operation on it. In this way, we can well preserve the above mapping properties of relations with almost the same model complexity of TransE. Additionally, as a practical knowledge graph is often far from completed, how to construct negative examples to reduce false negative labels in training is very important. Utilizing the one-to-many&#x2F;many-to-one mapping property of a relation, we propose a simple trick to reduce the possibility of false negative labeling. We conduct extensive experiments on link prediction, triplet classification and fact extraction on benchmark datasets like WordNet and Freebase. Experiments show TransH delivers significant improvements over TransE on predictive accuracy with comparable capability to scale up.</p>
</blockquote>
<p>论文地址: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/8870">https://ojs.aaai.org/index.php/AAAI/article/view/8870</a> .</p>
<p>PDF 地址: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/8870/8729">https://ojs.aaai.org/index.php/AAAI/article/view/8870/8729</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">Wang, Z., Zhang, J., Feng, J., &amp; Chen, Z. (2014). Knowledge Graph Embedding by Translating on Hyperplanes. Proceedings of the AAAI Conference on Artificial Intelligence, 28(1). https:&#x2F;&#x2F;doi.org&#x2F;10.1609&#x2F;aaai.v28i1.8870<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/07-TransH.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/07-TransH.pdf</a> .</p>
<h2 id="DistMult"><a href="#DistMult" class="headerlink" title="DistMult"></a>DistMult</h2><p>论文: Embedding Entities and Relations for Learning and Inference in Knowledge Bases .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>We consider learning representations of entities and relations in KBs using the neural-embedding approach. We show that most existing models, including NTN (Socher et al., 2013) and TransE (Bordes et al., 2013b), can be generalized under a unified learning framework, where entities are low-dimensional vectors learned from a neural network and relations are bilinear and&#x2F;or linear mapping functions. Under this framework, we compare a variety of embedding models on the link prediction task. We show that a simple bilinear formulation achieves new state-of-the-art results for the task (achieving a top-10 accuracy of 73.2% vs. 54.7% by TransE on Freebase). Furthermore, we introduce a novel approach that utilizes the learned relation embeddings to mine logical rules such as “BornInCity(a,b) and CityInCountry(b,c) &#x3D;&gt; Nationality(a,c)”. We find that embeddings learned from the bilinear objective are particularly good at capturing relational semantics and that the composition of relations is characterized by matrix multiplication. More interestingly, we demonstrate that our embedding-based rule extraction approach successfully outperforms a state-of-the-art confidence-based rule mining approach in mining Horn rules that involve compositional reasoning.</p>
</blockquote>
<p>论文地址: <a href="https://arxiv.org/abs/1412.6575">https://arxiv.org/abs/1412.6575</a> .</p>
<p>PDF 地址: <a href="https://arxiv.org/pdf/1412.6575.pdf">https://arxiv.org/pdf/1412.6575.pdf</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">@misc&#123;yang2015embedding,
      title&#x3D;&#123;Embedding Entities and Relations for Learning and Inference in Knowledge Bases&#125;, 
      author&#x3D;&#123;Bishan Yang and Wen-tau Yih and Xiaodong He and Jianfeng Gao and Li Deng&#125;,
      year&#x3D;&#123;2015&#125;,
      eprint&#x3D;&#123;1412.6575&#125;,
      archivePrefix&#x3D;&#123;arXiv&#125;,
      primaryClass&#x3D;&#123;cs.CL&#125;
&#125;

Yang BS，Yih S，He XD，et al．Embedding entities and relations for learning and inference in knowledge bases[C]&#x2F;&#x2F;Proceedings of ICLR．2015．http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;1412.6575．<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/04-DistMult.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/04-DistMult.pdf</a> .</p>
<h2 id="TransR"><a href="#TransR" class="headerlink" title="TransR"></a>TransR</h2><p>论文: Learning Entity and Relation Embeddings for Knowledge Graph Completion .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Knowledge graph completion aims to perform link prediction between entities. In this paper, we consider the approach of knowledge graph embeddings. Recently, models such as TransE and TransH build entity and relation embeddings by regarding a relation as translation from head entity to tail entity. We note that these models simply put both entities and relations within the same semantic space. In fact, an entity may have multiple aspects and various relations may focus on different aspects of entities, which makes a common space insufficient for modeling. In this paper, we propose TransR to build entity and relation embeddings in separate entity space and relation spaces. Afterwards, we learn embeddings by first projecting entities from entity space to corresponding relation space and then building translations between projected entities. In experiments, we evaluate our models on three tasks including link prediction, triple classification and relational fact extraction. Experimental results show significant and consistent improvements compared to state-of-the-art baselines including TransE and TransH. The source code of this paper can be obtained from <a href="https://github.com/mrlyk423/relation_extraction">https://github.com/mrlyk423/relation_extraction</a>.</p>
</blockquote>
<p>论文地址: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/9491">https://ojs.aaai.org/index.php/AAAI/article/view/9491</a> .</p>
<p>PDF 地址: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/9491/9350">https://ojs.aaai.org/index.php/AAAI/article/view/9491/9350</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">Lin, Y., Liu, Z., Sun, M., Liu, Y., &amp; Zhu, X. (2015). Learning Entity and Relation Embeddings for Knowledge Graph Completion. Proceedings of the AAAI Conference on Artificial Intelligence, 29(1). https:&#x2F;&#x2F;doi.org&#x2F;10.1609&#x2F;aaai.v29i1.9491<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/03-TransR.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/03-TransR.pdf</a> .</p>
<h2 id="TransD"><a href="#TransD" class="headerlink" title="TransD"></a>TransD</h2><p>论文: Knowledge Graph Embedding via Dynamic Mapping Matrix .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Knowledge graphs are useful resources for numerous AI applications, but they are far from completeness. Previous work such as TransE, TransH and TransR&#x2F;CTransR regard a relation as translation from head entity to tail entity and the CTransR achieves state-of-the-art performance. In this paper, we propose a more fine-grained model named TransD, which is an improvement of TransR&#x2F;CTransR. In TransD, we use two vectors to represent a named symbol object (entity and relation). The first one represents the meaning of a(n) entity (relation), the other one is used to construct mapping matrix dynamically. Compared with TransR&#x2F;CTransR, TransD not only considers the diversity of relations, but also entities. TransD has less parameters and has no matrix-vector multiplication operations, which makes it can be applied on large scale graphs. In Experiments, we evaluate our model on two typical tasks including triplets classification and link prediction. Evaluation results show that our approach outperforms state-of-the-art methods.</p>
</blockquote>
<p>论文地址: <a href="https://aclanthology.org/P15-1067/">https://aclanthology.org/P15-1067/</a> .</p>
<p>PDF 地址: <a href="https://aclanthology.org/P15-1067.pdf">https://aclanthology.org/P15-1067.pdf</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">@inproceedings&#123;ji-etal-2015-knowledge,
    title &#x3D; &quot;Knowledge Graph Embedding via Dynamic Mapping Matrix&quot;,
    author &#x3D; &quot;Ji, Guoliang  and
      He, Shizhu  and
      Xu, Liheng  and
      Liu, Kang  and
      Zhao, Jun&quot;,
    booktitle &#x3D; &quot;Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)&quot;,
    month &#x3D; jul,
    year &#x3D; &quot;2015&quot;,
    address &#x3D; &quot;Beijing, China&quot;,
    publisher &#x3D; &quot;Association for Computational Linguistics&quot;,
    url &#x3D; &quot;https:&#x2F;&#x2F;aclanthology.org&#x2F;P15-1067&quot;,
    doi &#x3D; &quot;10.3115&#x2F;v1&#x2F;P15-1067&quot;,
    pages &#x3D; &quot;687--696&quot;,
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/08-TransD.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/08-TransD.pdf</a> .</p>
<h2 id="HolE"><a href="#HolE" class="headerlink" title="HolE"></a>HolE</h2><p>论文: Holographic Embeddings of Knowledge Graphs .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Learning embeddings of entities and relations is an efficient and versatile method to perform machine learning on relational data such as knowledge graphs. In this work, we propose holographic embeddings (HolE) to learn compositional vector space representations of entire knowledge graphs. The proposed method is related to holographic models of associative memory in that it employs circular correlation to create compositional representations. By using correlation as the compositional operator, HolE can capture rich interactions but simultaneously remains efficient to compute, easy to train, and scalable to very large datasets. Experimentally, we show that holographic embeddings are able to outperform state-of-the-art methods for link prediction on knowledge graphs and relational learning benchmark datasets.</p>
</blockquote>
<p>论文地址: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/10314">https://ojs.aaai.org/index.php/AAAI/article/view/10314</a> .</p>
<p>PDF 地址: <a href="https://ojs.aaai.org/index.php/AAAI/article/view/10314/10173">https://ojs.aaai.org/index.php/AAAI/article/view/10314/10173</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">Nickel, M., Rosasco, L., &amp; Poggio, T. (2016). Holographic Embeddings of Knowledge Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 30(1). https:&#x2F;&#x2F;doi.org&#x2F;10.1609&#x2F;aaai.v30i1.10314<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/12-HolE.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/12-HolE.pdf</a> .</p>
<h2 id="ComplEx"><a href="#ComplEx" class="headerlink" title="ComplEx"></a>ComplEx</h2><p>论文: Complex Embeddings for Simple Link Prediction .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>In statistical relational learning, the link prediction problem is key to automatically understand the structure of large knowledge bases. As in previous studies, we propose to solve this problem through latent factorization. However, here we make use of complex valued embeddings. The composition of complex embeddings can handle a large variety of binary relations, among them symmetric and antisymmetric relations. Compared to state-of-the-art models such as Neural Tensor Network and Holographic Embeddings, our approach based on complex embeddings is arguably simpler, as it only uses the Hermitian dot product, the complex counterpart of the standard dot product between real vectors. Our approach is scalable to large datasets as it remains linear in both space and time, while consistently outperforming alternative approaches on standard link prediction benchmarks.</p>
</blockquote>
<p>论文地址: <a href="https://arxiv.org/abs/1606.06357">https://arxiv.org/abs/1606.06357</a> .</p>
<p>PDF 地址: <a href="https://arxiv.org/pdf/1606.06357.pdf">https://arxiv.org/pdf/1606.06357.pdf</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">Complex Embeddings for Simple Link Prediction, Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier and Guillaume Bouchard, ICML 2016.

@inproceedings&#123;trouillon2016complex,
	title &#x3D; &#123;&#123;Complex embeddings for simple link prediction&#125;&#125;,
	author &#x3D; &#123;Trouillon, Th\&#39;eo and Welbl, Johannes and Riedel, Sebastian and Gaussier, \&#39;Eric and Bouchard, Guillaume&#125;,
	booktitle &#x3D; &#123;International Conference on Machine Learning (ICML)&#125;,
	volume&#x3D;&#123;48&#125;,
	pages&#x3D;&#123;2071--2080&#125;,
	year &#x3D; &#123;2016&#125;
&#125;

@misc&#123;trouillon2016complex,
      title&#x3D;&#123;Complex Embeddings for Simple Link Prediction&#125;, 
      author&#x3D;&#123;Théo Trouillon and Johannes Welbl and Sebastian Riedel and Éric Gaussier and Guillaume Bouchard&#125;,
      year&#x3D;&#123;2016&#125;,
      eprint&#x3D;&#123;1606.06357&#125;,
      archivePrefix&#x3D;&#123;arXiv&#125;,
      primaryClass&#x3D;&#123;cs.AI&#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/05-ComplEx.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/05-ComplEx.pdf</a> .</p>
<h2 id="R-GCN"><a href="#R-GCN" class="headerlink" title="R-GCN"></a>R-GCN</h2><p>论文: Modeling Relational Data with Graph Convolutional Networks .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Knowledge graphs enable a wide variety of applications, including question answering and information retrieval. Despite the great effort invested in their creation and maintenance, even the largest (e.g., Yago, DBPedia or Wikidata) remain incomplete. We introduce Relational Graph Convolutional Networks (R-GCNs) and apply them to two standard knowledge base completion tasks: Link prediction (recovery of missing facts, i.e. subject-predicate-object triples) and entity classification (recovery of missing entity attributes). R-GCNs are related to a recent class of neural networks operating on graphs, and are developed specifically to deal with the highly multi-relational data characteristic of realistic knowledge bases. We demonstrate the effectiveness of R-GCNs as a stand-alone model for entity classification. We further show that factorization models for link prediction such as DistMult can be significantly improved by enriching them with an encoder model to accumulate evidence over multiple inference steps in the relational graph, demonstrating a large improvement of 29.8% on FB15k-237 over a decoder-only baseline.</p>
</blockquote>
<p>论文地址: </p>
<ol>
<li><a href="https://arxiv.org/abs/1703.06103">https://arxiv.org/abs/1703.06103</a> .</li>
</ol>
<p>PDF 地址: </p>
<ol>
<li><a href="https://arxiv.org/pdf/1703.06103.pdf">https://arxiv.org/pdf/1703.06103.pdf</a> .</li>
</ol>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/23-R-GCN.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/23-R-GCN.pdf</a> .</p>
<h2 id="ANALOGY"><a href="#ANALOGY" class="headerlink" title="ANALOGY"></a>ANALOGY</h2><p>论文: Analogical Inference for Multi-relational Embeddings .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledge-based inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the analogical properties of the embedded entities and relations. By formulating the objective function in a differentiable fashion, our model enjoys both its theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.</p>
</blockquote>
<p>论文地址: </p>
<ol>
<li><p><a href="https://proceedings.mlr.press/v70/liu17d.html">https://proceedings.mlr.press/v70/liu17d.html</a> .</p>
</li>
<li><p><a href="https://arxiv.org/abs/1705.02426">https://arxiv.org/abs/1705.02426</a> .</p>
</li>
</ol>
<p>PDF 地址: </p>
<ol>
<li><p><a href="http://proceedings.mlr.press/v70/liu17d/liu17d.pdf">http://proceedings.mlr.press/v70/liu17d/liu17d.pdf</a> .</p>
</li>
<li><p><a href="https://arxiv.org/pdf/1705.02426.pdf">https://arxiv.org/pdf/1705.02426.pdf</a> .</p>
</li>
</ol>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">Hanxiao Liu, Yuexin Wu, Yiming Yang Proceedings of the 34th International Conference on Machine Learning, PMLR 70:2168-2178, 2017.


@InProceedings&#123;pmlr-v70-liu17d,
  title &#x3D; 	 &#123;Analogical Inference for Multi-relational Embeddings&#125;,
  author &#x3D;       &#123;Hanxiao Liu and Yuexin Wu and Yiming Yang&#125;,
  booktitle &#x3D; 	 &#123;Proceedings of the 34th International Conference on Machine Learning&#125;,
  pages &#x3D; 	 &#123;2168--2178&#125;,
  year &#x3D; 	 &#123;2017&#125;,
  editor &#x3D; 	 &#123;Precup, Doina and Teh, Yee Whye&#125;,
  volume &#x3D; 	 &#123;70&#125;,
  series &#x3D; 	 &#123;Proceedings of Machine Learning Research&#125;,
  month &#x3D; 	 &#123;06--11 Aug&#125;,
  publisher &#x3D;    &#123;PMLR&#125;,
  pdf &#x3D; 	 &#123;http:&#x2F;&#x2F;proceedings.mlr.press&#x2F;v70&#x2F;liu17d&#x2F;liu17d.pdf&#125;,
  url &#x3D; 	 &#123;https:&#x2F;&#x2F;proceedings.mlr.press&#x2F;v70&#x2F;liu17d.html&#125;,
  abstract &#x3D; 	 &#123;Large-scale multi-relational embedding refers to the task of learning the latent representations for entities and relations in large knowledge graphs. An effective and scalable solution for this problem is crucial for the true success of knowledge-based inference in a broad range of applications. This paper proposes a novel framework for optimizing the latent representations with respect to the &lt;em&gt;analogical&lt;&#x2F;em&gt; properties of the embedded entities and relations. By formulating the objective function in a differentiable fashion, our model enjoys both its theoretical power and computational scalability, and significantly outperformed a large number of representative baseline methods on benchmark datasets. Furthermore, the model offers an elegant unification of several well-known methods in multi-relational embedding, which can be proven to be special instantiations of our framework.&#125;
&#125;

@misc&#123;liu2017analogical,
      title&#x3D;&#123;Analogical Inference for Multi-Relational Embeddings&#125;, 
      author&#x3D;&#123;Hanxiao Liu and Yuexin Wu and Yiming Yang&#125;,
      year&#x3D;&#123;2017&#125;,
      eprint&#x3D;&#123;1705.02426&#125;,
      archivePrefix&#x3D;&#123;arXiv&#125;,
      primaryClass&#x3D;&#123;cs.LG&#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/11-ANALOGY.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/11-ANALOGY.pdf</a> .</p>
<h2 id="SimplE"><a href="#SimplE" class="headerlink" title="SimplE"></a>SimplE</h2><p>论文: SimplE Embedding for Link Prediction in Knowledge Graphs .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Knowledge graphs contain knowledge about the world and provide a structured representation of this knowledge. Current knowledge graphs contain only a small subset of what is true in the world. Link prediction approaches aim at predicting new links for a knowledge graph given the existing links among the entities. Tensor factorization approaches have proved promising for such link prediction problems. Proposed in 1927, Canonical Polyadic (CP) decomposition is among the first tensor factorization approaches. CP generally performs poorly for link prediction as it learns two independent embedding vectors for each entity, whereas they are really tied. We present a simple enhancement of CP (which we call SimplE) to allow the two embeddings of each entity to be learned dependently. The complexity of SimplE grows linearly with the size of embeddings. The embeddings learned through SimplE are interpretable, and certain types of background knowledge can be incorporated into these embeddings through weight tying. We prove SimplE is fully expressive and derive a bound on the size of its embeddings for full expressivity. We show empirically that, despite its simplicity, SimplE outperforms several state-of-the-art tensor factorization techniques. SimplE’s code is available on GitHub at <a href="https://github.com/Mehran-k/SimplE">https://github.com/Mehran-k/SimplE</a>.</p>
</blockquote>
<p>论文地址: <a href="https://proceedings.neurips.cc/paper_files/paper/2018/hash/b2ab001909a8a6f04b51920306046ce5-Abstract.html">https://proceedings.neurips.cc/paper_files/paper/2018/hash/b2ab001909a8a6f04b51920306046ce5-Abstract.html</a> .</p>
<p>PDF 地址: </p>
<ol>
<li><p><a href="https://www.cs.ubc.ca/~poole/papers/Kazemi_Poole_SimplE_NIPS_2018.pdf">https://www.cs.ubc.ca/~poole/papers/Kazemi_Poole_SimplE_NIPS_2018.pdf</a> .</p>
</li>
<li><p><a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/b2ab001909a8a6f04b51920306046ce5-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2018/file/b2ab001909a8a6f04b51920306046ce5-Paper.pdf</a> .</p>
</li>
</ol>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">@inproceedings&#123;NEURIPS2018_b2ab0019,
 author &#x3D; &#123;Kazemi, Seyed Mehran and Poole, David&#125;,
 booktitle &#x3D; &#123;Advances in Neural Information Processing Systems&#125;,
 editor &#x3D; &#123;S. Bengio and H. Wallach and H. Larochelle and K. Grauman and N. Cesa-Bianchi and R. Garnett&#125;,
 pages &#x3D; &#123;&#125;,
 publisher &#x3D; &#123;Curran Associates, Inc.&#125;,
 title &#x3D; &#123;SimplE Embedding for Link Prediction in Knowledge Graphs&#125;,
 url &#x3D; &#123;https:&#x2F;&#x2F;proceedings.neurips.cc&#x2F;paper_files&#x2F;paper&#x2F;2018&#x2F;file&#x2F;b2ab001909a8a6f04b51920306046ce5-Paper.pdf&#125;,
 volume &#x3D; &#123;31&#125;,
 year &#x3D; &#123;2018&#125;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/10-SimplE.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/10-SimplE.pdf</a> .</p>
<h2 id="RotatE"><a href="#RotatE" class="headerlink" title="RotatE"></a>RotatE</h2><p>论文: RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry&#x2F;antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.</p>
</blockquote>
<p>论文地址: <a href="https://openreview.net/forum?id=HkgEQnRqYQ">https://openreview.net/forum?id=HkgEQnRqYQ</a> .</p>
<p>PDF 地址: <a href="https://openreview.net/pdf?id=HkgEQnRqYQ">https://openreview.net/pdf?id=HkgEQnRqYQ</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">@inproceedings&#123;
sun2018rotate,
title&#x3D;&#123;RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space&#125;,
author&#x3D;&#123;Zhiqing Sun and Zhi-Hong Deng and Jian-Yun Nie and Jian Tang&#125;,
booktitle&#x3D;&#123;International Conference on Learning Representations&#125;,
year&#x3D;&#123;2019&#125;,
url&#x3D;&#123;https:&#x2F;&#x2F;openreview.net&#x2F;forum?id&#x3D;HkgEQnRqYQ&#125;,
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/02-RotatE.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/02-RotatE.pdf</a> .</p>
<h2 id="KBGAT"><a href="#KBGAT" class="headerlink" title="KBGAT"></a>KBGAT</h2><p>论文: Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the local neighborhood surrounding a triple. To this effect, our paper proposes a novel attention-based feature embedding that captures both entity and relation features in any given entity’s neighborhood. Additionally, we also encapsulate relation clusters and multi-hop relations in our model. Our empirical study offers insights into the efficacy of our attention-based model and we show marked performance gains in comparison to state-of-the-art methods on all datasets.</p>
</blockquote>
<p>论文地址: <a href="https://aclanthology.org/P19-1466/">https://aclanthology.org/P19-1466/</a> .</p>
<p>PDF 地址: <a href="https://aclanthology.org/P19-1466.pdf">https://aclanthology.org/P19-1466.pdf</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/24-KBGAT.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/24-KBGAT.pdf</a> .</p>
<h2 id="CompGCN"><a href="#CompGCN" class="headerlink" title="CompGCN"></a>CompGCN</h2><p>论文: Composition-based Multi-Relational Graph Convolutional Networks .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Graph Convolutional Networks (GCNs) have recently been shown to be quite successful in modeling graph-structured data. However, the primary focus has been on handling simple undirected graphs. Multi-relational graphs are a more general and prevalent form of graphs where each edge has a label and direction associated with it. Most of the existing approaches to handle such graphs suffer from over-parameterization and are restricted to learning representations of nodes only. In this paper, we propose CompGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph. CompGCN leverages a variety of entity-relation composition operations from Knowledge Graph Embedding techniques and scales with the number of relations. It also generalizes several of the existing multi-relational GCN methods. We evaluate our proposed method on multiple tasks such as node classification, link prediction, and graph classification, and achieve demonstrably superior results. We make the source code of CompGCN available to foster reproducible research.</p>
</blockquote>
<p>论文地址: <a href="https://openreview.net/forum?id=BylA_C4tPr">https://openreview.net/forum?id=BylA_C4tPr</a> .</p>
<p>PDF 地址: <a href="https://openreview.net/pdf?id=BylA_C4tPr">https://openreview.net/pdf?id=BylA_C4tPr</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/25-CompGCN.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/25-CompGCN.pdf</a> .</p>
<h2 id="OpenKE"><a href="#OpenKE" class="headerlink" title="OpenKE"></a>OpenKE</h2><p>论文: OpenKE: An Open Toolkit for Knowledge Embedding .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>We release an open toolkit for knowledge embedding (OpenKE), which provides a unified framework and various fundamental models to embed knowledge graphs into a continuous low-dimensional space. OpenKE prioritizes operational efficiency to support quick model validation and large-scale knowledge representation learning. Meanwhile, OpenKE maintains sufficient modularity and extensibility to easily incorporate new models into the framework. Besides the toolkit, the embeddings of some existing large-scale knowledge graphs pre-trained by OpenKE are also available, which can be directly applied for many applications including information retrieval, personalized recommendation and question answering. The toolkit, documentation, and pre-trained embeddings are all released on <a href="http://openke.thunlp.org/">http://openke.thunlp.org/</a>.</p>
</blockquote>
<p>论文地址: <a href="https://aclanthology.org/D18-2024/">https://aclanthology.org/D18-2024/</a> .</p>
<p>PDF 地址: <a href="https://aclanthology.org/D18-2024.pdf">https://aclanthology.org/D18-2024.pdf</a> .</p>
<pre class="line-numbers language-BibTex" data-language="BibTex"><code class="language-BibTex">@inproceedings&#123;han-etal-2018-openke,
    title &#x3D; &quot;&#123;O&#125;pen&#123;KE&#125;: An Open Toolkit for Knowledge Embedding&quot;,
    author &#x3D; &quot;Han, Xu  and
      Cao, Shulin  and
      Lv, Xin  and
      Lin, Yankai  and
      Liu, Zhiyuan  and
      Sun, Maosong  and
      Li, Juanzi&quot;,
    booktitle &#x3D; &quot;Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations&quot;,
    month &#x3D; nov,
    year &#x3D; &quot;2018&quot;,
    address &#x3D; &quot;Brussels, Belgium&quot;,
    publisher &#x3D; &quot;Association for Computational Linguistics&quot;,
    url &#x3D; &quot;https:&#x2F;&#x2F;aclanthology.org&#x2F;D18-2024&quot;,
    doi &#x3D; &quot;10.18653&#x2F;v1&#x2F;D18-2024&quot;,
    pages &#x3D; &quot;139--144&quot;,
    abstract &#x3D; &quot;We release an open toolkit for knowledge embedding (OpenKE), which provides a unified framework and various fundamental models to embed knowledge graphs into a continuous low-dimensional space. OpenKE prioritizes operational efficiency to support quick model validation and large-scale knowledge representation learning. Meanwhile, OpenKE maintains sufficient modularity and extensibility to easily incorporate new models into the framework. Besides the toolkit, the embeddings of some existing large-scale knowledge graphs pre-trained by OpenKE are also available, which can be directly applied for many applications including information retrieval, personalized recommendation and question answering. The toolkit, documentation, and pre-trained embeddings are all released on \url&#123;http:&#x2F;&#x2F;openke.thunlp.org&#x2F;&#125;.&quot;,
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/01-OpenKE.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/01-OpenKE.pdf</a> .</p>
<h2 id="Pykg2vec"><a href="#Pykg2vec" class="headerlink" title="Pykg2vec"></a>Pykg2vec</h2><p>论文: Pykg2vec: A Python Library for Knowledge Graph Embedding .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Pykg2vec is a Python library for learning the representations of the entities and relations in knowledge graphs. Pykg2vec’s flexible and modular software architecture currently implements 25 state-of-the-art knowledge graph embedding algorithms, and is designed to easily incorporate new algorithms.The goal of pykg2vec is to provide a practical and educational platform to accelerate research in knowledge graph representation learning. Pykg2vec is built on top of PyTorch and Python’s multiprocessing framework and provides modules for batch generation, Bayesian hyperparameter optimization, evaluation of KGE tasks, embedding, and result visualization. Pykg2vec is released under the MIT License and is also available in the Python Package Index (PyPI). The source code of pykg2vec is available at <a href="https://github.com/Sujit-O/pykg2vec">https://github.com/Sujit-O/pykg2vec</a>.</p>
</blockquote>
<p>论文地址: <a href="https://jmlr.org/papers/v22/19-433.html">https://jmlr.org/papers/v22/19-433.html</a> .</p>
<p>PDF 地址: <a href="https://jmlr.org/papers/volume22/19-433/19-433.pdf">https://jmlr.org/papers/volume22/19-433/19-433.pdf</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/16-Pykg2vec.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/16-Pykg2vec.pdf</a> .</p>
<h2 id="PyKEEN-1-0"><a href="#PyKEEN-1-0" class="headerlink" title="PyKEEN 1.0"></a>PyKEEN 1.0</h2><p>论文: PyKEEN 1.0: A Python Library for Training and Evaluating Knowledge Graph Embeddings .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Recently, knowledge graph embeddings (KGEs) have received significant attention, and several software libraries have been developed for training and evaluation. While each of them addresses specific needs, we report on a community effort to a re-design and re-implementation of PyKEEN, one of the early KGE libraries. PyKEEN 1.0 enables users to compose knowledge graph embedding models based on a wide range of interaction models, training approaches, loss functions, and permits the explicit modeling of inverse relations. It allows users to measure each component’s influence individually on the model’s performance. Besides, an automatic memory optimization has been realized in order to optimally exploit the provided hardware. Through the integration of Optuna, extensive hyper-parameter optimization (HPO) functionalities are provided.</p>
</blockquote>
<p>论文地址: <a href="https://jmlr.org/papers/v22/20-825.html">https://jmlr.org/papers/v22/20-825.html</a> .</p>
<p>PDF 地址: <a href="https://jmlr.org/papers/volume22/20-825/20-825.pdf">https://jmlr.org/papers/volume22/20-825/20-825.pdf</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/15-PyKEEN.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/15-PyKEEN.pdf</a> .</p>
<h2 id="CogKGE"><a href="#CogKGE" class="headerlink" title="CogKGE"></a>CogKGE</h2><p>论文: CogKGE: A Knowledge Graph Embedding Toolkit and Benchmark for Representing Multi-source and Heterogeneous Knowledge .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>In this paper, we propose CogKGE, a knowledge graph embedding (KGE) toolkit, which aims to represent multi-source and heterogeneous knowledge. For multi-source knowledge, unlike existing methods that mainly focus on entity-centric knowledge, CogKGE also supports the representations of event-centric, commonsense and linguistic knowledge. For heterogeneous knowledge, besides structured triple facts, CogKGE leverages additional unstructured information, such as text descriptions, node types and temporal information, to enhance the meaning of embeddings. Designing CogKGE aims to provide a unified programming framework for KGE tasks and a series of knowledge representations for downstream tasks. As a research framework, CogKGE consists of five parts, including core, data, model, knowledge and adapter module. As a knowledge discovery toolkit, CogKGE provides pre-trained embedders to discover new facts, cluster entities and check facts. Furthermore, we construct two benchmark datasets for further research on multi-source heterogeneous KGE tasks: EventKG240K and CogNet360K. We also release an online system to discover knowledge visually. Source code, datasets and pre-trained embeddings are publicly available at GitHub, with a short instruction video.</p>
</blockquote>
<p>论文地址: <a href="https://aclanthology.org/2022.acl-demo.16/">https://aclanthology.org/2022.acl-demo.16/</a> .</p>
<p>PDF 地址: <a href="https://aclanthology.org/2022.acl-demo.16.pdf">https://aclanthology.org/2022.acl-demo.16.pdf</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/13-CogKGE.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/13-CogKGE.pdf</a> .</p>
<h2 id="NeuralKG"><a href="#NeuralKG" class="headerlink" title="NeuralKG"></a>NeuralKG</h2><p>论文: NeuralKG: An Open Source Library for Diverse Representation Learning of Knowledge Graphs .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>NeuralKG is an open-source Python-based library for diverse representation learning of knowledge graphs. It implements three different series of Knowledge Graph Embedding (KGE) methods, including conventional KGEs, GNN-based KGEs, and Rule-based KGEs. With a unified framework, NeuralKG successfully reproduces link prediction results of these methods on benchmarks, freeing users from the laborious task of reimplementing them, especially for some methods originally written in non-python programming languages. Besides, NeuralKG is highly configurable and extensible. It provides various decoupled modules that can be mixed and adapted to each other. Thus with NeuralKG, developers and researchers can quickly implement their own designed models and obtain the optimal training methods to achieve the best performance efficiently. We built an website in this http URL to organize an open and shared KG representation learning community. The source code is all publicly released at this https URL.</p>
</blockquote>
<p>论文地址: <a href="https://arxiv.org/abs/2202.12571">https://arxiv.org/abs/2202.12571</a> .</p>
<p>PDF 地址: <a href="https://arxiv.org/pdf/2202.12571.pdf">https://arxiv.org/pdf/2202.12571.pdf</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/14-NeuralKG.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/14-NeuralKG.pdf</a> .</p>
<h2 id="中文综述-哈尔滨理工大学"><a href="#中文综述-哈尔滨理工大学" class="headerlink" title="中文综述-哈尔滨理工大学"></a>中文综述-哈尔滨理工大学</h2><p>论文: 知识图谱嵌入技术研究进展 .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>知识图谱嵌入（KGE）是知识图谱领域一个新的研究热点，旨在利用词向量的平移不变性将知识图谱中实体和关系嵌入到低维向量空间，进而完成知识表示。以解决实际问题的类型为划分依据，首先，阐述了四类主要的知识图谱嵌入方法，包括基于深度学习的方法、基于图形特征的方法、基于翻译模型的方法以及基于其他模型的方法，对每种模型的算法思想进行详细阐述，总结了每种模型的优缺点；其次，从常用数据集、评价指标、算法、实验四方面对知识图谱嵌入算法实验进行分析与归纳，对嵌入方法做了横纵向对比；最后，从解决实际问题的角度出发，给出了知识图谱嵌入技术未来的发展方向。通过研究，发现在基于深度学习的方法中，LCPE模型的效果最好；在基于图形特征的方法中，TCE模型的效果最好；在基于翻译模型的方法中，NTransGH模型的效果最好。今后的研究可以在LCPE、TCE、NTransGH的基础上进行拓展，不断提高链接预测和三元组分类的实验效果。</p>
</blockquote>
<p>论文地址: <a href="http://fcst.ceaj.org/CN/10.3778/j.issn.1673-9418.2103086">http://fcst.ceaj.org/CN/10.3778/j.issn.1673-9418.2103086</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/17-zh-review.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/17-zh-review.pdf</a> .</p>
<h2 id="中文综述-哈尔滨工业大学"><a href="#中文综述-哈尔滨工业大学" class="headerlink" title="中文综述-哈尔滨工业大学"></a>中文综述-哈尔滨工业大学</h2><p>论文: 面向知识图谱的图嵌入学习研究进展 .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>知识图谱是一种用网络结构存储知识的知识库, 在知识图谱中, 单条知识被表示成三元组的形式, 即(头实体, 关系, 尾实体). 得力于知识图谱在各个领域的广泛应用, 面向知识图谱的图嵌入学习也得到越来越多研究人员的关注. 面向知识图谱的图嵌入学习任务旨在为图谱中的实体与关系学习低维且稠密的向量, 通过图嵌入向量表达实体与关系的语义信息以及度量实体之间、关系之间、实体与关系之间的语义联系, 已有许多研究证明图嵌入模型在下游任务中的有效性. 近年来, 越来越多研究人员开始关注知识图谱的图嵌入学习, 并取得大量的研究成果, 尝试将图嵌入算法分成了基于转移思想、基于张量分解、基于传统深度学习模型、基于图神经网络以及融入额外信息的图嵌入学习共5大类, 梳理、介绍各类图嵌入算法的设计思路、算法特征以及优缺点, 以帮助指导初步接触该领域的研究人员快速学习了解该研究领域的相关模型和算法.</p>
</blockquote>
<p>论文地址: <a href="http://www.jos.org.cn/jos/article/abstract/6426">http://www.jos.org.cn/jos/article/abstract/6426</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/18-zh-survey.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/18-zh-survey.pdf</a> .</p>
<h2 id="Review-University-of-North-Dakota"><a href="#Review-University-of-North-Dakota" class="headerlink" title="Review-University-of-North-Dakota"></a>Review-University-of-North-Dakota</h2><p>论文: A Review of Knowledge Graph Completion .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Information extraction methods proved to be effective at triple extraction from structured or unstructured data. The organization of such triples in the form of (head entity, relation, tail entity) is called the construction of Knowledge Graphs (KGs). Most of the current knowledge graphs are incomplete. In order to use KGs in downstream tasks, it is desirable to predict missing links in KGs. Different approaches have been recently proposed for representation learning of KGs by embedding both entities and relations into a low-dimensional vector space aiming to predict unknown triples based on previously visited triples. According to how the triples will be treated independently or dependently, we divided the task of knowledge graph completion into conventional and graph neural network representation learning and we discuss them in more detail. In conventional approaches, each triple will be processed independently and in GNN-based approaches, triples also consider their local neighborhood.</p>
</blockquote>
<p>论文地址: <a href="https://www.mdpi.com/2078-2489/13/8/396">https://www.mdpi.com/2078-2489/13/8/396</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/19-en-review.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/19-en-review.pdf</a> .</p>
<h2 id="Review-GNN"><a href="#Review-GNN" class="headerlink" title="Review-GNN"></a>Review-GNN</h2><p>论文: A Comprehensive Survey of Graph Neural Networks for Knowledge Graphs .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>The Knowledge graph, a multi-relational graph that represents rich factual information among entities of diverse classifications, has gradually become one of the critical tools for knowledge management. However, the existing knowledge graph still has some problems which form hot research topics in recent years. Numerous methods have been proposed based on various representation techniques. Graph Neural Network, a framework that uses deep learning to process graph-structured data directly, has significantly advanced the state-of-the-art in the past few years. This study firstly is aimed at providing a broad, complete as well as comprehensive overview of GNN-based technologies for solving four different KG tasks, including link prediction, knowledge graph alignment, knowledge graph reasoning, and node classification. Further, we also investigated the related artificial intelligence applications of knowledge graphs based on advanced GNN methods, such as recommender systems, question answering, and drug-drug interaction. This review will provide new insights for further study of KG and GNN.</p>
</blockquote>
<p>论文地址: <a href="https://ieeexplore.ieee.org/abstract/document/9831453">https://ieeexplore.ieee.org/abstract/document/9831453</a> .</p>
<p>论文 PDF 地址: <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9831453">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=9831453</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/20-en-gnn-review.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/20-en-gnn-review.pdf</a> .</p>
<h2 id="Review-Northeastern-University"><a href="#Review-Northeastern-University" class="headerlink" title="Review-Northeastern-University"></a>Review-Northeastern-University</h2><p>论文: A comprehensive overview of knowledge graph completion .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>Knowledge Graph (KG) provides high-quality structured knowledge for various downstream knowledge-aware tasks (such as recommendation and intelligent question-answering) with its unique advantages of representing and managing massive knowledge. The quality and completeness of KGs largely determine the effectiveness of the downstream tasks. But in view of the incomplete characteristics of KGs, there is still a large amount of valuable knowledge is missing from the KGs. Therefore, it is necessary to improve the existing KGs to supplement the missed knowledge. Knowledge Graph Completion (KGC) is one of the popular technologies for knowledge supplement. Accordingly, there has a growing concern over the KGC technologies. Recently, there have been lots of studies focusing on the KGC field. To investigate and serve as a helpful resource for researchers to grasp the main ideas and results of KGC studies, and further highlight ongoing research in KGC, in this paper, we provide a all-round up-to-date overview of the current state-of-the-art in KGC.</p>
<p>According to the information sources used in KGC methods, we divide the existing KGC methods into two main categories: the KGC methods relying on structural information and the KGC methods using other additional information. Further, each category is subdivided into different granularity for summarizing and comparing them. Besides, the other KGC methods for KGs of special fields (including temporal KGC, commonsense KGC, and hyper-relational KGC) are also introduced. In particular, we discuss comparisons and analyses for each category in our overview. Finally, some discussions and directions for future research are provided.</p>
</blockquote>
<p>论文地址: <a href="https://www.sciencedirect.com/science/article/pii/S095070512200805X">https://www.sciencedirect.com/science/article/pii/S095070512200805X</a> .</p>
<p>论文 PDF 地址: <a href="https://www.sciencedirect.com/science/article/pii/S095070512200805X/pdfft?md5=d0a6889250719442926d4f38a7cb2899&pid=1-s2.0-S095070512200805X-main.pdf">https://www.sciencedirect.com/science/article/pii/S095070512200805X/pdfft?md5=d0a6889250719442926d4f38a7cb2899&amp;pid=1-s2.0-S095070512200805X-main.pdf</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/21-en-review.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/21-en-review.pdf</a> .</p>
<h2 id="中文综述-东北大学"><a href="#中文综述-东北大学" class="headerlink" title="中文综述-东北大学"></a>中文综述-东北大学</h2><p>论文: 知识图谱嵌入技术研究综述 .</p>
<blockquote>
<p><strong>Abstract</strong></p>
<p>知识图谱(KG)是一种用图模型来描述知识和建模事物之间关联关系的技术. 知识图谱嵌入(KGE)作为一种被广泛采用的知识表示方法, 其主要思想是将知识图谱中的实体和关系嵌入到连续的向量空间中, 用来简化操作, 同时保留KG的固有结构. 可以使得多种下游任务受益, 例如KG补全和关系提取等. 首先对现有的知识图谱嵌入技术进行全面回顾, 不仅包括使用KG中观察到的事实进行嵌入的技术, 还包括添加时间维度的动态KG嵌入方法, 以及融合多源信息的KG嵌入技术. 对相关模型从实体嵌入、关系嵌入、评分函数等方面进行分析、对比与总结. 然后简要介绍KG嵌入技术在下游任务中的典型应用, 包括问答系统、推荐系统和关系提取等. 最后阐述知识图谱嵌入面临的挑战, 对未来的研究方向进行展望.</p>
</blockquote>
<p>论文地址: <a href="http://www.jos.org.cn/jos/article/abstract/6429">http://www.jos.org.cn/jos/article/abstract/6429</a> .</p>
<hr>
<p>笔记 PDF 地址: <a href="https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/22-zh-review.pdf">https://cdn.jsdelivr.net/gh/LuYF-Lemon-love/susu-kge-papers/read/22-zh-review.pdf</a> .</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>第五十七篇博文写完，开心！！！！</p>
<p>今天，也是充满希望的一天。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">LuYF-Lemon-love</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://luyf-lemon-love.space/2023/03/17/00057-du-de-kge-lun-wen-pdf-ban-ben/">https://luyf-lemon-love.space/2023/03/17/00057-du-de-kge-lun-wen-pdf-ban-ben/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">LuYF-Lemon-love</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                                    <span class="chip bg-color">知识图谱</span>
                                </a>
                            
                                <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/">
                                    <span class="chip bg-color">知识图谱补全</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">谢谢小主！</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162303.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162220.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2023/03/17/00058-windows-za-xiang/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/016-长腿.png" class="responsive-img" alt="00058-Windows 杂项">
                        
                        <span class="card-title">00058-Windows 杂项</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2023-03-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%9D%82%E9%A1%B9/" class="post-category">
                                    杂项
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Windows/">
                        <span class="chip bg-color">Windows</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2023/03/11/00056-python-biao-zhun-ku-xi-lie-xue-xi-bi-ji-windows10/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/008-119961999.jpg" class="responsive-img" alt="00056-Python 语法和标准库系列学习笔记">
                        
                        <span class="card-title">00056-Python 语法和标准库系列学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2023-03-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Python/" class="post-category">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022-2024</span>
            
            <a href="/about" target="_blank">LuYF-Lemon-love</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "5";
                        var startDate = "7";
                        var startHour = "4";
                        var startMinute = "53";
                        var startSecond = "32";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
                <span id="icp"><img src="/medias/icp.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="https://beian.miit.gov.cn" target="_blank">冀ICP备2022012632号-1</a>
            </span>
            
            <br>
            
                <span id="gongan"><img src="https://cos.luyf-lemon-love.space/images/备案图标.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32011502011618" target="_blank">苏公网安备 32011502011618号</a>
            </span>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/LuYF-Lemon-love" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:luyanfeng_nlp@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
