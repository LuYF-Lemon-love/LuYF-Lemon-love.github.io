<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="00254 NLP Course - Fast tokenizers in the QA pipeline, NLP LLM DeepLearning LuYF-Lemon-love 自然语言处理 深度学习 大语言模型">
    <meta name="description" content="前言我们现在将深入问答管道，看看如何利用偏移量从上下文中抓取手头问题的答案，就像我们在上一节中对分组实体所做的那样。然后，我们将了解如何处理被截断的非常长的上下文。如果你对问答任务不感兴趣，可以跳过这一节。
src link: https:">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>00254 NLP Course - Fast tokenizers in the QA pipeline | LuYF-Lemon-love の Blog</title>
    <link rel="icon" type="image/jpeg" href="https://cos.luyf-lemon-love.space/images/苏苏1.jpeg">
    
    <style>
        body{
            background-image: url(https://cos.luyf-lemon-love.space/images/016-%E6%8A%A5%E7%BA%B8%E5%A2%99%E9%BA%BB%E8%A1%A3%E5%AD%A6%E5%A7%90.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <span class="logo-span">LuYF-Lemon-love の Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>List</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/galleries">
          
          <i class="fas fa-image" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Image</span>
        </a>
      </li>
      
      <li>
        <a href="/verse">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Verse</span>
        </a>
      </li>
      
      <li>
        <a href="/bilibili">
          
          <i class="fas fa-video" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Bilibili</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <div class="logo-name">LuYF-Lemon-love の Blog</div>
        <div class="logo-desc">
            
            天之道，损有余而补不足，人之道则不然，损不足以奉有余。
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			List
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/galleries " style="margin-left:75px">
				  
				   <i class="fa fas fa-image" style="position: absolute;left:50px" ></i>
			      
		          <span>Image</span>
                  </a>
                </li>
              
                <li>

                  <a href="/verse " style="margin-left:75px">
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Verse</span>
                  </a>
                </li>
              
                <li>

                  <a href="/bilibili " style="margin-left:75px">
				  
				   <i class="fa fas fa-video" style="position: absolute;left:50px" ></i>
			      
		          <span>Bilibili</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/yanfeng98/paper-is-all-you-need" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/yanfeng98/paper-is-all-you-need" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cos.luyf-lemon-love.space/images/055-%E8%8B%B1%E9%9B%84%E8%81%94%E7%9B%9FLOL-%E5%8F%8C%E5%9F%8E%E4%B9%8B%E6%88%982%E4%B8%8D%E6%9C%BD%E9%87%91%E5%85%8B%E4%B8%9D.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">00254 NLP Course - Fast tokenizers in the QA pipeline</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                                <span class="chip bg-color">大语言模型</span>
                            </a>
                        
                            <a href="/tags/huggingface/">
                                <span class="chip bg-color">huggingface</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-category">
                                大语言模型
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-01-01
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-01-11
                </div>
                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们现在将深入问答管道，看看如何利用偏移量从上下文中抓取手头问题的答案，就像我们在上一节中对分组实体所做的那样。然后，我们将了解如何处理被截断的非常长的上下文。如果你对问答任务不感兴趣，可以跳过这一节。</p>
<p>src link: <a href="https://huggingface.co/learn/nlp-course/chapter6/3b">https://huggingface.co/learn/nlp-course/chapter6/3b</a></p>
<p>Operating System: Ubuntu 22.04.4 LTS</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ol>
<li><a href="https://huggingface.co/learn/nlp-course/chapter6/3b">NLP Course - Fast tokenizers in the QA pipeline</a></li>
</ol>
<h2 id="使用问答管道"><a href="#使用问答管道" class="headerlink" title="使用问答管道"></a>使用问答管道</h2><p>正如我们在第一章中看到的，我们可以使用这种问答流程来获取问题的答案。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

question_answerer <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"question-answering"</span><span class="token punctuation">)</span>
context <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch, and TensorFlow — with a seamless integration
between them. It's straightforward to train your models with one before loading them for inference with the other.
"""</span>
question <span class="token operator">=</span> <span class="token string">"Which deep learning libraries back 🤗 Transformers?"</span>
question_answerer<span class="token punctuation">(</span>question<span class="token operator">=</span>question<span class="token punctuation">,</span> context<span class="token operator">=</span>context<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.97773</span><span class="token punctuation">,</span>
 <span class="token string">'start'</span><span class="token punctuation">:</span> <span class="token number">78</span><span class="token punctuation">,</span>
 <span class="token string">'end'</span><span class="token punctuation">:</span> <span class="token number">105</span><span class="token punctuation">,</span>
 <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'Jax, PyTorch and TensorFlow'</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>与其他管道不同，它不能截断和分割超过模型接受的最大长度的文本（因此可能会错过文档末尾的信息），这个管道可以处理非常长的上下文，并且即使答案在末尾也会返回问题的答案。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">long_context <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
🤗 Transformers: State of the Art NLP

🤗 Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,
question answering, summarization, translation, text generation and more in over 100 languages.
Its aim is to make cutting-edge NLP easier to use for everyone.

🤗 Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and
then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and
can be modified to enable quick research experiments.

Why should I use transformers?

1. Easy-to-use state-of-the-art models:
  - High performance on NLU and NLG tasks.
  - Low barrier to entry for educators and practitioners.
  - Few user-facing abstractions with just three classes to learn.
  - A unified API for using all our pretrained models.
  - Lower compute costs, smaller carbon footprint:

2. Researchers can share trained models instead of always retraining.
  - Practitioners can reduce compute time and production costs.
  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.

3. Choose the right framework for every part of a model's lifetime:
  - Train state-of-the-art models in 3 lines of code.
  - Move a single model between TF2.0/PyTorch frameworks at will.
  - Seamlessly pick the right framework for training, evaluation and production.

4. Easily customize a model or an example to your needs:
  - We provide examples for each architecture to reproduce the results published by its original authors.
  - Model internals are exposed as consistently as possible.
  - Model files can be used independently of the library for quick experiments.

🤗 Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration
between them. It's straightforward to train your models with one before loading them for inference with the other.
"""</span>
question_answerer<span class="token punctuation">(</span>question<span class="token operator">=</span>question<span class="token punctuation">,</span> context<span class="token operator">=</span>long_context<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.97149</span><span class="token punctuation">,</span>
 <span class="token string">'start'</span><span class="token punctuation">:</span> <span class="token number">1892</span><span class="token punctuation">,</span>
 <span class="token string">'end'</span><span class="token punctuation">:</span> <span class="token number">1919</span><span class="token punctuation">,</span>
 <span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'Jax, PyTorch and TensorFlow'</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>让我们看看它是如何做到这一切的！</p>
<h2 id="使用模型进行问答"><a href="#使用模型进行问答" class="headerlink" title="使用模型进行问答"></a>使用模型进行问答</h2><p>与任何其他管道一样，我们首先对输入进行分词，然后将其发送到模型中。问答管道默认使用的检查点是 <a href="https://huggingface.co/distilbert-base-cased-distilled-squad">distilbert-base-cased-distilled-squad</a>（名称中的“squad”来自模型微调的数据集；我们将在第7章中更详细地讨论SQuAD数据集）。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForQuestionAnswering

model_checkpoint <span class="token operator">=</span> <span class="token string">"distilbert-base-cased-distilled-squad"</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForQuestionAnswering<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_checkpoint<span class="token punctuation">)</span>

inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> context<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>请注意，我们将问题和上下文作为一对进行分词，首先是问题。</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20250101225749.png"></p>
<p>问答模型的工作方式与我们至今为止看到的模型略有不同。以上图为例，该模型经过训练能够预测答案开始（此处为21）和结束（此处为24）的标记的索引。这就是为什么这些模型不返回一个张量，而是返回两个张量：一个对应于答案开始标记的logits，另一个对应于答案结束标记的logits。在这种情况下，我们只有一个包含66个标记的输入，因此我们得到：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">start_logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>start_logits
end_logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>end_logits
<span class="token keyword">print</span><span class="token punctuation">(</span>start_logits<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> end_logits<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">66</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>为了将那些logits转换为概率，我们将应用一个softmax函数——但在那之前，我们需要确保我们屏蔽了不属于上下文的索引。我们的输入是[CLS]问题[SEP]上下文[SEP]，所以我们需要屏蔽问题中的标记以及[SEP]标记。然而，我们将保留[CLS]标记，因为有些模型用它来表示答案不在上下文中。</p>
<p>由于我们随后将应用softmax，我们只需要将想要屏蔽的logits替换为一个大的负数。在这里，我们使用-10000：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Mask everything apart from the tokens of the context</span>
mask <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> sequence_ids<span class="token punctuation">]</span>
<span class="token comment"># Unmask the [CLS] token</span>
mask<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>
mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span>

start_logits<span class="token punctuation">[</span>mask<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10000</span>
end_logits<span class="token punctuation">[</span>mask<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>现在我们已经正确地屏蔽了我们不想预测的位置对应的logits，我们可以应用softmax了：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">start_probabilities <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>start_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
end_probabilities <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>end_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>在这一点上，我们可以取开始和结束概率的argmax——但我们可能会得到一个开始索引大于结束索引的结果，所以我们需要采取更多的预防措施。我们将计算每个可能的start_index和end_index的概率，其中start_index &lt;&#x3D; end_index，然后取概率最高的(start_index, end_index)元组。</p>
<p>假设事件“The answer starts at start_index”（答案从start_index开始）和“The answer ends at end_index”（答案在end_index结束）是独立的，那么答案从start_index开始并在end_index结束的概率是：</p>
<p>$\mathrm{start_probabilities}[\mathrm{start_index}] \times \mathrm{end_probabilities}[\mathrm{end_index}]$</p>
<p>因此，为了计算所有得分，我们只需要计算所有产品的start_probabilities[start_index]×end_probabilities[end_index]，其中start_index &lt;&#x3D; end_index。</p>
<p>首先，让我们计算所有可能的产品：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">scores <span class="token operator">=</span> start_probabilities<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> end_probabilities<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>然后，我们将通过将它们设置为0来屏蔽start_index &gt; end_index的值（其他概率都是正数）。torch.triu()函数返回作为参数传递的2D张量的上三角部分，因此它将为我们执行这种屏蔽：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>现在我们只需要得到最大值的索引。由于PyTorch将在扁平化的张量中返回索引，我们需要使用地板除法&#x2F;&#x2F;和模数%运算来得到start_index和end_index：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">max_index <span class="token operator">=</span> scores<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
start_index <span class="token operator">=</span> max_index <span class="token operator">//</span> scores<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
end_index <span class="token operator">=</span> max_index <span class="token operator">%</span> scores<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>scores<span class="token punctuation">[</span>start_index<span class="token punctuation">,</span> end_index<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>我们还没有完全完成，但至少我们已经有了答案的正确分数（你可以通过将其与前一部分的第一个结果进行比较来检查）：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token number">0.97773</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<blockquote>
<p>✏️ 尝试一下！计算五个最可能的答案的开始和结束索引。</p>
</blockquote>
<p>我们有了答案在令牌中的开始索引（start_index）和结束索引（end_index），现在只需要将这些索引转换成上下文中的字符索引。这时偏移量就会非常有用。我们可以获取这些偏移量，并像在令牌分类任务中那样使用它们：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs_with_offsets <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> context<span class="token punctuation">,</span> return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
offsets <span class="token operator">=</span> inputs_with_offsets<span class="token punctuation">[</span><span class="token string">"offset_mapping"</span><span class="token punctuation">]</span>

start_char<span class="token punctuation">,</span> _ <span class="token operator">=</span> offsets<span class="token punctuation">[</span>start_index<span class="token punctuation">]</span>
_<span class="token punctuation">,</span> end_char <span class="token operator">=</span> offsets<span class="token punctuation">[</span>end_index<span class="token punctuation">]</span>
answer <span class="token operator">=</span> context<span class="token punctuation">[</span>start_char<span class="token punctuation">:</span>end_char<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>现在我们只需要格式化所有内容以获得我们的结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">result <span class="token operator">=</span> <span class="token punctuation">&#123;</span>
    <span class="token string">"answer"</span><span class="token punctuation">:</span> answer<span class="token punctuation">,</span>
    <span class="token string">"start"</span><span class="token punctuation">:</span> start_char<span class="token punctuation">,</span>
    <span class="token string">"end"</span><span class="token punctuation">:</span> end_char<span class="token punctuation">,</span>
    <span class="token string">"score"</span><span class="token punctuation">:</span> scores<span class="token punctuation">[</span>start_index<span class="token punctuation">,</span> end_index<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'Jax, PyTorch and TensorFlow'</span><span class="token punctuation">,</span>
 <span class="token string">'start'</span><span class="token punctuation">:</span> <span class="token number">78</span><span class="token punctuation">,</span>
 <span class="token string">'end'</span><span class="token punctuation">:</span> <span class="token number">105</span><span class="token punctuation">,</span>
 <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.97773</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>太好了！这与我们的第一个示例相同！</p>
<blockquote>
<p>试一试！使用你之前计算的最佳得分来展示最可能的五个答案。为了检查你的结果，回到第一个pipeline，并在调用时传入 top_k&#x3D;5。</p>
</blockquote>
<h2 id="处理长上下文"><a href="#处理长上下文" class="headerlink" title="处理长上下文"></a>处理长上下文</h2><p>如果我们尝试对之前用作例子的长上下文和问题进行分词，我们会得到超过问题回答流程中使用的最大长度（384个令牌）的令牌数量：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> long_context<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token number">461</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>因此，我们需要将输入截断到这个最大长度。我们可以用几种方法来做这件事，但我们不想截断问题，只想截断上下文。由于上下文是第二个句子，我们将使用“only_second”截断策略。然后出现的问题是，问题的答案可能不在截断的上下文中。例如，我们挑选了一个问题，其答案位于上下文的末尾，当我们截断它时，这个答案就不存在了：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>question<span class="token punctuation">,</span> long_context<span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">384</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""
[CLS] Which deep learning libraries back [UNK] Transformers? [SEP] [UNK] Transformers : State of the Art NLP

[UNK] Transformers provides thousands of pretrained models to perform tasks on texts such as classification, information extraction,
question answering, summarization, translation, text generation and more in over 100 languages.
Its aim is to make cutting-edge NLP easier to use for everyone.

[UNK] Transformers provides APIs to quickly download and use those pretrained models on a given text, fine-tune them on your own datasets and
then share them with the community on our model hub. At the same time, each python module defining an architecture is fully standalone and
can be modified to enable quick research experiments.

Why should I use transformers?

1. Easy-to-use state-of-the-art models:
  - High performance on NLU and NLG tasks.
  - Low barrier to entry for educators and practitioners.
  - Few user-facing abstractions with just three classes to learn.
  - A unified API for using all our pretrained models.
  - Lower compute costs, smaller carbon footprint:

2. Researchers can share trained models instead of always retraining.
  - Practitioners can reduce compute time and production costs.
  - Dozens of architectures with over 10,000 pretrained models, some in more than 100 languages.

3. Choose the right framework for every part of a model's lifetime:
  - Train state-of-the-art models in 3 lines of code.
  - Move a single model between TF2.0/PyTorch frameworks at will.
  - Seamlessly pick the right framework for training, evaluation and production.

4. Easily customize a model or an example to your needs:
  - We provide examples for each architecture to reproduce the results published by its original authors.
  - Model internal [SEP]
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这意味着模型将难以选择正确的答案。为了解决这个问题，问题回答流程允许我们将上下文分成更小的块，并指定最大长度。为了确保我们不恰好在上文错误的地方分割，使找到答案成为可能，它还在块之间包含一些重叠。</p>
<p>我们可以通过添加 return_overflowing_tokens&#x3D;True 来让分词器（快速或慢速）为我们执行此操作，并且我们可以使用 stride 参数指定我们想要的重叠。这里有一个例子，使用了较短的句子：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">sentence <span class="token operator">=</span> <span class="token string">"This sentence is not too long but we are going to split it anyway."</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
    sentence<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span>
<span class="token punctuation">)</span>

<span class="token keyword">for</span> ids <span class="token keyword">in</span> inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>ids<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token string">'[CLS] This sentence is not [SEP]'</span>
<span class="token string">'[CLS] is not too long [SEP]'</span>
<span class="token string">'[CLS] too long but we [SEP]'</span>
<span class="token string">'[CLS] but we are going [SEP]'</span>
<span class="token string">'[CLS] are going to split [SEP]'</span>
<span class="token string">'[CLS] to split it anyway [SEP]'</span>
<span class="token string">'[CLS] it anyway. [SEP]'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>正如我们所看到的，句子已经被分成块，以便 inputs[“input_ids”] 中的每个条目最多有 6 个令牌（我们需要添加填充，使最后一个条目与其他条目的大小相同），并且每个条目之间有 2 个令牌的重叠。</p>
<p>让我们更仔细地看看分词的结果：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python">dict_keys<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'overflow_to_sample_mapping'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>正如预期的那样，我们得到了输入 ID 和一个注意力掩码。最后一个键，overflow_to_sample_mapping，是一个映射，告诉我们每个结果对应于哪个句子——在这里，我们有 7 个结果，都来自于我们传递给分词器的（唯一的）句子：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>这在当我们一起对几个句子进行分词时更有用。例如，像这样：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"This sentence is not too long but we are going to split it anyway."</span><span class="token punctuation">,</span>
    <span class="token string">"This sentence is shorter but will still get split."</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
    sentences<span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>得到我们：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>这意味着第一个句子像之前一样被分成 7 个块，接下来的 4 个块来自第二个句子。</p>
<p>现在让我们回到我们的长上下文。正如我们之前提到的，默认情况下，问题回答流程使用最大长度 384，以及步长 128，这与模型的微调方式相对应（你可以在调用流程时通过传递 max_seq_len 和 stride 参数来调整这些参数）。因此，我们在分词时将使用这些参数。我们还会添加填充（以使样本具有相同的长度，这样我们就可以构建张量），并请求偏移量：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
    question<span class="token punctuation">,</span>
    long_context<span class="token punctuation">,</span>
    stride<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">384</span><span class="token punctuation">,</span>
    padding<span class="token operator">=</span><span class="token string">"longest"</span><span class="token punctuation">,</span>
    truncation<span class="token operator">=</span><span class="token string">"only_second"</span><span class="token punctuation">,</span>
    return_overflowing_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    return_offsets_mapping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这些输入将包含模型期望的输入 ID 和注意力掩码，以及我们刚才讨论的偏移量和 overflow_to_sample_mapping。由于这两个参数不是模型使用的参数，我们将它们从输入中删除（并且我们不存储映射，因为在这里没有用处），然后将其转换为张量：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">_ <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"overflow_to_sample_mapping"</span><span class="token punctuation">)</span>
offsets <span class="token operator">=</span> inputs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"offset_mapping"</span><span class="token punctuation">)</span>

inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>convert_to_tensors<span class="token punctuation">(</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>我们的长上下文被分成了两部分，这意味着在通过模型处理后，我们将得到两套开始和结束的 logits：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>

start_logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>start_logits
end_logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>end_logits
<span class="token keyword">print</span><span class="token punctuation">(</span>start_logits<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> end_logits<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">]</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>像之前一样，我们在对 tokens 取 softmax 之前，首先屏蔽掉不属于上下文的 tokens。我们还屏蔽了所有的填充 tokens（由注意力掩码标记）：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">sequence_ids <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sequence_ids<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Mask everything apart from the tokens of the context</span>
mask <span class="token operator">=</span> <span class="token punctuation">[</span>i <span class="token operator">!=</span> <span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> sequence_ids<span class="token punctuation">]</span>
<span class="token comment"># Unmask the [CLS] token</span>
mask<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token comment"># Mask all the [PAD] tokens</span>
mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>logical_or<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>mask<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>inputs<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

start_logits<span class="token punctuation">[</span>mask<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10000</span>
end_logits<span class="token punctuation">[</span>mask<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">10000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>然后我们可以使用 softmax 将我们的 logits 转换为概率：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">start_probabilities <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>start_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
end_probabilities <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>end_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>下一步与我们对小上下文所做的类似，但我们需要对这两个块中的每一个都重复这个过程。我们为所有可能的答案跨度分配一个分数，然后选择分数最高的跨度：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">candidates <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> start_probs<span class="token punctuation">,</span> end_probs <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>start_probabilities<span class="token punctuation">,</span> end_probabilities<span class="token punctuation">)</span><span class="token punctuation">:</span>
    scores <span class="token operator">=</span> start_probs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> end_probs<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>triu<span class="token punctuation">(</span>scores<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    start_idx <span class="token operator">=</span> idx <span class="token operator">//</span> scores<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    end_idx <span class="token operator">=</span> idx <span class="token operator">%</span> scores<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    score <span class="token operator">=</span> scores<span class="token punctuation">[</span>start_idx<span class="token punctuation">,</span> end_idx<span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    candidates<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>start_idx<span class="token punctuation">,</span> end_idx<span class="token punctuation">,</span> score<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>candidates<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">0.33867</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">173</span><span class="token punctuation">,</span> <span class="token number">184</span><span class="token punctuation">,</span> <span class="token number">0.97149</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>这两个候选答案对应于模型能够在每个块中找到的最佳答案。模型更有信心确信正确答案在第二部分（这是一个好兆头！）。现在我们只需要将这两个 token 跨度映射到上下文中的字符跨度（我们只需要映射第二个跨度就能得到答案，但看看模型在第一块中选择了什么也是很有趣的）。</p>
<blockquote>
<p>✏️ 试一试！调整上面的代码，以返回五个最可能的答案的分数和跨度（总共，不是每个块的）。</p>
</blockquote>
<p>我们之前获取的偏移量实际上是一个偏移量列表，每个文本块都有一个列表：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> candidate<span class="token punctuation">,</span> offset <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>candidates<span class="token punctuation">,</span> offsets<span class="token punctuation">)</span><span class="token punctuation">:</span>
    start_token<span class="token punctuation">,</span> end_token<span class="token punctuation">,</span> score <span class="token operator">=</span> candidate
    start_char<span class="token punctuation">,</span> _ <span class="token operator">=</span> offset<span class="token punctuation">[</span>start_token<span class="token punctuation">]</span>
    _<span class="token punctuation">,</span> end_char <span class="token operator">=</span> offset<span class="token punctuation">[</span>end_token<span class="token punctuation">]</span>
    answer <span class="token operator">=</span> long_context<span class="token punctuation">[</span>start_char<span class="token punctuation">:</span>end_char<span class="token punctuation">]</span>
    result <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"answer"</span><span class="token punctuation">:</span> answer<span class="token punctuation">,</span> <span class="token string">"start"</span><span class="token punctuation">:</span> start_char<span class="token punctuation">,</span> <span class="token string">"end"</span><span class="token punctuation">:</span> end_char<span class="token punctuation">,</span> <span class="token string">"score"</span><span class="token punctuation">:</span> score<span class="token punctuation">&#125;</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">&#123;</span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'\n🤗 Transformers: State of the Art NLP'</span><span class="token punctuation">,</span> <span class="token string">'start'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'end'</span><span class="token punctuation">:</span> <span class="token number">37</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.33867</span><span class="token punctuation">&#125;</span>
<span class="token punctuation">&#123;</span><span class="token string">'answer'</span><span class="token punctuation">:</span> <span class="token string">'Jax, PyTorch and TensorFlow'</span><span class="token punctuation">,</span> <span class="token string">'start'</span><span class="token punctuation">:</span> <span class="token number">1892</span><span class="token punctuation">,</span> <span class="token string">'end'</span><span class="token punctuation">:</span> <span class="token number">1919</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.97149</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>如果我们忽略第一个结果，我们会得到与这个长上下文的流程相同的结果——太好了！</p>
<blockquote>
<p>✏️ 试一试！使用你之前计算的最佳得分来展示整个上下文中最可能的五个答案（不是每个块）。为了检查你的结果，回到第一个pipeline，并在调用时传入 top_k&#x3D;5。</p>
</blockquote>
<p>这结束了我们对分词器功能的深入探讨。在下一章中，当我们展示如何在一系列常见的 NLP 任务中对模型进行微调时，我们将会再次实践所有这些内容。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>第二百五十四篇博文写完，开心！！！！</p>
<p>今天，也是充满希望的一天。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">LuYF-Lemon-love</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://luyf-lemon-love.space/2025/01/01/00254-nlp-course-fast-tokenizers-in-the-qa-pipeline/">https://luyf-lemon-love.space/2025/01/01/00254-nlp-course-fast-tokenizers-in-the-qa-pipeline/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">LuYF-Lemon-love</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                                    <span class="chip bg-color">大语言模型</span>
                                </a>
                            
                                <a href="/tags/huggingface/">
                                    <span class="chip bg-color">huggingface</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">谢谢小主！</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162303.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162220.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/01/01/00255-python-shi-yong-zi-ding-yi-bian-li-han-shu/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/056-%E5%8F%AF%E7%88%B1%E7%B2%89%E8%89%B2%E8%BF%9E%E5%B8%BD%E8%A1%AB%E5%8A%A8%E6%BC%AB%E5%A5%B3%E5%AD%A9.jpg" class="responsive-img" alt="00255 Python 实用自定义便利函数">
                        
                        <span class="card-title">00255 Python 实用自定义便利函数</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-01-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Python/" class="post-category">
                                    Python
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/12/30/00253-monte-carlo-tree-search-suan-fa/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/054-%E5%A4%A7%E8%83%B8.jpg" class="responsive-img" alt="00253 Monte Carlo Tree Search算法">
                        
                        <span class="card-title">00253 Monte Carlo Tree Search算法</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-12-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="post-category">
                                    人工智能
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">强化学习</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022-2025</span>
            
            <a href="/about" target="_blank">LuYF-Lemon-love</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "5";
                        var startDate = "7";
                        var startHour = "4";
                        var startMinute = "53";
                        var startSecond = "32";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
                <span id="icp"><img src="/medias/icp.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="https://beian.miit.gov.cn" target="_blank">冀ICP备2022012632号-1</a>
            </span>
            
            <br>
            
                <span id="gongan"><img src="https://cos.luyf-lemon-love.space/images/备案图标.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32011502011618" target="_blank">苏公网安备 32011502011618号</a>
            </span>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yanfeng98" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:luyanfeng_nlp@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
