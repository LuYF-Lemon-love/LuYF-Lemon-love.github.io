<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="00035-TransE 原论文学习笔记, NLP LLM DeepLearning LuYF-Lemon-love 自然语言处理 深度学习 大语言模型">
    <meta name="description" content="前言TransE 是一个著名的知识表示学习 (knowledge representation learning, KRL) 模型。
本博文是 TransE 原论文学习笔记，包括代码实现。
TransE 原论文链接：Translating ">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>00035-TransE 原论文学习笔记 | LuYF-Lemon-love の Blog</title>
    <link rel="icon" type="image/jpeg" href="https://cos.luyf-lemon-love.space/images/苏苏1.jpeg">
    
    <style>
        body{
            background-image: url(https://cos.luyf-lemon-love.space/images/016-%E6%8A%A5%E7%BA%B8%E5%A2%99%E9%BA%BB%E8%A1%A3%E5%AD%A6%E5%A7%90.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <span class="logo-span">LuYF-Lemon-love の Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>List</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/galleries">
          
          <i class="fas fa-image" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Image</span>
        </a>
      </li>
      
      <li>
        <a href="/verse">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Verse</span>
        </a>
      </li>
      
      <li>
        <a href="/bilibili">
          
          <i class="fas fa-video" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Bilibili</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <div class="logo-name">LuYF-Lemon-love の Blog</div>
        <div class="logo-desc">
            
            天之道，损有余而补不足，人之道则不然，损不足以奉有余。
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			友情链接
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			List
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/galleries " style="margin-left:75px">
				  
				   <i class="fa fas fa-image" style="position: absolute;left:50px" ></i>
			      
		          <span>Image</span>
                  </a>
                </li>
              
                <li>

                  <a href="/verse " style="margin-left:75px">
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Verse</span>
                  </a>
                </li>
              
                <li>

                  <a href="/bilibili " style="margin-left:75px">
				  
				   <i class="fa fas fa-video" style="position: absolute;left:50px" ></i>
			      
		          <span>Bilibili</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/yanfeng98/paper-is-all-you-need" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/yanfeng98/paper-is-all-you-need" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cos.luyf-lemon-love.space/images/ionia_placidium_01.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">00035-TransE 原论文学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/C/">
                                <span class="chip bg-color">C++</span>
                            </a>
                        
                            <a href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/">
                                <span class="chip bg-color">多线程</span>
                            </a>
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                                <span class="chip bg-color">知识图谱</span>
                            </a>
                        
                            <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/">
                                <span class="chip bg-color">知识图谱补全</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Paper/" class="post-category">
                                Paper
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-10-10
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-28
                </div>
                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><code>TransE</code> 是一个著名的<code>知识表示学习</code> (<code>knowledge representation learning</code>, KRL) 模型。</p>
<p>本博文是 <code>TransE</code> 原论文学习笔记，包括代码实现。</p>
<p><strong>TransE</strong> 原论文链接：<a href="https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf">Translating Embeddings for Modeling Multi-relational Data</a>.</p>
<p><strong>代码仓库地址</strong>: <a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B">https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B</a> .</p>
<p>操作系统：Ubuntu 18.04.6 LTS</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><div id = "1"></div>

<ol>
<li><a href="https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf">Translating Embeddings for Modeling Multi-relational Data</a>.</li>
</ol>
<div id = "2"></div>

<ol start="2">
<li>T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems (NIPS 26), 2013.</li>
</ol>
<div id = "3"></div>

<ol start="3">
<li>X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)., 2010.</li>
</ol>
<div id = "4"></div>

<ol start="4">
<li>A. Bordes, J. Weston, R. Collobert, and Y. Bengio. Learning structured embeddings of knowledge bases. In Proceedings of the 25th Annual Conference on Artificial Intelligence (AAAI), 2011.</li>
</ol>
<div id = "5"></div>

<ol start="5">
<li>R. Socher, D. Chen, C. D. Manning, and A. Y. Ng. Learning new facts from knowledge bases with neural tensor networks and semantic word vectors. In Advances in Neural Information Processing Systems (NIPS 26), 2013.</li>
</ol>
<div id = "6"></div>

<ol start="6">
<li>M. Nickel, V. Tresp, and H.-P. Kriegel. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th International Conference on Machine Learning (ICML), 2011.</li>
</ol>
<div id = "7"></div>

<ol start="7">
<li>R. Jenatton, N. Le Roux, A. Bordes, G. Obozinski, et al. A latent factor model for highly multi-relational data. In Advances in Neural Information Processing Systems (NIPS 25), 2012.</li>
</ol>
<div id = "8"></div>

<ol start="8">
<li>A. Bordes, X. Glorot, J. Weston, and Y. Bengio. A semantic matching energy function for learning with multi-relational data. Machine Learning, 2013.</li>
</ol>
<div id = "9"></div>

<ol start="9">
<li><a href="https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.xavier_uniform_">torch.nn.init.xavier_uniform_</a>.</li>
</ol>
<div id = "10"></div>

<ol start="10">
<li><p>J. Weston, A. Bordes, O. Yakhnenko, and N. Usunier. Connecting language and knowledge bases with embedding models for relation extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2013.</p>
</li>
<li><p>Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, Xuan Zhu. Learning entity and relation embeddings for knowledge graph completion. The 29th AAAI Conference on Artificial Intelligence, 2015.</p>
</li>
<li><p><a href="https://blog.csdn.net/shunaoxi2313/article/details/89766467">transE(Translating Embedding)详解+简单python实现</a>.</p>
</li>
<li><p><a href="https://github.com/thunlp/Fast-TransX">Fast-TransX</a>.</p>
</li>
</ol>
<h2 id="TransE-原论文学习笔记"><a href="#TransE-原论文学习笔记" class="headerlink" title="TransE 原论文学习笔记"></a>TransE 原论文学习笔记</h2><p><strong>TransE</strong> 提出于 <em>2013</em> 年, 发表于 <a href="https://neurips.cc/">NeurIPS</a> 会议论文. 为什么介绍 <em>2013</em> 年的 <strong>TransE</strong>, 因为 <strong>TransE</strong> 相对于它的变体, <strong>简洁, 高效, 又不失准确</strong>.</p>
<p><strong>TransE</strong> 是一个将<strong>关系</strong>建模成<strong>实体低维度嵌入向量</strong>的<strong>平移</strong>的方法.</p>
<p><strong>TransE</strong> <code>成功地</code>在一个大型知识图谱 (<code>1M</code> 个实体, <code>25k</code> 个关系, 超过 <code>17M</code> 个训练三元组) 上完成训练 (学习).</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><strong>介绍</strong></h3><p><strong>Multi-relational data</strong> 是指<strong>有向图</strong>, 它的<strong>节点</strong>被称为<strong>实体</strong>, <em>(head, label, tail)</em> 形式的<strong>边</strong> (标注为 <em>$(h, \ell, t)$</em>) 能够指示在 <em>head</em> 和 <em>tail</em> 实体之间存在一个名为 <em>label</em> 的<strong>关系</strong>.</p>
<p><code>TransE</code> 在论文中<code>建模</code>了来自 <code>Wordnet</code> 和 <code>Freebase</code> 的 <code>Multi-relational data</code>.</p>
<p> <strong>TransE</strong> 是一个不需要<strong>额外知识</strong>, <strong>自动</strong>加新事实 (三元组) <strong>补全</strong>知识图谱的高效工具.</p>
<p>通过<code>对比</code>其他类型<code>知识表示学习</code>模型<code>表明</code>, 即使在<code>复杂</code>和<code>异构</code>的<code>多关系领域</code>中，<code>简单</code>而<code>适当</code>的<code>建模假设</code>可以在<code>准确性</code>和<code>可扩展性</code>之间实现更好的<code>权衡</code>。</p>
<p><strong>TransE</strong> 是一个基于能量 <em>(energy-based)</em> 的学习<strong>实体低维度嵌入向量</strong>的模型. <strong>关系</strong>被表示为<strong>嵌入空间</strong>的<strong>平移</strong>: 如果 <em>$(h, \ell, t)$</em> 成立, <em>t</em> 的嵌入应该接近于 <em>h</em> 的嵌入加上某个<strong>向量</strong>, 某个向量就是<strong>关系的嵌入向量</strong> ($\ell$).</p>
<p>基于<code>平移</code> 的 <code>TransE</code> 主要<code>设计动机</code>是: <code>层次性关系</code>在知识图谱中非常普遍, <code>平移</code>是<code>表示实体</code>的<code>自然转换</code>. 如, <code>null</code> <code>平移向量</code>对应于<code>实体之间的等价关系</code>, 因此<code>平移</code>也可以表示<code>同级关系</code> (<code>父子关系</code>中的<code>兄弟关系</code>). 因此, 可以使用<code>每个关系</code>的 <code>parameter budget</code>（一个<code>低维向量</code>）来表示<code>知识图谱</code>中的关键 (<code>关系</code>).</p>
<p><code>TransE</code> 的<code>第二个设计动机</code>是: <code>Mikolov</code> 等研究者于 <code>2013</code> 年提出了<code>词表示学习模型</code> —— <code>word2vec</code><a href="#2"><sup>2</sup></a>, 并发现 <code>word2vec</code> 学习到的<code>词向量</code>之间有着<code>有趣的语义平移现象</code>, 如:</p>
<p>$$<br>\nu(king) - \nu(man) \simeq \nu(queen) - \nu(woman)<br>$$</p>
<p>其中, $\nu(x)$ 表示 $x$ 的词向量, 这种<code>语义平移现象</code>表明了<code>词和词之间的隐含语义关系</code>被成功地<code>编码进了词向量中</code>. <code>word2vec</code> 表明存在<code>不同类型实体</code>之间的 <code>1-to-1</code> 关系能够表示成<code>嵌入向量空间</code>的平移.</p>
<p>由于 <code>TransE</code> 的<code>轻量参数</code>, 它能够<code>成功地</code>在包含 <code>1M</code> 实体, <code>25k</code>关系, 超过 <code>17M</code> 训练三元组的 <code>Freebase</code> 的<code>大型子集</code>上进行训练。</p>
<h3 id="Translation-based-model"><a href="#Translation-based-model" class="headerlink" title="Translation-based model"></a><strong><code>Translation-based</code> model</strong></h3><p>训练集 <em>$S$</em> 是由<code>三元组</code> <em>$(h, \ell, t)$</em> 组成, <em>$h, t \in E$</em> (实体集合), <em>$\ell \in L$</em> (关系集合), <strong>TransE</strong> 学习<code>实体</code>和<code>关系</code>的<code>嵌入向量</code>. 嵌入向量的值为 <em>$R^k$</em> (<em>$k$</em> 是超参数).</p>
<p>模型的基本思想是关系 <em>$\ell$</em> 是嵌入向量的平移, 例如: 如果 <em>$(h, \ell, t)$</em> 成立, <em>$h + \ell \approx t$</em>, 即 <em>$t$</em> 应该是 <em>$h + \ell$</em> 最近的邻居, 如果不成立, <em>$h + \ell$</em> 应该远离 <em>$t$</em>. 根据<code>能量框架</code> (<code>energy-based framework</code>), <code>三元组的能量</code>应该等价于 <em>$d(h + \ell, t)$</em>, <code>差异性度量</code>函数 <em>$d$</em> 是 <strong>$L_1$</strong> 或者 <strong>$L_2-norm$</strong>.</p>
<p>为了<code>学习嵌入向量</code>, 在训练集上<code>最小化</code> <strong>margin-based ranking criterion</strong> 损失函数:</p>
<p>$$<br>\mathcal{L} &#x3D; \sum_{(h, \ell, t) \in S} \sum_{(h^{‘}, \ell, t^{‘}) \in S^{‘}<em>{(h, \ell, t)}} [\gamma + d(h + \ell, t) - d(h^{‘} + \ell, t^{‘})]</em>{+}<br>$$</p>
<p><em>$[x]_+$</em> 显示 <em>$x$</em> 正的部分, <em>$\gamma &gt; 0$</em> 是一个 <strong>margin</strong> 超参数.</p>
<p>$$<br>S^{‘}_{(h, \ell, t)} &#x3D; {(h^{‘}, \ell, t)|h^{‘} \in E} \cup {(h, \ell, t^{‘})|t^{‘} \in E}.<br>$$</p>
<p><strong>负三元组</strong> (<code>corrupted triplets</code>) 集合是<code>根据上面的公式</code>构造的, 是将<code>训练集三元组</code>中的 <code>head</code> 或者 <code>tail</code> 实体用<code>随机的实体</code>替换得到的 (<strong><code>head</code> 和 <code>tail</code> 不同时替换</strong>). <strong>损失函数会使<code>训练集中的三元组的能量</code>比<code>负三元组</code>低</strong>. 实体作为三元组的 <code>head</code> 和 <code>tail</code> 时的嵌入向量相同.</p>
<p>优化方法是<strong>随机梯度下降</strong> (<code>SGD</code>), 并且使用 <strong>$L_2-norm$</strong> 将<code>实体</code>和<code>关系</code>的<code>嵌入向量</code>限制为 <code>1</code> (it prevents the training process to <code>trivially</code> minimize $\mathcal{L}$ by artificially increasing entity embeddings norms.<a href="#1"><sup>1</sup></a>).</p>
<p>详细的训练过程如下图. 首先, 实体和关系的嵌入被随机初始化 (使用 <code>Xavier 初始值</code> 进行初始化<a href="#3"><sup>3</sup></a>). 每一轮 (epoch) 迭代, <code>实体和关系</code>的嵌入首先被<strong>归一化 ( <code>normalized</code>)</strong>, 然后从训练集中采样 <code>1 batch</code> 三元组作为<code>正三元组</code>; 对于每一个采样得到的正三元组, 随机替换 <code>head</code> 或 <code>tail</code> (<strong>使用伯努利分布（Bernoulli distribution) 可以更加高效的选择替换 head 或 tail</strong>)得到一个<code>负三元组</code>. 然后<strong>采用<code>固定学习率</code>的梯度<code>更新</code>实体和关系的嵌入向量</strong>. 该迭代过程<code>基于验证集上表现</code>停止.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20220926131142.png"></p>
<p>Xavier 初始值简介</p>
<p>该模型层的<code>激活函数</code>为 <code>None</code>, <code>tanh</code>, <code>logistic</code>, <code>softmax</code> 时, 神经元初始化准则<a href="#9"><sup>9</sup></a>为:</p>
<ol>
<li><code>正态分布</code>, 均值为 <code>0</code>, 方差为 $\sigma^2 &#x3D; \frac{1}{fan_{avg}}$</li>
</ol>
<p><code>or</code></p>
<ol start="2">
<li>$-r$ 和 $+r$ 之间的<code>均匀分布</code>, 其中 $r &#x3D; \sqrt{\frac{3}{fan_{avg}}}$</li>
</ol>
<p>其中, $fan_{avg} &#x3D; \frac{(fan_{in} + fan_{out})}{2}$, $fan_{in}$ 是<code>前一层的节点数</code>, $fan_{out}$ 是<code>下一层的节点数</code>.</p>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><ol>
<li><p><code>Structured Embeddings or SE</code><a href="#4"><sup>4</sup></a>, 虽然 <code>SE</code> 能够重现 <code>TransE</code> 的 <code>平移</code>, 但是 <code>TransE</code> 在实验中表现的更好. 主要原因如下:</p>
<ul>
<li><code>TransE</code> 更直接的表达<code>关系的特性</code> (<code>平移</code>).</li>
<li>在<code>嵌入向量模型</code>中, 优化是异常困难的.</li>
<li>对于 <code>SE</code> 来说, <code>更大的表现力</code>似乎更像是<code>欠拟合</code>的同义词，而不是<code>更好的性能</code>.</li>
</ul>
</li>
<li><p>相比于 <code>the Neural Tensor Model</code><a href="#5"><sup>5</sup></a>, <code>TransE</code> 的有较少的参数: 这可以<code>简化训练</code>并防止<code>欠拟合</code>, 并可能<code>弥补较低的表现力</code>.</p>
</li>
<li><p><code>TransE</code>，可以看作是<code>编码一系列 2-way 交互</code>. 对于 $h$, $\ell$ 和 $t$ 之间存在的 <code>3-way</code> 依赖是相当重要的数据, <code>TransE</code> 不能够很好地建模 (相比于 <code>RESCAL</code><a href="#6"><sup>6</sup></a> <code>LFM</code><a href="#7"><sup>7</sup></a> <code>SME</code><a href="#8"><sup>8</sup></a>)</p>
</li>
<li><p>为了处理像 <code>Freebase</code> 这样的通用大规模知识图谱, 人们应该首先正确地建模<code>最常见的连接模式</code>, 就像 <code>TransE</code> 所做的那样.</p>
</li>
</ol>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><h4 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h4><p>数据来自于 <code>Wordnet</code> 和 <code>Freebase</code>. 数据集的统计如下:</p>
<table>
<thead>
<tr>
<th align="center">DATA SET</th>
<th align="center">WN</th>
<th align="center">FB15K</th>
<th align="center">FB1M</th>
</tr>
</thead>
<tbody><tr>
<td align="center">ENTITIES</td>
<td align="center">40,943</td>
<td align="center">14,951</td>
<td align="center">1×10<sup>6</sup></td>
</tr>
<tr>
<td align="center">RELATIONSHIPS</td>
<td align="center">18</td>
<td align="center">1,345</td>
<td align="center">23,382</td>
</tr>
<tr>
<td align="center">TRAIN. EX.</td>
<td align="center">141,442</td>
<td align="center">483,142</td>
<td align="center">17.5×10<sup>6</sup></td>
</tr>
<tr>
<td align="center">VALID EX.</td>
<td align="center">5,000</td>
<td align="center">50,000</td>
<td align="center">50,000</td>
</tr>
<tr>
<td align="center">TEST EX.</td>
<td align="center">5,000</td>
<td align="center">59,071</td>
<td align="center">177,404</td>
</tr>
</tbody></table>
<blockquote>
<p><strong><code>Wordnet</code></strong>: This <code>KB</code> is designed to <code>produce an intuitively usable dictionary and thesaurus</code>, and support <code>automatic text analysis</code>. Its entities (termed synsets) correspond to <code>word senses</code>, and relationships define lexical relations between them. We considered the data version used in <a href="#8">8</a>, which we denote WN in the following. Examples of triplets are <code>(_score_NN_1, _hypernym, _evaluation_NN_1)</code> or <code>(_score_NN_2, _has_part, _musical_notation_NN_1)</code>. WN is <code>composed of senses</code>, its entities are denoted by <code>the concatenation of a word, its part-of-speech tag and a digit</code> indicating which sense it refers to i.e. <code>_score_NN_1</code> encodes the first meaning of the noun “score”.</p>
<p><strong><code>Freebase</code></strong>: Freebase is a huge and growing KB of general facts; there are currently around <strong>1.2 billion triplets</strong> and <strong>more than 80 million entities</strong>. We created two data sets with Freebase.</p>
</blockquote>
<p>实验数据集为 <a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/data/FB15K">FB15K</a>. 该数据集是 <code>Wikilinks database</code> 的<code>实体子集</code>, 该子集中的实体和关系在 <code>Freebase</code> 至少出现了 <code>100</code> 次. 并且移除了像 ’!&#x2F;people&#x2F;person&#x2F;nationality’ 这样的关系, 因为它是关系 ’&#x2F;people&#x2F;person&#x2F;nationality’ <code>head</code> 和 <code>tail</code> 的颠倒. 一共 <strong>592,213</strong> 个三元组, <strong>14,951</strong> 个实体, <strong>1,345</strong> 个关系, 被<code>随机地</code>分成了训练集 (<strong>483,142</strong> 个), 验证集 (<strong>50,000</strong> 个), 测试集 (<strong>59,071</strong> 个).</p>
<p><code>FB1M</code>: 是从 <code>Freebase</code> 创建了<code>另一个数据集</code>, 方法是<code>选择最常出现的 100 万个实体</code>. 该数据大约有 <code>25k</code> 个关系和超过 <code>1700</code> 万训练三元组.</p>
<h4 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h4><p><strong>评估准则</strong>: 测试集中的三元组全部都是<code>正三元组</code>. 对于每一个测试三元组, <code>head</code> 被<code>所有实体</code>依次替换, 通过模型计算各个负三组的能量 <strong>$d(h^{‘} + \ell, t)$</strong>, 然后用升序排序. 测试三元组 (正三元组) 的名次被保存. 替换 <code>tail</code> 而不是 <code>head</code> 重复上面的过程. 最终报告<code>测试三元组的平均排名</code>和 <em><code>hits@10</code></em> (<code>测试三元组</code>排在<code>前 10</code> 的比例).</p>
<p>上面的指标<code>可能存在缺陷</code>, 因为一些<code>&quot;负三元组&quot;</code>可能存在于<code>训练集</code>和<code>验证集</code>. 在这种情况下,这些<code>&quot;负三元组&quot;</code>的排名可能<code>高于</code>测试三元组, 但这种<code>&quot;负三元组&quot;</code>不应该归类为错误, 因为<code>测试三元组</code>和<code>负三元组</code>都是正确的. <strong>为了排除指标的缺陷, 移除了出现在数据集 (训练集, 验证集, 测试集) 中的<code>负三元组</code>. 确保了负三元组不属于数据集</strong>. 因此有两种设置的指标 (<code>平均排名</code>和 <em><code>hits@10</code></em>): 原始 (存在缺陷) 被标记为 <em><code>raw</code></em>, 新的被标记为 <em><code>filtered</code></em> (or <em><code>filt.</code></em>).</p>
<p>Baselines</p>
<ol>
<li><p><code>Unstructured</code>: a version of <code>TransE</code> which considers the data as <code>mono-relational</code> and sets all <code>translations</code> to 0.</p>
</li>
<li><p><code>RESCAL</code>: the collective matrix factorization model.</p>
</li>
<li><p><code>SE</code>: energy-based models.</p>
</li>
<li><p><code>SME(linear)/SME(bilinear)</code>: energy-based models.</p>
</li>
<li><p><code>LFM</code>: energy-based models.</p>
</li>
</ol>
<p>基线模型的额外信息</p>
<p><code>RESCAL</code> is trained via <code>an alternating least-square method</code>, whereas <code>the others</code> are trained by <code>stochastic gradient descent</code>, like <code>TransE</code>.</p>
<p><code>SME(linear)</code>, <code>SME(bilinear)</code>, <code>LFM</code> and <code>TransE</code> have about <code>the same number of parameters</code> as <code>Unstructured</code> for <code>low dimensional embeddings</code>, the other algorithms <code>SE</code> and <code>RESCAL</code>, which learn at least <code>one k × k matrix</code> for each relationship rapidly need to <code>learn many parameters</code>.</p>
<p><code>RESCAL</code> needs <code>about 87 times more parameters</code> on <code>FB15k</code> because it requires <code>a much larger embedding space</code> than other models to achieve good performance.</p>
<p>Implementation</p>
<p>TransE 超参数选择</p>
<p>For experiments with <code>TransE</code>, we selected the learning rate $\lambda$ for <code>the stochastic gradient descent</code> among <code>&#123;0.001, 0.01, 0.1&#125;</code>, the margin $\gamma$ among <code>&#123;1, 2, 10&#125;</code> and the latent dimension $k$ among <code>&#123;20, 50&#125;</code> on <code>the validation set</code> of <code>each data set</code>.</p>
<p>The <code>dissimilarity measure</code> $d$ was set either to the $L_1$ or $L_2$ distance according to <code>validation performance</code> as well.</p>
<p><strong>WN 的最佳参数</strong>: 嵌入维度 <strong>$k &#x3D; 20$</strong>, 学习率 <strong>$\lambda &#x3D; 0.01$</strong>, <strong>margin $\gamma &#x3D; 2$</strong>, 能量函数 <strong>$d &#x3D; L_1$</strong>.</p>
<p><strong>FB15K 的最佳参数</strong>: 嵌入维度 <strong>$k &#x3D; 50$</strong>, 学习率 <strong>$\lambda &#x3D; 0.01$</strong>, <strong>margin $\gamma &#x3D; 1$</strong>, 能量函数 <strong>$d &#x3D; L_1$</strong>.</p>
<p><strong>FB1M 的最佳参数</strong>: 嵌入维度 <strong>$k &#x3D; 50$</strong>, 学习率 <strong>$\lambda &#x3D; 0.01$</strong>, <strong>margin $\gamma &#x3D; 1$</strong>, 能量函数 <strong>$d &#x3D; L_2$</strong>.</p>
<p>对于所有数据集, 最多训练 <code>1000 epochs</code>, 可以参考验证集上的平均排名 (raw) 使用提前停止获得最佳模型.</p>
<h4 id="链接预测"><a href="#链接预测" class="headerlink" title="链接预测"></a>链接预测</h4><p>TransE 总体实验结果</p>
<p>As expected, the <code>filtered</code> setting provides <code>lower mean ranks</code> and <code>higher</code> <em>hits@10</em>, which we believe are <code>a clearer evaluation of the performance of the methods in link prediction</code>.</p>
<p><code>The trends</code> between <code>raw</code> and <code>filtered</code> are the same.</p>
<p><code>TransE</code>, outperforms all counterparts on all metrics, usually with a wide margin.</p>
<p>The good performance of <code>TransE</code> is due to an appropriate design of the model according to the data, but also to its <code>relative simplicity</code>. This means that it can be <code>optimized efficiently with stochastic gradient</code>.</p>
<p><code>SE</code> is <code>more expressive</code> than our proposal. However, its <code>complexity</code> may make it <code>quite hard to learn</code>, resulting in worse performance.</p>
<p><code>TransE</code> is indeed less subject to <code>underfitting</code> and that this could explain its better performances.</p>
<p>基线模型详细的总体实验结果</p>
<p><code>SME(bilinear)</code> and <code>LFM</code> suffer from the same training issue: we <code>never managed to train them well enough</code> so that they could exploit their full capabilities.</p>
<p>The poor results of <code>LFM</code> might also be explained by <code>our evaluation setting</code>, <code>based on ranking entities</code>, whereas <code>LFM</code> was <code>originally</code> proposed to <code>predict relationships</code>.</p>
<p><code>RESCAL</code> can achieve quite good <em>hits@10</em> on FB15k but <code>yields poor mean ranks</code>, especially on <code>WN</code>, even when we used <code>large latent dimensions</code> (<code>2, 000</code> on <code>Wordnet</code>).</p>
<p>The impact of the translation term is <code>huge</code>.</p>
<p><code>Unstructured</code> simply <code>clusters</code> all entities cooccurring together, <code>independent of the relationships involved</code>, and hence can only make guesses of which entities are related.</p>
<p>On <code>FB1M</code>, <code>the mean ranks of TransE</code> and <code>Unstructured</code> are almost <code>similar</code>, but <code>TransE</code> places <code>10 times more predictions</code> in <code>the top 10</code>.</p>
<hr>
<p>根据 <strong>head</strong> 和 <strong>tail</strong> 的基数 (cardinalities) 能够将<code>关系</code>分成以下<code>四种</code>: <strong>1-TO-1</strong>, <strong>1-TO-MANY</strong>, <strong>MANY-TO-1</strong>, <strong>MANY-TO-MANY</strong></p>
<ol>
<li><p><code>1-TO-1</code>: 一个 <code>head</code> 至多有一个 <code>tail</code>.</p>
</li>
<li><p><code>1-TO-MANY</code>: 一个 <code>head</code> 有很多 <code>tail</code>.</p>
</li>
<li><p><code>MANY-TO-1</code>: 许多 <code>head</code> 有很多相同 <code>tail</code>.</p>
</li>
<li><p><code>MANY-TO-MANY</code>: 多个 <code>head</code> 和多个 <code>tail</code> 同时出现.</p>
</li>
</ol>
<p>关系划分方法</p>
<p>We classified the relationships into these <code>four classes</code> by computing, for <code>each relationship</code> $\ell$, the <code>averaged number of heads</code> $h$ (respect. tails $t$) appearing in the <code>FB15k</code> data set, given a pair $(\ell, t)$ (respect. a pair $(h, \ell)$). If <code>this average number</code> was below <code>1.5</code> then the argument was labeled as <code>1</code> and <code>MANY</code> otherwise. For example, a <code>relationship</code> having <code>an average of 1.2 head per tail</code> and of <code>3.2 tails per head</code> was classified as <code>1-to-Many</code>.</p>
<p><code>FB15k</code> 有 <code>26.2%</code> 的 <code>1-TO-1</code>, <code>22.7%</code> 的 <code>1-TO-MANY</code>, <code>28.3%</code> 的 <code>MANY-TO-1</code>, <code>22.8%</code> 的 <code>MANY-TO-MANY</code>.</p>
<p>可以发现类型为 <strong>1-TO-MANY</strong> 和 <strong>MANY-TO-1</strong> 的关系, 从 <strong>MANY</strong> 侧边预测 <strong>1</strong> 侧边具有很高的利用价值, 因为这种训练数据较多.</p>
<p>平移的重要性</p>
<p>Adding the <code>translation term</code> (i.e. upgrading <code>Unstructured</code> into <code>TransE</code>) brings the ability to <code>move in the embeddings space</code>, from <code>one entity cluster to another</code> by following relationships.</p>
<hr>
<p><img src="https://cos.luyf-lemon-love.space/images/20220926171344.png"></p>
<p>上图使用 <strong>TransE</strong> 预测的 <strong>tails</strong> 中，黑体和斜体都是知识图谱已有的知识 (正三元组), 其余就是模型补全的, 即<strong>知识图谱的补全</strong>.</p>
<h4 id="Learning-to-predict-new-relationships-with-few-examples"><a href="#Learning-to-predict-new-relationships-with-few-examples" class="headerlink" title="Learning to predict new relationships with few examples"></a>Learning to predict new relationships with few examples</h4><p>实验细节</p>
<p>Using <code>FB15k</code>, we wanted to test how well methods could generalize to new facts by checking <code>how fast they were learning new relationships</code>.</p>
<p>To that end, we <code>randomly</code> selected <code>40</code> relationships and <code>split the data into two sets</code>: a set (named <code>FB15k-40rel</code>) containing all triplets with these <code>40</code> relationships and another set (<code>FB15k-rest</code>) containing the rest. We made sure that <code>both sets</code> contained all entities.</p>
<p><code>FB15k-rest</code> has then been split into <code>a training set of 353,788 triplets</code> and <code>a validation set of 53,266</code>, and <code>FB15k-40rel</code> into <code>a training set of 40,000 triplets</code> (<code>1,000</code> for each relationship) and a test set of <code>45,159</code>.</p>
<p>Using these data sets, we conducted the following experiment: (1) models were <code>trained</code> and <code>selected</code> using <code>FB15k-rest training and validation sets</code>, (2) they were subsequently <code>trained</code> on <code>the training set FB15k-40rel</code> but only to learn the parameters related to <code>the fresh 40 relationships</code>, (3) they were evaluated in link prediction <code>on the test set of FB15k-40rel</code> (containing only relationships <code>unseen</code> during phase (1)).</p>
<p>We <code>repeated</code> this procedure while using <code>0</code>, <code>10</code>, <code>100</code> and <code>1000</code> examples of <code>each relationship</code> in phase (2).</p>
<hr>
<p>实验结果</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221011144348.png"></p>
<p>The performance of <code>Unstructured</code> is <code>the best</code> when <code>no example</code> of the unknown relationship is provided, because it <code>does not use this information to predict</code>. But, of course, this performance <code>does not improve</code> while <code>providing labeled examples</code>.</p>
<p><code>TransE</code> is the <code>fastest</code> method to learn: with only <code>10 examples</code> of a new relationship, the <em>hits@10</em> is already <code>18%</code> and it improves <code>monotonically</code> with the number of provided samples.</p>
<p>We believe the <code>simplicity</code> of the <code>TransE</code> model makes it able to <code>generalize</code> well, without having to <code>modify</code> any of <code>the already trained embeddings</code>.</p>
<h3 id="Conclusion-and-future-work"><a href="#Conclusion-and-future-work" class="headerlink" title="Conclusion and future work"></a>Conclusion and future work</h3><p><strong>TransE</strong> 应用一共有三个: <strong>知识图谱补全</strong> (Link prediction), 知识表示, 嵌入到关系抽取模型中.</p>
<p>原论文</p>
<p>We proposed <code>a new approach</code> to learn embeddings of KBs, focusing on the minimal parametrization of the model to <code>primarily represent hierarchical relationships</code>. We showed that it works very well <code>compared to competing methods</code> on <code>two different knowledge bases</code>, and is also <code>a highly scalable model</code>, whereby we applied it to <code>a very large-scale chunk of Freebase data</code>. Although it remains <code>unclear</code> to us if all relationship types can be <code>modeled adequately</code> by our approach, by breaking down the evaluation into <code>categories</code> (<code>1-to-1</code>, <code>1-to-Many</code>, . . . ) it <code>appears to be performing well</code> compared to other approaches across all settings.</p>
<p>Future work could analyze this model further, and also concentrates on exploiting it in more tasks, in particular, applications such as <code>learning word representations</code> inspired by <a href="#2">2</a>. <code>Combining KBs with text</code> as in <a href="#8">8</a> is <code>another important direction</code> where our approach could prove useful. Hence, we recently fruitfully <code>inserted TransE into a framework for relation extraction</code> from text <a href="#10">10</a>.</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><p><strong>代码仓库地址</strong>: <a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B">https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B</a> .</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ tree
<span class="token builtin class-name">.</span>
├── data
│   └── FB15K
│       ├── entity2id.txt
│       ├── relation2id.txt
│       ├── test2id.txt
│       ├── train2id.txt
│       └── valid2id.txt
├── papers
│   └── TransE.pdf
├── README.md
└── TransE
    ├── clean.sh
    ├── data_preprocessing.py
    ├── run.sh
    ├── test_transE.cpp
    └── transE.cpp

<span class="token number">4</span> directories, <span class="token number">12</span> files<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><h4 id="FB15K"><a href="#FB15K" class="headerlink" title="FB15K"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/data/FB15K/">FB15K</a></h4><p>该数据集是 <code>Wikilinks database</code> 的实体子集, 该子集中的实体和关系在 <code>Freebase</code> 至少出现了 <code>100</code> 次. 并且移除了像 <code>’!/people/person/nationality’</code> 这样的关系, 因为它是关系 <code>’/people/person/nationality’</code> <code>head</code> 和 <code>tail</code> 的颠倒. 一共 <code>592,213</code> 个三元组, <code>14,951</code> 个实体, <code>1,345</code> 个关系, 被随机地分成了训练集 (<code>483,142</code> 个), 验证集 (<code>50,000</code> 个), 测试集 (<code>59,071</code> 个).</p>
<ul>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/data/FB15K/entity2id.txt">entity2id.txt</a>: 第一行是实体个数. 其余行是实体名和对应的实体 ID, 每行一个.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/data/FB15K/relation2id.txt">relation2id.txt</a>: 第一行是关系个数. 其余行是关系名和对应的关系 ID, 每行一个.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/data/FB15K/train2id.txt">train2id.txt</a>: 训练文件. 第一行是训练集三元组的个数. 其余行是 (e1, e2, rel) 格式的三元组, 每行一个. e1, e2 是实体 ID, rel 是关系 ID.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/data/FB15K/valid2id.txt">valid2id.txt</a>: 验证文件. 第一行是验证集三元组的个数. 其余行是 (e1, e2, rel) 格式的三元组, 每行一个. e1, e2 是实体 ID, rel 是关系 ID.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/data/FB15K/test2id.txt">test2id.txt</a>: 测试文件. 第一行是测试集三元组的个数. 其余行是 (e1, e2, rel) 格式的三元组, 每行一个. e1, e2 是实体 ID, rel 是关系 ID.</p>
</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ tree
<span class="token builtin class-name">.</span>
├── entity2id.txt
├── relation2id.txt
├── test2id.txt
├── train2id.txt
└── valid2id.txt

<span class="token number">0</span> directories, <span class="token number">5</span> files
$ <span class="token function">head</span> entity2id.txt 
<span class="token number">14951</span>
/m/027rn	<span class="token number">0</span>
/m/06cx9	<span class="token number">1</span>
/m/017dcd	<span class="token number">2</span>
/m/06v8s0	<span class="token number">3</span>
/m/07s9rl0	<span class="token number">4</span>
/m/0170z3	<span class="token number">5</span>
/m/01sl1q	<span class="token number">6</span>
/m/044mz_	<span class="token number">7</span>
/m/0cnk2q	<span class="token number">8</span>
$ <span class="token function">head</span> relation2id.txt 
<span class="token number">1345</span>
/location/country/form_of_government	<span class="token number">0</span>
/tv/tv_program/regular_cast./tv/regular_tv_appearance/actor	<span class="token number">1</span>
/media_common/netflix_genre/titles	<span class="token number">2</span>
/award/award_winner/awards_won./award/award_honor/award_winner	<span class="token number">3</span>
/soccer/football_team/current_roster./sports/sports_team_roster/position	<span class="token number">4</span>
/sports/sports_position/players./soccer/football_roster_position/team	<span class="token number">5</span>
/government/political_district/representatives./government/government_position_held/legislative_sessions	<span class="token number">6</span>
/film/film/starring./film/performance/actor	<span class="token number">7</span>
/soccer/football_team/current_roster./soccer/football_roster_position/position	<span class="token number">8</span>
$ <span class="token function">head</span> test2id.txt 
<span class="token number">59071</span>
<span class="token number">453</span> <span class="token number">1347</span> <span class="token number">37</span>
<span class="token number">3136</span> <span class="token number">4357</span> <span class="token number">588</span>
<span class="token number">8663</span> <span class="token number">4522</span> <span class="token number">307</span>
<span class="token number">2404</span> <span class="token number">8386</span> <span class="token number">186</span>
<span class="token number">722</span> <span class="token number">806</span> <span class="token number">37</span>
<span class="token number">1248</span> <span class="token number">10937</span> <span class="token number">26</span>
<span class="token number">9182</span> <span class="token number">1043</span> <span class="token number">20</span>
<span class="token number">706</span> <span class="token number">14564</span> <span class="token number">28</span>
<span class="token number">706</span> <span class="token number">14004</span> <span class="token number">28</span>
$ <span class="token function">head</span> train2id.txt 
<span class="token number">483142</span>
<span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span>
<span class="token number">2</span> <span class="token number">3</span> <span class="token number">1</span>
<span class="token number">4</span> <span class="token number">5</span> <span class="token number">2</span>
<span class="token number">6</span> <span class="token number">7</span> <span class="token number">3</span>
<span class="token number">8</span> <span class="token number">9</span> <span class="token number">4</span>
<span class="token number">10</span> <span class="token number">11</span> <span class="token number">5</span>
<span class="token number">12</span> <span class="token number">13</span> <span class="token number">6</span>
<span class="token number">14</span> <span class="token number">15</span> <span class="token number">7</span>
<span class="token number">16</span> <span class="token number">17</span> <span class="token number">8</span>
$ <span class="token function">head</span> valid2id.txt 
<span class="token number">50000</span>
<span class="token number">5167</span> <span class="token number">1427</span> <span class="token number">52</span>
<span class="token number">239</span> <span class="token number">2379</span> <span class="token number">326</span>
<span class="token number">837</span> <span class="token number">9339</span> <span class="token number">3</span>
<span class="token number">7674</span> <span class="token number">4431</span> <span class="token number">272</span>
<span class="token number">4528</span> <span class="token number">8708</span> <span class="token number">155</span>
<span class="token number">71</span> <span class="token number">5412</span> <span class="token number">32</span>
<span class="token number">5041</span> <span class="token number">5979</span> <span class="token number">26</span>
<span class="token number">11273</span> <span class="token number">3632</span> <span class="token number">390</span>
<span class="token number">10994</span> <span class="token number">36</span> <span class="token number">168</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="TransE"><a href="#TransE" class="headerlink" title="TransE"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/TransE">TransE</a></h3><ul>
<li><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/TransE/data_preprocessing.py">data_preprocessing.py</a>: 该 <code>Python</code> 脚本用于创建下面这些临时数据文件.</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">..</span>/data/FB15K/1-1.txt
<span class="token punctuation">..</span>/data/FB15K/1-n.txt
<span class="token punctuation">..</span>/data/FB15K/n-1.txt
<span class="token punctuation">..</span>/data/FB15K/n-n.txt
<span class="token punctuation">..</span>/data/FB15K/test2id_all.txt
<span class="token punctuation">..</span>/data/FB15K/type_constrain.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/TransE/transE.cpp">transE.cpp</a>: 该 <code>C++</code> 文件用于模型训练.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/TransE/test_transE.cpp">test_transE.cpp</a>: 该 <code>C++</code> 文件用于模型测试.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/TransE/run.sh">run.sh</a>: 该 <code>Shell</code> 脚本用于模型训练和模型测试.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/knowledge-representation-learning/C%2B%2B/TransE/clean.sh">clean.sh</a>: 该 <code>Shell</code> 脚本用于清理临时文件.</p>
</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ tree
<span class="token builtin class-name">.</span>
├── clean.sh
├── data_preprocessing.py
├── run.sh
├── test_transE.cpp
└── transE.cpp

<span class="token number">0</span> directories, <span class="token number">5</span> files<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="data-preprocessing-py"><a href="#data-preprocessing-py" class="headerlink" title="data_preprocessing.py"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/knowledge-representation-learning/C%2B%2B/TransE/data_preprocessing.py">data_preprocessing.py</a></h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># data_preprocessing.py</span>
<span class="token comment"># 使用方法: $ python3 data_preprocessing.py</span>
<span class="token comment"># created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com></span>
<span class="token comment">#</span>
<span class="token comment"># 该 Python 脚本用于创建下面这些临时数据文件</span>
<span class="token comment"># ../data/FB15K/1-1.txt ../data/FB15K/1-n.txt ../data/FB15K/n-1.txt ../data/FB15K/n-n.txt ../data/FB15K/test2id_all.txt ../data/FB15K/type_constrain.txt</span>
<span class="token comment">#</span>
<span class="token comment"># prerequisites: </span>
<span class="token comment">#     train2id.txt, valid2id.txt, test2id.txt</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n##################################################"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n数据预处理开始..."</span><span class="token punctuation">)</span>

<span class="token comment">##################################################</span>
<span class="token comment"># 从 train2id.txt, valid2id.txt、test2id.txt 读取三元组</span>
<span class="token comment">##################################################</span>

<span class="token comment"># lef 和 rig 类型为 &#123;[]&#125;, 外层是 &lt;class 'dict'>, 内层是 &lt;class 'list'></span>
<span class="token comment"># lef 外层的 key 为三元组 (训练集、验证集、测试集) (h, r)</span>
<span class="token comment"># lef 外层的 value 为 (h, r) 对应的 t 的 list</span>
<span class="token comment"># rig 外层的 key 为三元组 (训练集、验证集、测试集) (r, t)</span>
<span class="token comment"># rig 外层的 value 为 (r, t) 对应的 h 的 list  </span>
lef <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
rig <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>

<span class="token comment"># rel_lef 和 rel_rig 类型为 &#123;&#123;&#125;&#125;, 外层是 &lt;class 'dict'>, 内层是 &lt;class 'dict'></span>
<span class="token comment"># rel_lef 外层的 key 为三元组 (训练集、验证集、测试集) r</span>
<span class="token comment"># rel_lef 内层的 key 为 r 对应的 h, 内层的 value 为 1</span>
<span class="token comment"># rel_rig 外层的 key 为三元组 (训练集、验证集、测试集) r</span>
<span class="token comment"># rel_rig 内层的 key 为 r 对应的 t, 内层的 value 为 1</span>
rel_lef <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
rel_rig <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>

train_list <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/train2id.txt"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
valid_list <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/valid2id.txt"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
test_list <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/test2id.txt"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>

tot <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>train_list<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tot<span class="token punctuation">)</span><span class="token punctuation">:</span>

	content <span class="token operator">=</span> train_list<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
	h<span class="token punctuation">,</span> t<span class="token punctuation">,</span> r <span class="token operator">=</span> content<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>

	<span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token punctuation">(</span>h<span class="token punctuation">,</span> r<span class="token punctuation">)</span> <span class="token keyword">in</span> lef<span class="token punctuation">:</span>
		lef<span class="token punctuation">[</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
	<span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token punctuation">(</span>r<span class="token punctuation">,</span>t<span class="token punctuation">)</span> <span class="token keyword">in</span> rig<span class="token punctuation">:</span>
		rig<span class="token punctuation">[</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
	lef<span class="token punctuation">[</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span> r<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
	rig<span class="token punctuation">[</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>h<span class="token punctuation">)</span>
	
	<span class="token keyword">if</span> <span class="token keyword">not</span> r <span class="token keyword">in</span> rel_lef<span class="token punctuation">:</span>
		rel_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
	<span class="token keyword">if</span> <span class="token keyword">not</span> r <span class="token keyword">in</span> rel_rig<span class="token punctuation">:</span>
		rel_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
	rel_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">[</span>h<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
	rel_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>

tot <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>valid_list<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tot<span class="token punctuation">)</span><span class="token punctuation">:</span>

	content <span class="token operator">=</span> valid_list<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
	h<span class="token punctuation">,</span>t<span class="token punctuation">,</span>r <span class="token operator">=</span> content<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>

	<span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token punctuation">(</span>h<span class="token punctuation">,</span>r<span class="token punctuation">)</span> <span class="token keyword">in</span> lef<span class="token punctuation">:</span>
		lef<span class="token punctuation">[</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span>r<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
	<span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token punctuation">(</span>r<span class="token punctuation">,</span>t<span class="token punctuation">)</span> <span class="token keyword">in</span> rig<span class="token punctuation">:</span>
		rig<span class="token punctuation">[</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span>t<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
	lef<span class="token punctuation">[</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span>r<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
	rig<span class="token punctuation">[</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span>t<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>h<span class="token punctuation">)</span>

	<span class="token keyword">if</span> <span class="token keyword">not</span> r <span class="token keyword">in</span> rel_lef<span class="token punctuation">:</span>
		rel_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
	<span class="token keyword">if</span> <span class="token keyword">not</span> r <span class="token keyword">in</span> rel_rig<span class="token punctuation">:</span>
		rel_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
	rel_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">[</span>h<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
	rel_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>

tot <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>test_list<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tot<span class="token punctuation">)</span><span class="token punctuation">:</span>

	content <span class="token operator">=</span> test_list<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
	h<span class="token punctuation">,</span>t<span class="token punctuation">,</span>r <span class="token operator">=</span> content<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>

	<span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token punctuation">(</span>h<span class="token punctuation">,</span>r<span class="token punctuation">)</span> <span class="token keyword">in</span> lef<span class="token punctuation">:</span>
		lef<span class="token punctuation">[</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span>r<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
	<span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token punctuation">(</span>r<span class="token punctuation">,</span>t<span class="token punctuation">)</span> <span class="token keyword">in</span> rig<span class="token punctuation">:</span>
		rig<span class="token punctuation">[</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span>t<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
	lef<span class="token punctuation">[</span><span class="token punctuation">(</span>h<span class="token punctuation">,</span>r<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
	rig<span class="token punctuation">[</span><span class="token punctuation">(</span>r<span class="token punctuation">,</span>t<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>h<span class="token punctuation">)</span>

	<span class="token keyword">if</span> <span class="token keyword">not</span> r <span class="token keyword">in</span> rel_lef<span class="token punctuation">:</span>
		rel_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
	<span class="token keyword">if</span> <span class="token keyword">not</span> r <span class="token keyword">in</span> rel_rig<span class="token punctuation">:</span>
		rel_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
	rel_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">[</span>h<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
	rel_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span><span class="token punctuation">[</span>t<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>

test_list<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
valid_list<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_list<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">##################################################</span>
<span class="token comment"># 创建 type_constrain.txt</span>
<span class="token comment"># type_constrain.txt: 类型约束文件, 第一行是关系的个数</span>
<span class="token comment"># 下面的行是每个关系的类型限制 (训练集、验证集、测试集中每个关系存在的 head 和 tail 的类型)</span>
<span class="token comment"># 每个关系有两行：</span>
<span class="token comment"># 第一行：`id of relation` `Number of head types` `head1` `head2` ...</span>
<span class="token comment"># 第二行: `id of relation` `number of tail types` `tail1` `tail2` ...</span>
<span class="token comment">#</span>
<span class="token comment"># For example, the relation with id 1200 has 4 types of head entities, which are 3123, 1034, 58 and 5733</span>
<span class="token comment"># The relation with id 1200 has 4 types of tail entities, which are 12123, 4388, 11087 and 11088</span>
<span class="token comment"># 1200	4	3123	1034	58	5733</span>
<span class="token comment"># 1200	4	12123	4388	11087	11088</span>
<span class="token comment">##################################################</span>

f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/type_constrain.txt"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>
f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%d\n"</span><span class="token operator">%</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>rel_lef<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> rel_lef<span class="token punctuation">:</span>
	f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%s\t%d"</span><span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>rel_lef<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword">for</span> j <span class="token keyword">in</span> rel_lef<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>
		f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\t%s"</span><span class="token operator">%</span><span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">)</span>
	f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
	f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%s\t%d"</span><span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>rel_rig<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token keyword">for</span> j <span class="token keyword">in</span> rel_rig<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>
		f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\t%s"</span><span class="token operator">%</span><span class="token punctuation">(</span>j<span class="token punctuation">)</span><span class="token punctuation">)</span>
	f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n../data/FB15K/type_constrain.txt 创建成功."</span><span class="token punctuation">)</span>


<span class="token comment">##################################################</span>
<span class="token comment"># 创建 1-1.txt、1-n.txt、n-1.txt、n-n.txt、test2id_all.txt</span>
<span class="token comment">##################################################</span>

<span class="token comment"># rel_lef, tot_lef, rel_rig, tot_rig 类型为 &lt;class 'dict'></span>
<span class="token comment"># rel_lef 的 key 为 r, value 为相应 (关系为 r) 三元组 (训练集、验证集、测试集) tail 的个数</span>
<span class="token comment"># tot_lef 的 key 为 r, value 为相应 (关系为 r) 三元组 (训练集、验证集、测试集) head 的种类数</span>
<span class="token comment"># rel_rig 的 key 为 r, value 为相应 (关系为 r) 三元组 (训练集、验证集、测试集) head 的个数</span>
<span class="token comment"># tot_rig 的 key 为 r, value 为相应 (关系为 r) 三元组 (训练集、验证集、测试集) tail 的种类数</span>
rel_lef <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
tot_lef <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
rel_rig <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
tot_rig <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> lef<span class="token punctuation">:</span>
	<span class="token keyword">if</span> <span class="token keyword">not</span> i<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">in</span> rel_lef<span class="token punctuation">:</span>
		rel_lef<span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
		tot_lef<span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
	rel_lef<span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>lef<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
	tot_lef<span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1.0</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> rig<span class="token punctuation">:</span>
	<span class="token keyword">if</span> <span class="token keyword">not</span> i<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">in</span> rel_rig<span class="token punctuation">:</span>
		rel_rig<span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
		tot_rig<span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
	rel_rig<span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>rig<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
	tot_rig<span class="token punctuation">[</span>i<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1.0</span>

<span class="token comment"># 统计测试集中各种三元组 (关系: 1-1, 1-n, n-1, n-n) 的数量</span>
<span class="token comment"># s11: 1-1</span>
<span class="token comment"># s1n: 1-n</span>
<span class="token comment"># sn1: n-1</span>
<span class="token comment"># snn: n-n</span>
s11 <span class="token operator">=</span> <span class="token number">0</span>
s1n <span class="token operator">=</span> <span class="token number">0</span>
sn1 <span class="token operator">=</span> <span class="token number">0</span>
snn <span class="token operator">=</span> <span class="token number">0</span>

f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/test2id.txt"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
tot <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tot<span class="token punctuation">)</span><span class="token punctuation">:</span>

	content <span class="token operator">=</span> f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
	h<span class="token punctuation">,</span> t<span class="token punctuation">,</span> r <span class="token operator">=</span> content<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>

	rign <span class="token operator">=</span> rel_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">/</span> tot_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span>
	lefn <span class="token operator">=</span> rel_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">/</span> tot_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span>

	<span class="token keyword">if</span> <span class="token punctuation">(</span>rign <span class="token operator">&lt;=</span> <span class="token number">1.5</span> <span class="token keyword">and</span> lefn <span class="token operator">&lt;=</span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		s11 <span class="token operator">+=</span> <span class="token number">1</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>rign <span class="token operator">></span> <span class="token number">1.5</span> <span class="token keyword">and</span> lefn <span class="token operator">&lt;=</span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		s1n <span class="token operator">+=</span> <span class="token number">1</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>rign <span class="token operator">&lt;=</span> <span class="token number">1.5</span> <span class="token keyword">and</span> lefn <span class="token operator">></span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		sn1 <span class="token operator">+=</span> <span class="token number">1</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>rign <span class="token operator">></span> <span class="token number">1.5</span> <span class="token keyword">and</span> lefn <span class="token operator">></span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		snn <span class="token operator">+=</span> <span class="token number">1</span>

f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 创建 1-1.txt、1-n.txt、n-1.txt、n-n.txt、test2id_all.txt</span>
<span class="token comment"># 1-1.txt: 第一行是测试集中关系为 1-1 的三元组的个数，其余行为 (e1, e2, rel) 格式的三元组</span>
<span class="token comment"># 1-n.txt: 第一行是测试集中关系为 1-n 的三元组的个数，其余行为 (e1, e2, rel) 格式的三元组</span>
<span class="token comment"># n-1.txt: 第一行是测试集中关系为 n-1 的三元组的个数，其余行为 (e1, e2, rel) 格式的三元组</span>
<span class="token comment"># n-n.txt: 第一行是测试集中关系为 n-n 的三元组的个数，其余行为 (e1, e2, rel) 格式的三元组</span>
<span class="token comment"># test2id_all.txt:</span>
<span class="token comment">#     第一行是测试集中三元组的个数</span>
<span class="token comment">#     其余行为 `label` `(e1, e2, rel)`</span>
<span class="token comment">#     label:</span>
<span class="token comment">#         0: 1-1, 1: 1-n, 2: n-1, 3: n-n</span>
f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/test2id.txt"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span>
f11 <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/1-1.txt"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>
f1n <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/1-n.txt"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>
fn1 <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/n-1.txt"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>
fnn <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/n-n.txt"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>
fall <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"../data/FB15K/test2id_all.txt"</span><span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">)</span>

tot <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
fall<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%d\n"</span><span class="token operator">%</span><span class="token punctuation">(</span>tot<span class="token punctuation">)</span><span class="token punctuation">)</span>
f11<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%d\n"</span><span class="token operator">%</span><span class="token punctuation">(</span>s11<span class="token punctuation">)</span><span class="token punctuation">)</span>
f1n<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%d\n"</span><span class="token operator">%</span><span class="token punctuation">(</span>s1n<span class="token punctuation">)</span><span class="token punctuation">)</span>
fn1<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%d\n"</span><span class="token operator">%</span><span class="token punctuation">(</span>sn1<span class="token punctuation">)</span><span class="token punctuation">)</span>
fnn<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"%d\n"</span><span class="token operator">%</span><span class="token punctuation">(</span>snn<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>tot<span class="token punctuation">)</span><span class="token punctuation">:</span>

	content <span class="token operator">=</span> f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
	h<span class="token punctuation">,</span> t<span class="token punctuation">,</span> r <span class="token operator">=</span> content<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>

	rign <span class="token operator">=</span> rel_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">/</span> tot_lef<span class="token punctuation">[</span>r<span class="token punctuation">]</span>
	lefn <span class="token operator">=</span> rel_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span> <span class="token operator">/</span> tot_rig<span class="token punctuation">[</span>r<span class="token punctuation">]</span>

	<span class="token keyword">if</span> <span class="token punctuation">(</span>rign <span class="token operator">&lt;=</span> <span class="token number">1.5</span> <span class="token keyword">and</span> lefn <span class="token operator">&lt;=</span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		f11<span class="token punctuation">.</span>write<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
		fall<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"0"</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span>content<span class="token punctuation">)</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>rign <span class="token operator">></span> <span class="token number">1.5</span> <span class="token keyword">and</span> lefn <span class="token operator">&lt;=</span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		f1n<span class="token punctuation">.</span>write<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
		fall<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"1"</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span>content<span class="token punctuation">)</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>rign <span class="token operator">&lt;=</span> <span class="token number">1.5</span> <span class="token keyword">and</span> lefn <span class="token operator">></span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		fn1<span class="token punctuation">.</span>write<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
		fall<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"2"</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span>content<span class="token punctuation">)</span>
	<span class="token keyword">if</span> <span class="token punctuation">(</span>rign <span class="token operator">></span> <span class="token number">1.5</span> <span class="token keyword">and</span> lefn <span class="token operator">></span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
		fnn<span class="token punctuation">.</span>write<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
		fall<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"3"</span><span class="token operator">+</span><span class="token string">"\t"</span><span class="token operator">+</span>content<span class="token punctuation">)</span>

fall<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
f11<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
f1n<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
fn1<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
fnn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n../data/FB15K/1-1.txt ../data/FB15K/1-n.txt ../data/FB15K/n-1.txt ../data/FB15K/n-n.txt ../data/FB15K/test2id_all.txt 创建成功."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n数据预处理结束.\n"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="transE-cpp"><a href="#transE-cpp" class="headerlink" title="transE.cpp"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/knowledge-representation-learning/C%2B%2B/TransE/transE.cpp">transE.cpp</a></h4><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; transE.cpp
&#x2F;&#x2F; 使用方法:
&#x2F;&#x2F;     编译:
&#x2F;&#x2F;           $ g++ transE.cpp -o .&#x2F;build&#x2F;transE -pthread -O3 -march&#x3D;native
&#x2F;&#x2F;     运行:
&#x2F;&#x2F;           $ .&#x2F;build&#x2F;transE
&#x2F;&#x2F;           
&#x2F;&#x2F; created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com&gt;
&#x2F;&#x2F;
&#x2F;&#x2F; 该 C++ 文件用于模型训练
&#x2F;&#x2F;
&#x2F;&#x2F; prerequisites:
&#x2F;&#x2F;     relation2id.txt, entity2id.txt, train2id.txt
&#x2F;&#x2F;
&#x2F;&#x2F; 加载 Pretrained Embeddings (可选)
&#x2F;&#x2F; prerequisites: 
&#x2F;&#x2F;     entity2vec + note + .bin
&#x2F;&#x2F;     relation2vec + note + .bin
&#x2F;&#x2F;     
&#x2F;&#x2F;     or
&#x2F;&#x2F;
&#x2F;&#x2F;     entity2vec + note + .vec
&#x2F;&#x2F;     relation2vec + note + .vec
&#x2F;&#x2F;
&#x2F;&#x2F; 输出实体嵌入和关系嵌入
&#x2F;&#x2F; output: 
&#x2F;&#x2F;     entity2vec + note + .bin
&#x2F;&#x2F;     relation2vec + note + .bin
&#x2F;&#x2F;     
&#x2F;&#x2F;     or
&#x2F;&#x2F;
&#x2F;&#x2F;     entity2vec + note + .vec
&#x2F;&#x2F;     relation2vec + note + .vec

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 包含标准库
&#x2F;&#x2F; ##################################################

#include &lt;cstdio&gt;           &#x2F;&#x2F; FILE, fscanf, fwrite, fopen, fclose
#include &lt;cstdlib&gt;          &#x2F;&#x2F; malloc, calloc, free, atoi, atof, rand, RAND_MAX
#include &lt;cmath&gt;            &#x2F;&#x2F; exp, fabs
#include &lt;cstring&gt;          &#x2F;&#x2F; memcpy, strcmp
#include &lt;fcntl.h&gt;          &#x2F;&#x2F; open, close, O_RDONLY
#include &lt;unistd.h&gt;         &#x2F;&#x2F; stat
#include &lt;sys&#x2F;stat.h&gt;       &#x2F;&#x2F; stat
#include &lt;sys&#x2F;mman.h&gt;       &#x2F;&#x2F; mmap, munmap
#include &lt;sys&#x2F;time.h&gt;       &#x2F;&#x2F; timeval, gettimeofday
#include &lt;pthread.h&gt;        &#x2F;&#x2F; pthread_create, pthread_exit, pthread_join
#include &lt;string&gt;           &#x2F;&#x2F; std::string, std::string::c_str
#include &lt;algorithm&gt;        &#x2F;&#x2F; std::sort

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 声明和定义变量
&#x2F;&#x2F; ##################################################

#define REAL float
#define INT int

const REAL pi &#x3D; 3.141592653589793238462643383;

INT bern_flag &#x3D; 1;
INT load_binary_flag &#x3D; 0;
INT out_binary_flag &#x3D; 0;
INT dimension &#x3D; 50;
REAL alpha &#x3D; 0.01;
REAL margin &#x3D; 1.0;
INT nbatches &#x3D; 1;
INT epochs &#x3D; 1000;
INT threads &#x3D; 32;

std::string in_path &#x3D; &quot;..&#x2F;data&#x2F;FB15K&#x2F;&quot;;
std::string out_path &#x3D; &quot;.&#x2F;build&#x2F;&quot;;
std::string load_path &#x3D; &quot;&quot;;
std::string note &#x3D; &quot;&quot;;

&#x2F;&#x2F; 三元组: (head, label, tail)
&#x2F;&#x2F; h: head
&#x2F;&#x2F; r: label or relationship
&#x2F;&#x2F; t: tail
&#x2F;&#x2F; a relationship of name label between the entities head and tail
struct Triple &#123;
	INT h, r, t;
&#125;;

&#x2F;&#x2F; 为 std::sort() 定义比较仿函数
&#x2F;&#x2F; 以三元组的 head 进行比较
struct cmp_head &#123;
	bool operator()(const Triple &amp;a, const Triple &amp;b) &#123;
		return (a.h &lt; b.h)||(a.h &#x3D;&#x3D; b.h &amp;&amp; a.r &lt; b.r)
			||(a.h &#x3D;&#x3D; b.h &amp;&amp; a.r &#x3D;&#x3D; b.r &amp;&amp; a.t &lt; b.t);
	&#125;
&#125;;

&#x2F;&#x2F; 为 std::sort() 定义比较仿函数
&#x2F;&#x2F; 以三元组的 tail 进行比较
struct cmp_tail &#123;
	bool operator()(const Triple &amp;a, const Triple &amp;b) &#123;
		return (a.t &lt; b.t)||(a.t &#x3D;&#x3D; b.t &amp;&amp; a.r &lt; b.r)
			||(a.t &#x3D;&#x3D; b.t &amp;&amp; a.r &#x3D;&#x3D; b.r &amp;&amp; a.h &lt; b.h);
	&#125;
&#125;;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 一些用于程序初始化的数学函数
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; 为每一个线程保存独立的随机种子
unsigned long long *next_random;

&#x2F;&#x2F; 更新第 id[0, threads) 线程的随机种子
unsigned long long randd(INT id) &#123;
	next_random[id] &#x3D; next_random[id] 
		* (unsigned long long)25214903917 + 11;
	return next_random[id];
&#125;

&#x2F;&#x2F; 为第 id[0, threads) 线程返回取值为 [0, x) 的伪随机数
INT rand_max(INT id, INT x) &#123;
	INT res &#x3D; randd(id) % x;
	while (res &lt; 0)
		res +&#x3D; x;
	return res;
&#125;

&#x2F;&#x2F; 返回取值为 [min, max) 的伪随机数 
REAL rand(REAL min, REAL max) &#123;
	return min + (max - min) * rand() &#x2F; (RAND_MAX + 1.0);
&#125;

&#x2F;&#x2F; 正态分布函数，X ~ N (miu, sigma)
REAL normal(REAL x, REAL miu, REAL sigma) &#123;
	return 1.0 &#x2F; sqrt(2 * pi) &#x2F; sigma
		* exp(-1 * (x-miu) * (x-miu) &#x2F; (2 * sigma * sigma));
&#125;

&#x2F;&#x2F; 从正态（高斯）分布中抽取随机样本，取值为 [min, max) 的伪随机数
REAL randn(REAL miu, REAL sigma, REAL min, REAL max) &#123;
	REAL x, y, d_scope;
	do &#123;
		x &#x3D; rand(min, max);
		y &#x3D; normal(x, miu, sigma);
		d_scope &#x3D; rand(0.0, normal(miu, miu, sigma));
	&#125; while (d_scope &gt; y);
	return x;
&#125;

&#x2F;&#x2F; 最大范数正则化函数: 如果输入向量的 L2 范数 &gt; 1, 将输入向量的压缩, 使的其 L2 范数 &#x3D; 1
&#x2F;&#x2F; 可以参考: https:&#x2F;&#x2F;tensorflow.google.cn&#x2F;api_docs&#x2F;python&#x2F;tf&#x2F;keras&#x2F;constraints&#x2F;MaxNorm
&#x2F;*
@keras_export(&quot;keras.constraints.MaxNorm&quot;, &quot;keras.constraints.max_norm&quot;)
class MaxNorm(Constraint):
    &quot;&quot;&quot;MaxNorm weight constraint.
    Constrains the weights incident to each hidden unit
    to have a norm less than or equal to a desired value.
    Also available via the shortcut function &#96;tf.keras.constraints.max_norm&#96;.
    Args:
      max_value: the maximum norm value for the incoming weights.
      axis: integer, axis along which to calculate weight norms.
        For instance, in a &#96;Dense&#96; layer the weight matrix
        has shape &#96;(input_dim, output_dim)&#96;,
        set &#96;axis&#96; to &#96;0&#96; to constrain each weight vector
        of length &#96;(input_dim,)&#96;.
        In a &#96;Conv2D&#96; layer with &#96;data_format&#x3D;&quot;channels_last&quot;&#96;,
        the weight tensor has shape
        &#96;(rows, cols, input_depth, output_depth)&#96;,
        set &#96;axis&#96; to &#96;[0, 1, 2]&#96;
        to constrain the weights of each filter tensor of size
        &#96;(rows, cols, input_depth)&#96;.
    &quot;&quot;&quot;

    def __init__(self, max_value&#x3D;2, axis&#x3D;0):
        self.max_value &#x3D; max_value
        self.axis &#x3D; axis

    @doc_controls.do_not_generate_docs
    def __call__(self, w):
        norms &#x3D; backend.sqrt(
            tf.reduce_sum(tf.square(w), axis&#x3D;self.axis, keepdims&#x3D;True)
        )
        desired &#x3D; backend.clip(norms, 0, self.max_value)
        return w * (desired &#x2F; (backend.epsilon() + norms))

    @doc_controls.do_not_generate_docs
    def get_config(self):
        return &#123;&quot;max_value&quot;: self.max_value, &quot;axis&quot;: self.axis&#125;
*&#x2F;
void norm(REAL * vec) &#123;
	REAL x &#x3D; 0;
	for (INT i &#x3D; 0; i &lt; dimension; i++)
		x +&#x3D; (*(vec + i)) * (*(vec + i));
	x &#x3D; sqrt(x);
	if (x &gt; 1)
		for (INT i &#x3D; 0; i &lt; dimension; i++)
			*(vec + i) &#x2F;&#x3D; x;
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 从 train2id.txt 中读取三元组
&#x2F;&#x2F; prerequisites: 
&#x2F;&#x2F;     relation2id.txt, entity2id.txt, train2id.txt
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; relation_total: 关系总数
&#x2F;&#x2F; entity_total: 实体总数
&#x2F;&#x2F; train_triple_total: 训练集中的三元组总数
INT relation_total, entity_total, train_triple_total;

&#x2F;&#x2F; relation_vec (relation_total * dimension): 关系嵌入矩阵
&#x2F;&#x2F; entity_vec (entity_total * dimension): 实体嵌入矩阵
REAL *relation_vec, *entity_vec;

&#x2F;&#x2F; train_head (train_triple_total): 训练集中的三元组集合，以 head 排序
&#x2F;&#x2F; train_tail (train_triple_total): 训练集中的三元组集合，以 tail 排序
&#x2F;&#x2F; train_list (train_triple_total): 训练集中的三元组集合，未排序
Triple *train_head, *train_tail, *train_list;

&#x2F;&#x2F; left_head (entity_total): 存储每种实体 (head) 在 train_head 中第一次出现的位置
&#x2F;&#x2F; right_head (entity_total): 存储每种实体 (head) 在 train_head 中最后一次出现的位置
&#x2F;&#x2F; left_tail (entity_total): 存储每种实体 (tail) 在 train_tail 中第一次出现的位置
&#x2F;&#x2F; right_tail (entity_total): 存储每种实体 (tail) 在 train_tail 中最后一次出现的位置
INT *left_head, *right_head;
INT *left_tail, *right_tail;

&#x2F;&#x2F; left_mean (relation_total): 记录每种关系 head 的种类数
&#x2F;&#x2F; right_mean (relation_total): 记录每种关系 tail 的种类数
REAL *left_mean, *right_mean;

void init() &#123;

	FILE *fin;
	INT tmp;

	&#x2F;&#x2F; 初始化 relation_vec
	fin &#x3D; fopen((in_path + &quot;relation2id.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fin, &quot;%d&quot;, &amp;relation_total);
	fclose(fin);
	printf(&quot;relation_total: %d\n&quot;, relation_total);

	relation_vec &#x3D; (REAL *)calloc(relation_total * dimension,
			sizeof(REAL));
	for (INT i &#x3D; 0; i &lt; relation_total; i++) &#123;
		for (INT ii &#x3D; 0; ii &lt; dimension; ii++)
			relation_vec[i * dimension + ii] &#x3D;
				randn(0, 1.0 &#x2F; dimension, -6 &#x2F; sqrt(dimension),
					6 &#x2F; sqrt(dimension));
	&#125;

	&#x2F;&#x2F; 初始化 entity_vec
	fin &#x3D; fopen((in_path + &quot;entity2id.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fin, &quot;%d&quot;, &amp;entity_total);
	fclose(fin);
	printf(&quot;entity_total: %d\n&quot;, entity_total);

	entity_vec &#x3D; (REAL *)calloc(entity_total * dimension,
			sizeof(REAL));
	for (INT i &#x3D; 0; i &lt; entity_total; i++) &#123;
		for (INT ii &#x3D; 0; ii &lt; dimension; ii++)
			entity_vec[i * dimension + ii] &#x3D;
				randn(0, 1.0 &#x2F; dimension, -6 &#x2F; sqrt(dimension),
					6 &#x2F; sqrt(dimension));
	&#125;

	&#x2F;&#x2F; 读取训练集中的三元组
	fin &#x3D; fopen((in_path + &quot;train2id.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fin, &quot;%d&quot;, &amp;train_triple_total);
	train_head &#x3D; (Triple *)calloc(train_triple_total, sizeof(Triple));
	train_tail &#x3D; (Triple *)calloc(train_triple_total, sizeof(Triple));
	train_list &#x3D; (Triple *)calloc(train_triple_total, sizeof(Triple));
	for (INT i &#x3D; 0; i &lt; train_triple_total; i++) &#123;
		tmp &#x3D; fscanf(fin, &quot;%d&quot;, &amp;train_list[i].h);
		tmp &#x3D; fscanf(fin, &quot;%d&quot;, &amp;train_list[i].t);
		tmp &#x3D; fscanf(fin, &quot;%d&quot;, &amp;train_list[i].r);
		train_head[i] &#x3D; train_list[i];
		train_tail[i] &#x3D; train_list[i];
	&#125;
	fclose(fin);
	printf(&quot;train_triple_total: %d\n\n&quot;, train_triple_total);

	&#x2F;&#x2F; train_head 和 train_tail 分别以 head 和 tail 排序
	std::sort(train_head, train_head + train_triple_total, cmp_head());
	std::sort(train_tail, train_tail + train_triple_total, cmp_tail());

	&#x2F;&#x2F; 获得 left_head, right_head, left_tail, right_tail
	left_head &#x3D; (INT *)calloc(entity_total, sizeof(INT));
	right_head &#x3D; (INT *)calloc(entity_total, sizeof(INT));
	left_tail &#x3D; (INT *)calloc(entity_total, sizeof(INT));
	right_tail &#x3D; (INT *)calloc(entity_total, sizeof(INT));
	for (INT i &#x3D; 1; i &lt; train_triple_total; i++) &#123;
		if (train_head[i].h !&#x3D; train_head[i - 1].h) &#123;
			right_head[train_head[i - 1].h] &#x3D; i - 1;
			left_head[train_head[i].h] &#x3D; i;
		&#125;
		if (train_tail[i].t !&#x3D; train_tail[i - 1].t) &#123;
			right_tail[train_tail[i - 1].t] &#x3D; i - 1;
			left_tail[train_tail[i].t] &#x3D; i;
		&#125;
	&#125;
	right_head[train_head[train_triple_total - 1].h] &#x3D; train_triple_total - 1;
	right_tail[train_tail[train_triple_total - 1].t] &#x3D; train_triple_total - 1;

	&#x2F;&#x2F; 获得 left_mean、right_mean，为 train_mode 中的 bern_flag 做准备
	&#x2F;&#x2F; 在训练过程中，我们能够构建负三元组进行负采样
	&#x2F;&#x2F; bern 算法能根据特定关系的 head 和 tail 种类的比值，选择构建适当的负三元组
	&#x2F;&#x2F; train_mode 中的 bern_flag: pr &#x3D; left_mean &#x2F; (left_mean + right_mean)
	&#x2F;&#x2F; 因此为训练而构建的负三元组比 &#x3D; tail &#x2F; (tail + head)
	left_mean &#x3D; (REAL *)calloc(relation_total * 2, sizeof(REAL));
	right_mean &#x3D; left_mean + relation_total;
	for (INT i &#x3D; 0; i &lt; entity_total; i++) &#123;
		for (INT j &#x3D; left_head[i] + 1; j &lt;&#x3D; right_head[i]; j++)
			if (train_head[j].r !&#x3D; train_head[j - 1].r)
				left_mean[train_head[j].r] +&#x3D; 1.0;
		if (left_head[i] &lt;&#x3D; right_head[i])
			left_mean[train_head[left_head[i]].r] +&#x3D; 1.0;
		for (INT j &#x3D; left_tail[i] + 1; j &lt;&#x3D; right_tail[i]; j++)
			if (train_tail[j].r !&#x3D; train_tail[j - 1].r)
				right_mean[train_tail[j].r] +&#x3D; 1.0;
		if (left_tail[i] &lt;&#x3D; right_tail[i])
			right_mean[train_tail[left_tail[i]].r] +&#x3D; 1.0;
	&#125;
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 加载 Pretrained Embeddings
&#x2F;&#x2F; prerequisites: 
&#x2F;&#x2F;     entity2vec + note + .bin
&#x2F;&#x2F;     relation2vec + note + .bin
&#x2F;&#x2F;     
&#x2F;&#x2F;     or
&#x2F;&#x2F;
&#x2F;&#x2F;     entity2vec + note + .vec
&#x2F;&#x2F;     relation2vec + note + .vec
&#x2F;&#x2F; ##################################################

void load_binary() &#123;

	&#x2F;&#x2F; 以二进制形式加载预训练实体嵌入
	struct stat statbuf1;
	if (stat((load_path + &quot;entity2vec&quot; + note + &quot;.bin&quot;).c_str(),
			&amp;statbuf1) !&#x3D; -1) &#123;  
		INT fd &#x3D; open((load_path + &quot;entity2vec&quot; + note + &quot;.bin&quot;).c_str(),
			O_RDONLY);
		REAL* entity_vec_tmp &#x3D; (REAL*)mmap(NULL, statbuf1.st_size,
			PROT_READ, MAP_PRIVATE, fd, 0); 
		memcpy(entity_vec, entity_vec_tmp, statbuf1.st_size);
		munmap(entity_vec_tmp, statbuf1.st_size);
		close(fd);
		printf(&quot;%s&quot;, (&quot;以二进制形式加载预训练实体嵌入 (&quot; + load_path + &quot;entity2vec&quot; + note + &quot;.bin&quot; + &quot;) 成功.\n&quot;).c_str());
	&#125;

	&#x2F;&#x2F; 以二进制形式加载预训练关系嵌入
	struct stat statbuf2;
	if (stat((load_path + &quot;relation2vec&quot; + note + &quot;.bin&quot;).c_str(),
			&amp;statbuf2) !&#x3D; -1) &#123;  
		INT fd &#x3D; open((load_path + &quot;relation2vec&quot; + note + &quot;.bin&quot;).c_str(),
			O_RDONLY);
		REAL* relation_vec_tmp &#x3D;(REAL*)mmap(NULL, statbuf2.st_size,
			PROT_READ, MAP_PRIVATE, fd, 0); 
		memcpy(relation_vec, relation_vec_tmp, statbuf2.st_size);
		munmap(relation_vec_tmp, statbuf2.st_size);
		close(fd);
		printf(&quot;%s&quot;, (&quot;以二进制形式加载预训练关系嵌入 (&quot; + load_path + &quot;relation2vec&quot; + note + &quot;.bin&quot; + &quot;) 成功.\n\n&quot;).c_str());
	&#125;
&#125;

void load() &#123;
	
	if (load_binary_flag) &#123;
		load_binary();
		return;
	&#125;
	FILE *fin;
	INT tmp;

	&#x2F;&#x2F; 加载预训练实体嵌入
	fin &#x3D; fopen((load_path + &quot;entity2vec&quot; + note + &quot;.vec&quot;).c_str(), &quot;r&quot;);
	for (INT i &#x3D; 0; i &lt; entity_total; i++) &#123;
		INT last &#x3D; i * dimension;
		for (INT j &#x3D; 0; j &lt; dimension; j++)
			tmp &#x3D; fscanf(fin, &quot;%f&quot;, &amp;entity_vec[last + j]);
	&#125;
	fclose(fin);
	printf(&quot;%s&quot;, (&quot;加载预训练实体嵌入 (&quot; + load_path + &quot;entity2vec&quot; + note + &quot;.vec&quot; + &quot;) 成功.\n&quot;).c_str());

	&#x2F;&#x2F; 加载预训练关系嵌入
	fin &#x3D; fopen((load_path + &quot;relation2vec&quot; + note + &quot;.vec&quot;).c_str(), &quot;r&quot;);
	for (INT i &#x3D; 0; i &lt; relation_total; i++) &#123;
		INT last &#x3D; i * dimension;
		for (INT j &#x3D; 0; j &lt; dimension; j++)
			tmp &#x3D; fscanf(fin, &quot;%f&quot;, &amp;relation_vec[last + j]);
	&#125;
	fclose(fin);
	printf(&quot;%s&quot;, (&quot;加载预训练关系嵌入 (&quot; + load_path + &quot;relation2vec&quot; + note + &quot;.vec&quot; + &quot;) 成功.\n\n&quot;).c_str());
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; Update embeddings
&#x2F;&#x2F; ##################################################

INT Len;
INT Batch;

&#x2F;&#x2F; 由于没有使用互斥锁、读写锁、条件变量和信号量等手段进行线程同步
&#x2F;&#x2F; 所以 res 可能被不同线程同时访问并修改，因此 res 会比真实值略小
&#x2F;&#x2F; 但由于 res 只是为了直观地看到损失值的变化趋势，因此不需要通过
&#x2F;&#x2F; 线程同步（降低程序性能）获得精确结果
REAL res;

&#x2F;&#x2F; 使用 L1 范数计算能量 d(h + l, t)
REAL calc_sum(INT e1, INT e2, INT rel) &#123;
	REAL sum &#x3D; 0;
	INT last1 &#x3D; e1 * dimension;
	INT last2 &#x3D; e2 * dimension;
	INT lastr &#x3D; rel * dimension;
	for (INT i &#x3D; 0; i &lt; dimension; i++)
		sum +&#x3D; fabs(entity_vec[last2 + i] -
			entity_vec[last1 + i] - relation_vec[lastr + i]);
	return sum;
&#125;

&#x2F;&#x2F; 根据 d(h + l, t) 更新实体和关系嵌入
&#x2F;&#x2F; (e1_a, rel_a, e2_a): 正三元组
&#x2F;&#x2F; (e1_b, rel_b, e2_b): 负三元组
void gradient(INT e1_a, INT e2_a, INT rel_a, INT e1_b, INT e2_b, INT rel_b) &#123;
	INT lasta1 &#x3D; e1_a * dimension;
	INT lasta2 &#x3D; e2_a * dimension;
	INT lastar &#x3D; rel_a * dimension;
	INT lastb1 &#x3D; e1_b * dimension;
	INT lastb2 &#x3D; e2_b * dimension;
	INT lastbr &#x3D; rel_b * dimension;

	for (INT i &#x3D; 0; i  &lt; dimension; i++) &#123;
		REAL x;

		&#x2F;&#x2F; 尽可能让 d(e1_a, rel_a, e2_a) 接近 0
		x &#x3D; (entity_vec[lasta2 + i] -
			entity_vec[lasta1 + i] - relation_vec[lastar + i]);
		if (x &gt; 0)
			x &#x3D; -alpha;
		else
			x &#x3D; alpha;
		relation_vec[lastar + i] -&#x3D; x;
		entity_vec[lasta1 + i] -&#x3D; x;
		entity_vec[lasta2 + i] +&#x3D; x;

		&#x2F;&#x2F; 尽可能让 d(e1_b, rel_b, e2_b) 远离 0
		x &#x3D; (entity_vec[lastb2 + i] -
			entity_vec[lastb1 + i] - relation_vec[lastbr + i]);
		if (x &gt; 0)
			x &#x3D; alpha;
		else
			x &#x3D; -alpha;
		relation_vec[lastbr + i] -&#x3D;  x;
		entity_vec[lastb1 + i] -&#x3D; x;
		entity_vec[lastb2 + i] +&#x3D; x;
	&#125;
&#125;

&#x2F;&#x2F; 损失函数 L &#x3D; [margin + d(e1_a, rel_a, e2_a) - d(e1_b, rel_b, e2_b)]+
&#x2F;&#x2F; 当 L &gt; 0，说明 (d(e1_b, rel_b, e2_b) - d(e1_a, rel_a, e2_a)) &lt; margin，
&#x2F;&#x2F; 进而，正负三元组的实体和关系嵌入需要 update
void train_kb(INT e1_a, INT e2_a, INT rel_a, INT e1_b, INT e2_b, INT rel_b) &#123;
	REAL sum1 &#x3D; calc_sum(e1_a, e2_a, rel_a);
	REAL sum2 &#x3D; calc_sum(e1_b, e2_b, rel_b);
	if (sum1 + margin &gt; sum2) &#123;
		res +&#x3D; margin + sum1 - sum2;
		gradient(e1_a, e2_a, rel_a, e1_b, e2_b, rel_b);
	&#125;
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 构建负三元组
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; 用 head 和 relationship 构建负三元组，即替换 tail
&#x2F;&#x2F; 该函数返回负三元组的 tail
INT corrupt_with_head(INT id, INT h, INT r) &#123;
	INT lef, rig, mid, ll, rr;

	&#x2F;&#x2F; lef: head(h) 在 train_head 中第一次出现的前一个位置
	&#x2F;&#x2F; rig: head(h) 在 train_head 中最后一次出现的位置
	lef &#x3D; left_head[h] - 1;
	rig &#x3D; right_head[h];
	while (lef + 1 &lt; rig) &#123;
		mid &#x3D; (lef + rig) &gt;&gt; 1;
		&#x2F;&#x2F; 二分查找算法变体
		&#x2F;&#x2F; 由于 &gt;&#x3D; -&gt; rig，所以 rig 最终在第一个 r 的位置
		if (train_head[mid].r &gt;&#x3D; r) rig &#x3D; mid; else lef &#x3D; mid;
	&#125;
	ll &#x3D; rig;

	lef &#x3D; left_head[h];
	rig &#x3D; right_head[h] + 1;
	while (lef + 1 &lt; rig) &#123;
		mid &#x3D; (lef + rig) &gt;&gt; 1;
		&#x2F;&#x2F; 二分查找算法变体
		&#x2F;&#x2F; 由于 &lt;&#x3D; -&gt; lef，所以 lef 最终在最后一个 r 的位置
		if (train_head[mid].r &lt;&#x3D; r) lef &#x3D; mid; else rig &#x3D; mid;
	&#125;
	rr &#x3D; lef;

	&#x2F;&#x2F; 只能产生 (entity_total - (rr - ll + 1)) 种实体，即去掉训练集中已有的三元组
	INT tmp &#x3D; rand_max(id, entity_total - (rr - ll + 1));

	&#x2F;&#x2F; 第一种：tmp 小于第一个 r 对应的 tail
	if (tmp &lt; train_head[ll].t) return tmp;

	&#x2F;&#x2F; 第二种：tmp 大于最后一个 r 对应的 tail
	if (tmp &gt; train_head[rr].t - rr + ll - 1) return tmp + rr - ll + 1;

	&#x2F;&#x2F; 第三种：由于 (&gt;&#x3D; -&gt; rig), (lef + 1 &lt; rig), (tmp + lef - ll + 1)
	&#x2F;&#x2F; 因此最终返回取值为 (train_head[lef].t, train_head[rig].t) 的 tail
	lef &#x3D; ll, rig &#x3D; rr + 1;
	while (lef + 1 &lt; rig) &#123;
		mid &#x3D; (lef + rig) &gt;&gt; 1;
		if (train_head[mid].t - mid + ll - 1 &lt; tmp)
			lef &#x3D; mid;
		else
			rig &#x3D; mid;
	&#125;
	return tmp + lef - ll + 1;
&#125;

&#x2F;&#x2F; 用 tail 和 relationship 构建负三元组，即替换 head
&#x2F;&#x2F; 该函数返回负三元组的 head
INT corrupt_with_tail(INT id, INT t, INT r) &#123;
	INT lef, rig, mid, ll, rr;

	&#x2F;&#x2F; lef: tail(t) 在 train_tail 中第一次出现的前一个位置
	&#x2F;&#x2F; rig: tail(t) 在 train_tail 中最后一次出现的位置
	lef &#x3D; left_tail[t] - 1;
	rig &#x3D; right_tail[t];
	while (lef + 1 &lt; rig) &#123;
		mid &#x3D; (lef + rig) &gt;&gt; 1;
		&#x2F;&#x2F; 二分查找算法变体
		&#x2F;&#x2F; 由于 &gt;&#x3D; -&gt; rig，所以 rig 最终在第一个 r 的位置
		if (train_tail[mid].r &gt;&#x3D; r) rig &#x3D; mid; else lef &#x3D; mid;
	&#125;
	ll &#x3D; rig;
	lef &#x3D; left_tail[t];
	rig &#x3D; right_tail[t] + 1;
	while (lef + 1 &lt; rig) &#123;
		mid &#x3D; (lef + rig) &gt;&gt; 1;
		&#x2F;&#x2F; 二分查找算法变体
		&#x2F;&#x2F; 由于 &lt;&#x3D; -&gt; lef，所以 lef 最终在最后一个 r 的位置
		if (train_tail[mid].r &lt;&#x3D; r) lef &#x3D; mid; else rig &#x3D; mid;
	&#125;
	rr &#x3D; lef;

	&#x2F;&#x2F; 只能产生 (entity_total - (rr - ll + 1)) 种实体，即去掉训练集中已有的三元组
	INT tmp &#x3D; rand_max(id, entity_total - (rr - ll + 1));

	&#x2F;&#x2F; 第一种：tmp 小于第一个 r 对应的 head
	if (tmp &lt; train_tail[ll].h) return tmp;

	&#x2F;&#x2F; 第二种：tmp 大于最后一个 r 对应的 head
	if (tmp &gt; train_tail[rr].h - rr + ll - 1) return tmp + rr - ll + 1;

	&#x2F;&#x2F; 第三种：由于 (&gt;&#x3D; -&gt; rig), (lef + 1 &lt; rig), (tmp + lef - ll + 1)
	&#x2F;&#x2F; 因此最终返回取值为 (train_tail[lef].h, train_tail[rig].h) 的 head
	lef &#x3D; ll, rig &#x3D; rr + 1;
	while (lef + 1 &lt; rig) &#123;
		mid &#x3D; (lef + rig) &gt;&gt; 1;
		if (train_tail[mid].h - mid + ll - 1 &lt; tmp)
			lef &#x3D; mid;
		else 
			rig &#x3D; mid;
	&#125;
	return tmp + lef - ll + 1;
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 多个线程训练
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; 单个线程内运行的任务
void* train_mode(void *thread_id) &#123;
	INT id, pr, i, j;

	&#x2F;&#x2F; id: 线程 ID
	id &#x3D; (unsigned long long)(thread_id);
	next_random[id] &#x3D; rand();

	&#x2F;&#x2F; 每一个 Batch 被多个线程同时训练
	for (INT k &#x3D; Batch &#x2F; threads; k &gt;&#x3D; 0; k--) &#123;
		i &#x3D; rand_max(id, Len);
		if (bern_flag)
			pr &#x3D; 1000 * left_mean[train_list[i].r] &#x2F;
				(left_mean[train_list[i].r] + right_mean[train_list[i].r]);
		else
			pr &#x3D; 500;
		if (randd(id) % 1000 &lt; pr) &#123;
			
			&#x2F;&#x2F; 通过 h, r 构造出负三元组
			j &#x3D; corrupt_with_head(id, train_list[i].h, train_list[i].r);
			train_kb(train_list[i].h, train_list[i].t, train_list[i].r,
				train_list[i].h, j, train_list[i].r);
		&#125; else &#123;

			&#x2F;&#x2F; 通过 t, r 构造出负三元组
			j &#x3D; corrupt_with_tail(id, train_list[i].t, train_list[i].r);
			train_kb(train_list[i].h, train_list[i].t, train_list[i].r,
				j, train_list[i].t, train_list[i].r);
		&#125;

		&#x2F;&#x2F; 对于 entity_vec 和 relation_vec 进行归一化
		norm(relation_vec + dimension * train_list[i].r);
		norm(entity_vec + dimension * train_list[i].h);
		norm(entity_vec + dimension * train_list[i].t);
		norm(entity_vec + dimension * j);
	&#125;

	pthread_exit(NULL);
&#125;

&#x2F;&#x2F; 训练函数
void* train() &#123;
	Len &#x3D; train_triple_total;
	Batch &#x3D; Len &#x2F; nbatches;
	next_random &#x3D; (unsigned long long *)calloc(threads, sizeof(unsigned long long));

	for (INT epoch &#x3D; 1; epoch &lt;&#x3D; epochs; epoch++) &#123;
		res &#x3D; 0;
		for (INT batch &#x3D; 0; batch &lt; nbatches; batch++) &#123;
			pthread_t *pt &#x3D; (pthread_t *)malloc(threads * sizeof(pthread_t));
			for (long a &#x3D; 0; a &lt; threads; a++)
				pthread_create(&amp;pt[a], NULL, train_mode,  (void*)a);
			for (long a &#x3D; 0; a &lt; threads; a++)
				pthread_join(pt[a], NULL);
			free(pt);
		&#125;
		
		if (epoch % 50 &#x3D;&#x3D; 0)
			printf(&quot;Epoch %d&#x2F;%d - loss: %f\n&quot;, epoch, epochs, res);
	&#125;
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 输出实体嵌入和关系嵌入
&#x2F;&#x2F; output: 
&#x2F;&#x2F;     entity2vec + note + .bin
&#x2F;&#x2F;     relation2vec + note + .bin
&#x2F;&#x2F;     
&#x2F;&#x2F;     or
&#x2F;&#x2F;
&#x2F;&#x2F;     entity2vec + note + .vec
&#x2F;&#x2F;     relation2vec + note + .vec
&#x2F;&#x2F; ##################################################

void out_binary() &#123;
		
	INT len, tot;
	REAL *head;	
	FILE* f1 &#x3D; fopen((out_path + &quot;entity2vec&quot; + note + &quot;.bin&quot;).c_str(), &quot;wb&quot;);
	FILE* f2 &#x3D; fopen((out_path + &quot;relation2vec&quot; + note + &quot;.bin&quot;).c_str(), &quot;wb&quot;);

	&#x2F;&#x2F; 以二进制形式输出实体嵌入
	len &#x3D; entity_total * dimension; tot &#x3D; 0;
	head &#x3D; entity_vec;
	while (tot &lt; len) &#123;
		INT sum &#x3D; fwrite(head + tot, sizeof(REAL), len - tot, f1);
		tot &#x3D; tot + sum;
	&#125;
	printf(&quot;%s&quot;, (&quot;\n以二进制形式输出实体嵌入 (&quot; + out_path + &quot;entity2vec&quot; + note + &quot;.bin&quot; + &quot;) 成功.\n&quot;).c_str());

	&#x2F;&#x2F; 以二进制形式输出关系嵌入
	len &#x3D; relation_total * dimension; tot &#x3D; 0;
	head &#x3D; relation_vec;
	while (tot &lt; len) &#123;
		INT sum &#x3D; fwrite(head + tot, sizeof(REAL), len - tot, f2);
		tot &#x3D; tot + sum;
	&#125;
	printf(&quot;%s&quot;, (&quot;以二进制形式输出关系嵌入 (&quot; + out_path + &quot;relation2vec&quot; + note + &quot;.bin&quot; + &quot;) 成功.\n&quot;).c_str());
		
	fclose(f1);
	fclose(f2);
&#125;

void out() &#123;

	if (out_binary_flag) &#123;
		out_binary(); 
		return;
	&#125;

	FILE* f1 &#x3D; fopen((out_path + &quot;entity2vec&quot; + note + &quot;.vec&quot;).c_str(), &quot;w&quot;);
	FILE* f2 &#x3D; fopen((out_path + &quot;relation2vec&quot; + note + &quot;.vec&quot;).c_str(), &quot;w&quot;);

	&#x2F;&#x2F; 输出预训练实体嵌入
	for (INT  i &#x3D; 0; i &lt; entity_total; i++) &#123;
		INT last &#x3D; i * dimension;
		for (INT j &#x3D; 0; j &lt; dimension; j++)
			fprintf(f1, &quot;%.6f\t&quot;, entity_vec[last + j] );
		fprintf(f1,&quot;\n&quot;);
	&#125;
	printf(&quot;%s&quot;, (&quot;\n输出预训练实体嵌入 (&quot; + out_path + &quot;entity2vec&quot; + note + &quot;.vec&quot; + &quot;) 成功.\n&quot;).c_str());

	&#x2F;&#x2F; 输出预训练关系嵌入
	for (INT i &#x3D; 0; i &lt; relation_total; i++) &#123;
		INT last &#x3D; dimension * i;
		for (INT j &#x3D; 0; j &lt; dimension; j++)
			fprintf(f2, &quot;%.6f\t&quot;, relation_vec[last + j]);
		fprintf(f2,&quot;\n&quot;);
	&#125;
	printf(&quot;%s&quot;, (&quot;输出预训练关系嵌入 (&quot; + out_path + &quot;relation2vec&quot; + note + &quot;.vec&quot; + &quot;) 成功.\n&quot;).c_str());

	fclose(f1);
	fclose(f2);
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; Main function
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; 寻找特定参数的位置
INT arg_pos(char *str, INT argc, char **argv) &#123;
	INT a;
	for (a &#x3D; 1; a &lt; argc; a++) if (!strcmp(str, argv[a])) &#123;
		if (a &#x3D;&#x3D; argc - 1) &#123;
			printf(&quot;Argument missing for %s\n&quot;, str);
			exit(1);
		&#125;
		return a;
	&#125;
	return -1;
&#125;

void setparameters(INT argc, char **argv) &#123;
	INT i;
	if ((i &#x3D; arg_pos((char *)&quot;-bern&quot;, argc, argv)) &gt; 0) bern_flag &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-load-binary&quot;, argc, argv)) &gt; 0) load_binary_flag &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-out-binary&quot;, argc, argv)) &gt; 0) out_binary_flag &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-size&quot;, argc, argv)) &gt; 0) dimension &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-alpha&quot;, argc, argv)) &gt; 0) alpha &#x3D; atof(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-margin&quot;, argc, argv)) &gt; 0) margin &#x3D; atof(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-nbatches&quot;, argc, argv)) &gt; 0) nbatches &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-epochs&quot;, argc, argv)) &gt; 0) epochs &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-threads&quot;, argc, argv)) &gt; 0) threads &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-input&quot;, argc, argv)) &gt; 0) in_path &#x3D; argv[i + 1];
	if ((i &#x3D; arg_pos((char *)&quot;-output&quot;, argc, argv)) &gt; 0) out_path &#x3D; argv[i + 1];
	if ((i &#x3D; arg_pos((char *)&quot;-load&quot;, argc, argv)) &gt; 0) load_path &#x3D; argv[i + 1];	
	if ((i &#x3D; arg_pos((char *)&quot;-note&quot;, argc, argv)) &gt; 0) note &#x3D; argv[i + 1];
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; .&#x2F;transE [-bern 0&#x2F;1] [-load-binary 0&#x2F;1] [-out-binary 0&#x2F;1]
&#x2F;&#x2F;          [-size SIZE] [-alpha ALPHA] [-margin MARGIN]
&#x2F;&#x2F;          [-nbatches NBATCHES] [-epochs EPOCHS]
&#x2F;&#x2F;          [-threads THREAD] [-input INPUT] [-output OUTPUT]
&#x2F;&#x2F;          [-load LOAD] [-note NOTE]

&#x2F;&#x2F; optional arguments:
&#x2F;&#x2F; -bern [0&#x2F;1]          [1] 使用 bern 算法进行负采样，默认值为 [1]
&#x2F;&#x2F; -load-binary [0&#x2F;1]   [1] 以二进制形式加载预训练嵌入，默认值为 [0]
&#x2F;&#x2F; -out-binary [0&#x2F;1]    [1] 以二进制形式输出嵌入，默认值为 [0]
&#x2F;&#x2F; -size SIZE           实体和关系嵌入维度，默认值为 [50]
&#x2F;&#x2F; -alpha ALPHA         学习率，默认值为 0.01
&#x2F;&#x2F; -margin MARGIN       margin in max-margin loss for pairwise training，默认值为 1.0
&#x2F;&#x2F; -nbatches NBATCHES   number of batches for each epoch. if unspecified, nbatches will default to 1
&#x2F;&#x2F; -epochs EPOCHS       number of epochs. if unspecified, epochs will default to 1000
&#x2F;&#x2F; -threads THREAD      number of worker threads. if unspecified, threads will default to 32
&#x2F;&#x2F; -input INPUT         folder of training data. if unspecified, in_path will default to &quot;..&#x2F;data&#x2F;FB15K&#x2F;&quot;
&#x2F;&#x2F; -output OUTPUT       folder of outputing results. if unspecified, out_path will default to &quot;.&#x2F;build&#x2F;&quot;
&#x2F;&#x2F; -load LOAD           folder of pretrained data. if unspecified, load_path will default to &quot;&quot;
&#x2F;&#x2F; -note NOTE           information you want to add to the filename. if unspecified, note will default to &quot;&quot;
&#x2F;&#x2F; ##################################################

INT main(INT argc, char **argv) &#123;

	printf(&quot;##################################################\n\n&quot;);
	printf(&quot;训练开始:\n\n&quot;);

	struct timeval start, end;
	gettimeofday(&amp;start, NULL);

	setparameters(argc, argv);
	init();
	if (load_path !&#x3D; &quot;&quot;) load();
	train();
	if (out_path !&#x3D; &quot;&quot;) out();
	
	gettimeofday(&amp;end, NULL);
	long double time_use &#x3D; 1000000 * (end.tv_sec - start.tv_sec) + end.tv_usec - start.tv_usec;

	printf(&quot;\n训练结束, 用时 %.6Lf 秒.\n\n&quot;, time_use&#x2F;1000000.0);
	printf(&quot;##################################################\n\n&quot;);

	return 0;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="test-transE-cpp"><a href="#test-transE-cpp" class="headerlink" title="test_transE.cpp"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/knowledge-representation-learning/C%2B%2B/TransE/test_transE.cpp">test_transE.cpp</a></h4><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; test_transE.cpp
&#x2F;&#x2F; 使用方法:
&#x2F;&#x2F;     编译:
&#x2F;&#x2F;           $ g++ test_transE.cpp -o .&#x2F;build&#x2F;test_transE -pthread -O3 -march&#x3D;native
&#x2F;&#x2F;     运行:
&#x2F;&#x2F;           $ .&#x2F;build&#x2F;test_transE
&#x2F;&#x2F;
&#x2F;&#x2F; created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com&gt;
&#x2F;&#x2F;
&#x2F;&#x2F; 该 C++ 文件用于模型测试
&#x2F;&#x2F;
&#x2F;&#x2F; prerequisites: 
&#x2F;&#x2F;     relation2id.txt, entity2id.txt, test2id_all.txt
&#x2F;&#x2F;     train2id.txt、valid2id.txt、type_constrain.txt
&#x2F;&#x2F;
&#x2F;&#x2F; 加载 Pretrained Embeddings
&#x2F;&#x2F; prerequisites: 
&#x2F;&#x2F;     entity2vec + note + .bin
&#x2F;&#x2F;     relation2vec + note + .bin
&#x2F;&#x2F;     
&#x2F;&#x2F;     or
&#x2F;&#x2F;
&#x2F;&#x2F;     entity2vec + note + .vec
&#x2F;&#x2F;     relation2vec + note + .vec

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 包含标准库
&#x2F;&#x2F; ##################################################

#include &lt;cstdio&gt;           &#x2F;&#x2F; FILE, fscanf, fopen, fclose
#include &lt;cstdlib&gt;          &#x2F;&#x2F; malloc, calloc, free, atoi
#include &lt;cmath&gt;            &#x2F;&#x2F; fabs
#include &lt;cstring&gt;          &#x2F;&#x2F; memcpy, strcmp, memset
#include &lt;fcntl.h&gt;          &#x2F;&#x2F; open, close, O_RDONLY
#include &lt;unistd.h&gt;         &#x2F;&#x2F; stat
#include &lt;sys&#x2F;stat.h&gt;       &#x2F;&#x2F; stat
#include &lt;sys&#x2F;mman.h&gt;       &#x2F;&#x2F; mmap, munmap
#include &lt;sys&#x2F;time.h&gt;       &#x2F;&#x2F; timeval, gettimeofday
#include &lt;pthread.h&gt;        &#x2F;&#x2F; pthread_create, pthread_exit, pthread_join
#include &lt;string&gt;           &#x2F;&#x2F; std::string, std::string::c_str
#include &lt;algorithm&gt;        &#x2F;&#x2F; std::sort

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 声明和定义变量
&#x2F;&#x2F; ##################################################

#define REAL float
#define INT int

INT load_binary_flag &#x3D; 0;
INT dimension &#x3D; 50;
INT threads &#x3D; 32;

std::string in_path &#x3D; &quot;..&#x2F;data&#x2F;FB15K&#x2F;&quot;;
std::string load_path &#x3D; &quot;.&#x2F;build&#x2F;&quot;;
std::string note &#x3D; &quot;&quot;;

&#x2F;&#x2F; 三元组: (head, label, tail)
&#x2F;&#x2F; h: head
&#x2F;&#x2F; r: label or relationship
&#x2F;&#x2F; t: tail
&#x2F;&#x2F; label(head-tail, relationship type):
&#x2F;&#x2F;     1: 1-1
&#x2F;&#x2F;     2: 1-n
&#x2F;&#x2F;     3: n-1
&#x2F;&#x2F;     4: n-n
&#x2F;&#x2F; a relationship of name label between the entities head and tail
struct Triple &#123;
	INT h, r, t;
	INT label;
&#125;;

&#x2F;&#x2F; 为 std::sort() 定义比较仿函数
&#x2F;&#x2F; 以三元组的 head 进行比较
struct cmp_head &#123;
	bool operator()(const Triple &amp;a, const Triple &amp;b) &#123;
		return (a.h &lt; b.h)||(a.h &#x3D;&#x3D; b.h &amp;&amp; a.r &lt; b.r)
		        ||(a.h &#x3D;&#x3D; b.h &amp;&amp; a.r &#x3D;&#x3D; b.r &amp;&amp; a.t &lt; b.t);
	&#125;
&#125;;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 从 test2id_all.txt、train2id.txt、valid2id.txt 中读取三元组
&#x2F;&#x2F; prerequisites: 
&#x2F;&#x2F;     relation2id.txt, entity2id.txt, test2id_all.txt
&#x2F;&#x2F;     train2id.txt、valid2id.txt、type_constrain.txt
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; relation_total: 关系总数
&#x2F;&#x2F; entity_total: 实体总数
INT relation_total;
INT entity_total;

&#x2F;&#x2F; relation_vec (relation_total * dimension): 关系嵌入矩阵
&#x2F;&#x2F; entity_vec (entity_total * dimension): 实体嵌入矩阵
REAL *relation_vec, *entity_vec;

&#x2F;&#x2F; test_total: 测试集中的三元组总数
&#x2F;&#x2F; train_total: 训练集中的三元组总数
&#x2F;&#x2F; valid_total: 验证集中的三元组总数
&#x2F;&#x2F; triple_total: 测试集、训练集、验证集中的三元组总数，以 head 排序
INT test_total, train_total, valid_total, triple_total;

&#x2F;&#x2F; test_list (test_total): 测试集中的三元组集合
&#x2F;&#x2F; triple_list (triple_total): 测试集、训练集、验证集中的三元组集合
Triple *test_list, *triple_list;

&#x2F;&#x2F; 统计测试集中各种三元组 (关系: 1-1, 1-n, n-1, n-n) 的数量
&#x2F;&#x2F; nntotal[1]: 1-1, nntotal[2]: 1-n, nntotal[3]: n-1, nntotal[4]: n-n
INT nntotal[5];

&#x2F;&#x2F; head_type: 存储各个关系的 head 类型, 各个关系的 head 类型独立地以升序排列
&#x2F;&#x2F; tail_type: 存储各个关系的 tail 类型, 各个关系的 tail 类型独立地以升序排列
INT head_type[1000000];
INT tail_type[1000000];

&#x2F;&#x2F; head_left: 记录各个关系的 head 类型在 head_type 中第一次出现的位置
&#x2F;&#x2F; head_right: 记录各个关系的 head 类型在 head_type 中最后一次出现的后一个位置
&#x2F;&#x2F; tail_left: 记录各个关系的 tail 类型在 tail_type 中第一次出现的位置
&#x2F;&#x2F; tail_right: 记录各个关系的 tail 类型在 tail_type 中最后一次出现的后一个位置
INT head_left[10000];
INT head_right[10000];
INT tail_left[10000];
INT tail_right[10000];

void init() &#123;

	FILE *fin;
	INT tmp, h, r, t, label;

	&#x2F;&#x2F; 为 relation_vec 分配一个内存块，并将其所有位初始化为零
	fin &#x3D; fopen((in_path + &quot;relation2id.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fin, &quot;%d&quot;, &amp;relation_total);
	fclose(fin);
	relation_vec &#x3D; (REAL *)calloc(relation_total * dimension, sizeof(REAL));

	&#x2F;&#x2F; 为 entity_vec 分配一个内存块，并将其所有位初始化为零
	fin &#x3D; fopen((in_path + &quot;entity2id.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fin, &quot;%d&quot;, &amp;entity_total);
	fclose(fin);
	entity_vec &#x3D; (REAL *)calloc(entity_total * dimension, sizeof(REAL));

	&#x2F;&#x2F; 读取测试集、训练集、验证集中的三元组
	FILE* f_kb1 &#x3D; fopen((in_path + &quot;test2id_all.txt&quot;).c_str(), &quot;r&quot;);
	FILE* f_kb2 &#x3D; fopen((in_path + &quot;train2id.txt&quot;).c_str(), &quot;r&quot;);
	FILE* f_kb3 &#x3D; fopen((in_path + &quot;valid2id.txt&quot;).c_str(), &quot;r&quot;);

	tmp &#x3D; fscanf(f_kb1, &quot;%d&quot;, &amp;test_total);
	tmp &#x3D; fscanf(f_kb2, &quot;%d&quot;, &amp;train_total);
	tmp &#x3D; fscanf(f_kb3, &quot;%d&quot;, &amp;valid_total);
	triple_total &#x3D; test_total + train_total + valid_total;
	test_list &#x3D; (Triple *)calloc(test_total, sizeof(Triple));
	triple_list &#x3D; (Triple *)calloc(triple_total, sizeof(Triple));

	&#x2F;&#x2F; 将 nntotal 的内存初始化为 0
	memset(nntotal, 0, sizeof(nntotal));

	for (INT i &#x3D; 0; i &lt; test_total; i++) &#123;
		tmp &#x3D; fscanf(f_kb1, &quot;%d&quot;, &amp;label);
		tmp &#x3D; fscanf(f_kb1, &quot;%d&quot;, &amp;h);
		tmp &#x3D; fscanf(f_kb1, &quot;%d&quot;, &amp;t);
		tmp &#x3D; fscanf(f_kb1, &quot;%d&quot;, &amp;r);
		label++;
		nntotal[label]++;
		test_list[i].label &#x3D; label;
		test_list[i].h &#x3D; h;
		test_list[i].t &#x3D; t;
		test_list[i].r &#x3D; r;
		triple_list[i].h &#x3D; h;
		triple_list[i].t &#x3D; t;
		triple_list[i].r &#x3D; r;
	&#125;

	for (INT i &#x3D; 0; i &lt; train_total; i++) &#123;
		tmp &#x3D; fscanf(f_kb2, &quot;%d&quot;, &amp;h);
		tmp &#x3D; fscanf(f_kb2, &quot;%d&quot;, &amp;t);
		tmp &#x3D; fscanf(f_kb2, &quot;%d&quot;, &amp;r);
		triple_list[i + test_total].h &#x3D; h;
		triple_list[i + test_total].t &#x3D; t;
		triple_list[i + test_total].r &#x3D; r;
	&#125;

	for (INT i &#x3D; 0; i &lt; valid_total; i++) &#123;
		tmp &#x3D; fscanf(f_kb3, &quot;%d&quot;, &amp;h);
		tmp &#x3D; fscanf(f_kb3, &quot;%d&quot;, &amp;t);
		tmp &#x3D; fscanf(f_kb3, &quot;%d&quot;, &amp;r);
		triple_list[i + test_total + train_total].h &#x3D; h;
		triple_list[i + test_total + train_total].t &#x3D; t;
		triple_list[i + test_total + train_total].r &#x3D; r;
	&#125;

	fclose(f_kb1);
	fclose(f_kb2);
	fclose(f_kb3);

	&#x2F;&#x2F; triple_list 用 head 排序
	std::sort(triple_list, triple_list + triple_total, cmp_head());

	&#x2F;&#x2F; type_constrain.txt: 类型约束文件, 第一行是关系的个数
	&#x2F;&#x2F; 下面的行是每个关系的类型限制 (训练集、验证集、测试集中每个关系存在的 head 和 tail 的类型)
	&#x2F;&#x2F; 每个关系有两行：
	&#x2F;&#x2F; 第一行：&#96;id of relation&#96; &#96;Number of head types&#96; &#96;head1&#96; &#96;head2&#96; ...
	&#x2F;&#x2F; 第二行: &#96;id of relation&#96; &#96;number of tail types&#96; &#96;tail1&#96; &#96;tail2&#96; ...
	&#x2F;&#x2F;
	&#x2F;&#x2F; For example, the relation with id 1200 has 4 types of head entities, which are 3123, 1034, 58 and 5733
	&#x2F;&#x2F; The relation with id 1200 has 4 types of tail entities, which are 12123, 4388, 11087 and 11088
	&#x2F;&#x2F; 1200	4	3123	1034	58	5733
	&#x2F;&#x2F; 1200	4	12123	4388	11087	11088
	INT total_left &#x3D; 0;
	INT total_right &#x3D; 0;
	FILE* f_type &#x3D; fopen((in_path + &quot;type_constrain.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(f_type, &quot;%d&quot;, &amp;relation_total);
	
	for (INT i &#x3D; 0; i &lt; relation_total; i++) &#123;
		INT rel, tot;
		tmp &#x3D; fscanf(f_type, &quot;%d%d&quot;, &amp;rel, &amp;tot);
		head_left[rel] &#x3D; total_left;
		for (INT j &#x3D; 0; j &lt; tot; j++) &#123;
			tmp &#x3D; fscanf(f_type, &quot;%d&quot;, &amp;head_type[total_left]);
			total_left++;
		&#125;
		head_right[rel] &#x3D; total_left;
		std::sort(head_type + head_left[rel], head_type + head_right[rel]);

		tmp &#x3D; fscanf(f_type, &quot;%d%d&quot;, &amp;rel, &amp;tot);
		tail_left[rel] &#x3D; total_right;
		for (INT j &#x3D; 0; j &lt; tot; j++) &#123;
			tmp &#x3D; fscanf(f_type, &quot;%d&quot;, &amp;tail_type[total_right]);
			total_right++;
		&#125;
		tail_right[rel] &#x3D; total_right;
		std::sort(tail_type + tail_left[rel], tail_type + tail_right[rel]);
	&#125;
	fclose(f_type);
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 加载 Pretrained Embeddings
&#x2F;&#x2F; prerequisites: 
&#x2F;&#x2F;     entity2vec + note + .bin
&#x2F;&#x2F;     relation2vec + note + .bin
&#x2F;&#x2F;     
&#x2F;&#x2F;     or
&#x2F;&#x2F;
&#x2F;&#x2F;     entity2vec + note + .vec
&#x2F;&#x2F;     relation2vec + note + .vec
&#x2F;&#x2F; ##################################################

void load_binary() &#123;

	&#x2F;&#x2F; 以二进制形式加载预训练实体嵌入
	struct stat statbuf1;
	if (stat((load_path + &quot;entity2vec&quot; + note + &quot;.bin&quot;).c_str(),
			&amp;statbuf1) !&#x3D; -1) &#123;
		INT fd &#x3D; open((load_path + &quot;entity2vec&quot; + note + &quot;.bin&quot;).c_str(),
			O_RDONLY);
		REAL* entity_vec_tmp &#x3D; (REAL*)mmap(NULL, statbuf1.st_size,
			PROT_READ, MAP_PRIVATE, fd, 0);
		memcpy(entity_vec, entity_vec_tmp, statbuf1.st_size);
		munmap(entity_vec_tmp, statbuf1.st_size);
		close(fd);
		printf(&quot;%s&quot;, (&quot;以二进制形式加载预训练实体嵌入 (&quot; + load_path + &quot;entity2vec&quot; + note + &quot;.bin&quot; + &quot;) 成功.\n&quot;).c_str());
	&#125;

	&#x2F;&#x2F; 以二进制形式加载预训练关系嵌入
	struct stat statbuf2;
	if (stat((load_path + &quot;relation2vec&quot; + note + &quot;.bin&quot;).c_str(),
			&amp;statbuf2) !&#x3D; -1) &#123;
		INT fd &#x3D; open((load_path + &quot;relation2vec&quot; + note + &quot;.bin&quot;).c_str(),
			O_RDONLY);
		REAL* relation_vec_tmp &#x3D; (REAL*)mmap(NULL, statbuf2.st_size,
			PROT_READ, MAP_PRIVATE, fd, 0);
		memcpy(relation_vec, relation_vec_tmp, statbuf2.st_size);
		munmap(relation_vec_tmp, statbuf2.st_size);
		close(fd);
		printf(&quot;%s&quot;, (&quot;以二进制形式加载预训练关系嵌入 (&quot; + load_path + &quot;relation2vec&quot; + note + &quot;.bin&quot; + &quot;) 成功.\n\n&quot;).c_str());
	&#125;
&#125;

void load() &#123;

	if (load_binary_flag) &#123;
		load_binary();
		return;
	&#125;

	FILE *fin;
	INT tmp;

	&#x2F;&#x2F; 加载预训练实体嵌入
	fin &#x3D; fopen((load_path + &quot;entity2vec&quot; + note + &quot;.vec&quot;).c_str(), &quot;r&quot;);
	for (INT i &#x3D; 0; i &lt; entity_total; i++) &#123;
		INT last &#x3D; i * dimension;
		for (INT j &#x3D; 0; j &lt; dimension; j++)
			tmp &#x3D; fscanf(fin, &quot;%f&quot;, &amp;entity_vec[last + j]);
	&#125;
	fclose(fin);
	printf(&quot;%s&quot;, (&quot;加载预训练实体嵌入 (&quot; + load_path + &quot;entity2vec&quot; + note + &quot;.vec&quot; + &quot;) 成功.\n&quot;).c_str());

	&#x2F;&#x2F; 加载预训练关系嵌入
	fin &#x3D; fopen((load_path + &quot;relation2vec&quot; + note + &quot;.vec&quot;).c_str(), &quot;r&quot;);
	for (INT i &#x3D; 0; i &lt; relation_total; i++) &#123;
		INT last &#x3D; i * dimension;
		for (INT j &#x3D; 0; j &lt; dimension; j++)
			tmp &#x3D; fscanf(fin, &quot;%f&quot;, &amp;relation_vec[last + j]);
	&#125;
	fclose(fin);
	printf(&quot;%s&quot;, (&quot;加载预训练关系嵌入 (&quot; + load_path + &quot;relation2vec&quot; + note + &quot;.vec&quot; + &quot;) 成功.\n\n&quot;).c_str());
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 多个线程测试
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; 使用 L1 范数计算能量 d(h + l, t)
REAL calc_sum(INT e1, INT e2, INT rel) &#123;
	REAL sum &#x3D; 0;
	INT last1 &#x3D; e1 * dimension;
	INT last2 &#x3D; e2 * dimension;
	INT lastr &#x3D; rel * dimension;
	for (INT i &#x3D; 0; i &lt; dimension; i++)
		sum +&#x3D; fabs(entity_vec[last2 + i] -
			entity_vec[last1 + i] - relation_vec[lastr + i]);
	return sum;
&#125;

&#x2F;&#x2F; 检查数据集中是否存在 (h, t, r)
bool find(INT h, INT t, INT r) &#123;
	INT lef &#x3D; 0;
	INT rig &#x3D; triple_total - 1;
	INT mid;
	while (lef + 1 &lt; rig) &#123;
		INT mid &#x3D; (lef + rig) &gt;&gt; 1;
		if ((triple_list[mid].h &lt; h) 
			|| (triple_list[mid].h &#x3D;&#x3D; h &amp;&amp; triple_list[mid].r &lt; r) 
			|| (triple_list[mid].h &#x3D;&#x3D; h &amp;&amp; triple_list[mid].r &#x3D;&#x3D; r 
					&amp;&amp; triple_list[mid].t &lt; t)) 
				lef &#x3D; mid; else rig &#x3D; mid;
	&#125;
	if (triple_list[lef].h &#x3D;&#x3D; h &amp;&amp; triple_list[lef].r &#x3D;&#x3D; r 
		&amp;&amp; triple_list[lef].t &#x3D;&#x3D; t) return true;
	if (triple_list[rig].h &#x3D;&#x3D; h &amp;&amp; triple_list[rig].r &#x3D;&#x3D; r 
		&amp;&amp; triple_list[rig].t &#x3D;&#x3D; t) return true;
	return false;
&#125;

&#x2F;&#x2F; l_raw_tot, l_filter_tot, r_raw_tot, r_filter_tot 的形状为 [6][threads]
&#x2F;&#x2F; l_raw_rank, l_filter_rank, r_raw_rank, r_filter_rank 的形状为 [6][threads]
&#x2F;&#x2F; 第一维度:
&#x2F;&#x2F; 0: 代表全部测试集的结果
&#x2F;&#x2F; 1: 代表关系为 1-1 的测试三元组的结果
&#x2F;&#x2F; 2: 代表关系为 1-n 的测试三元组的结果
&#x2F;&#x2F; 3: 代表关系为 n-1 的测试三元组的结果
&#x2F;&#x2F; 4: 代表关系为 n-n 的测试三元组的结果
&#x2F;&#x2F; 5: 代表全部测试集的结果, 通过 type_constrain.txt 来构造负三元组
&#x2F;&#x2F; 第二维度:
&#x2F;&#x2F; 0 ~ (threads - 1): 线程 ID
&#x2F;&#x2F; l_raw_tot: 记录排名前 10 的 (替换 head 生成负三元组) 测试三元组个数
&#x2F;&#x2F; l_filter_tot: 记录排名前 10 的 (替换 head 生成负三元组) 测试三元组个数, 且负三元组不在数据集中
&#x2F;&#x2F; r_raw_tot: 记录排名前 10 的 (替换 tail 生成负三元组) 测试三元组个数
&#x2F;&#x2F; r_filter_tot: 记录排名前 10 的 (替换 tail 生成负三元组) 测试三元组个数, 且负三元组不在数据集中
&#x2F;&#x2F; l_raw_rank: 记录 (替换 head 生成负三元组) 测试三元组的排名总和 (排名从 0 开始)
&#x2F;&#x2F; l_filter_rank: 记录 (替换 head 生成负三元组) 测试三元组的排名总和 (排名从 0 开始), 且负三元组不在数据集中
&#x2F;&#x2F; r_raw_rank: 记录 (替换 tail 生成负三元组) 测试三元组的排名总和 (排名从 0 开始)
&#x2F;&#x2F; r_filter_rank: 记录 (替换 tail 生成负三元组) 测试三元组的排名总和 (排名从 0 开始), 且负三元组不在数据集中
REAL *l_raw_tot[6], *l_filter_tot[6], *r_raw_tot[6], *r_filter_tot[6];
REAL *l_raw_rank[6], *l_filter_rank[6], *r_raw_rank[6], *r_filter_rank[6];

&#x2F;&#x2F; 单个线程内运行的任务
void* test_mode(void *thread_id) &#123;
	INT id;

	&#x2F;&#x2F; id: 线程 ID
	id &#x3D; (unsigned long long)(thread_id);
	INT lef &#x3D; test_total &#x2F; (threads) * id;
	INT rig &#x3D; test_total &#x2F; (threads) * (id + 1) - 1;
	if (id &#x3D;&#x3D; threads - 1) rig &#x3D; test_total - 1;

	for (INT i &#x3D; lef; i &lt;&#x3D; rig; i++) &#123;

		INT h &#x3D; test_list[i].h;
		INT t &#x3D; test_list[i].t;
		INT r &#x3D; test_list[i].r;
		INT label &#x3D; test_list[i].label;

		REAL minimal &#x3D; calc_sum(h, t, r);

		&#x2F;&#x2F; l_raw: 记录能量 (d(h + l, t)) 小于测试三元组的 (替换 head) 负三元组个数
		&#x2F;&#x2F; l_filter: 记录能量 (d(h + l, t)) 小于测试三元组的 (替换 head) 负三元组个数, 且负三元组不在数据集中
		&#x2F;&#x2F; r_raw: 记录能量 (d(h + l, t)) 小于测试三元组的 (替换 tail) 负三元组个数
		&#x2F;&#x2F; r_filter: 记录能量 (d(h + l, t)) 小于测试三元组的 (替换 tail) 负三元组个数, 且负三元组不在数据集中
		INT l_raw &#x3D; 0;
		INT l_filter &#x3D; 0;
		INT r_raw &#x3D; 0;
		INT r_filter &#x3D; 0;

		&#x2F;&#x2F; l_raw_constrain: 记录能量 (d(h + l, t)) 小于测试三元组的 (通过 type_constrain.txt 替换 head 构造负三元组) 负三元组个数
		&#x2F;&#x2F; l_filter_constrain: 记录能量 (d(h + l, t)) 小于测试三元组的 (通过 type_constrain.txt 替换 head 构造负三元组) 负三元组个数, 且负三元组不在数据集中
		&#x2F;&#x2F; r_raw_constrain: 记录能量 (d(h + l, t)) 小于测试三元组的 (通过 type_constrain.txt 替换 tail 构造负三元组) 负三元组个数
		&#x2F;&#x2F; r_filter_constrain: 记录能量 (d(h + l, t)) 小于测试三元组的 (通过 type_constrain.txt 替换 tail 构造负三元组) 负三元组个数, 且负三元组不在数据集中
		INT l_raw_constrain &#x3D; 0;
		INT l_filter_constrain &#x3D; 0;
		INT r_raw_constrain &#x3D; 0;
		INT r_filter_constrain &#x3D; 0;

		&#x2F;&#x2F; left_head_type: 记录关系 r 的 head 类型在 head_type 中第一次出现的位置
		&#x2F;&#x2F; left_tail_type: 记录关系 r 的 tail 类型在 tail_type 中第一次出现的位置
		INT left_head_type &#x3D; head_left[r], left_tail_type &#x3D; tail_left[r];
		for (INT j &#x3D; 0; j &lt; entity_total; j++) &#123;

			&#x2F;&#x2F; 替换 head
			if (j !&#x3D; h) &#123;
				REAL value &#x3D; calc_sum(j, t, r);
				if (value &lt; minimal) &#123;
					l_raw +&#x3D; 1;
					if (not find(j, t, r))
						l_filter +&#x3D; 1;
				&#125;
				while (left_head_type &lt; head_right[r] &amp;&amp; head_type[left_head_type] &lt; j) left_head_type++;
				if (left_head_type &lt; head_right[r] &amp;&amp; head_type[left_head_type] &#x3D;&#x3D; j) &#123;
					if (value &lt; minimal) &#123;
						l_raw_constrain +&#x3D; 1;
						if (not find(j, t, r))
							l_filter_constrain +&#x3D; 1;
					&#125;
				&#125;
			&#125;

			&#x2F;&#x2F; 替换 tail
			if (j !&#x3D; t) &#123;
				REAL value &#x3D; calc_sum(h, j, r);
				if (value &lt; minimal) &#123;
					r_raw +&#x3D; 1;
					if (not find(h, j, r))
						r_filter +&#x3D; 1;
				&#125;
				while (left_tail_type &lt; tail_right[r] &amp;&amp; tail_type[left_tail_type] &lt; j) left_tail_type++;
				if (left_tail_type &lt; tail_right[r] &amp;&amp; tail_type[left_tail_type] &#x3D;&#x3D; j) &#123;
					if (value &lt; minimal) &#123;
						r_raw_constrain +&#x3D; 1;
						if (not find(h, j, r))
							r_filter_constrain +&#x3D; 1;
					&#125;
				&#125;
			&#125;
		&#125;
		
		&#x2F;&#x2F; 全部测试集
		if (l_raw &lt; 10) l_raw_tot[0][id] +&#x3D; 1;
		if (l_filter &lt; 10) l_filter_tot[0][id] +&#x3D; 1;
		if (r_raw &lt; 10) r_raw_tot[0][id] +&#x3D; 1;
		if (r_filter &lt; 10) r_filter_tot[0][id] +&#x3D; 1;

		l_raw_rank[0][id] +&#x3D; l_raw;
		l_filter_rank[0][id] +&#x3D; l_filter;
		r_raw_rank[0][id] +&#x3D; r_raw;
		r_filter_rank[0][id] +&#x3D; r_filter;

		&#x2F;&#x2F; 1-1, 1-n, n-1, n-n
		if (l_raw &lt; 10) l_raw_tot[label][id] +&#x3D; 1;
		if (l_filter &lt; 10) l_filter_tot[label][id] +&#x3D; 1;
		if (r_raw &lt; 10) r_raw_tot[label][id] +&#x3D; 1;
		if (r_filter &lt; 10) r_filter_tot[label][id] +&#x3D; 1;

		l_raw_rank[label][id] +&#x3D; l_raw;
		l_filter_rank[label][id] +&#x3D; l_filter;
		r_raw_rank[label][id] +&#x3D; r_raw;
		r_filter_rank[label][id] +&#x3D; r_filter;

		&#x2F;&#x2F; 全部测试集的结果, 通过 type_constrain.txt 来构造负三元组
		if (l_raw_constrain &lt; 10) l_raw_tot[5][id] +&#x3D; 1;
		if (l_filter_constrain &lt; 10) l_filter_tot[5][id] +&#x3D; 1;
		if (r_raw_constrain &lt; 10) r_raw_tot[5][id] +&#x3D; 1;
		if (r_filter_constrain &lt; 10) r_filter_tot[5][id] +&#x3D; 1;

		l_raw_rank[5][id] +&#x3D; l_raw_constrain;
		l_filter_rank[5][id] +&#x3D; l_filter_constrain;
		r_raw_rank[5][id] +&#x3D; r_raw_constrain;
		r_filter_rank[5][id] +&#x3D; r_filter_constrain;
	&#125;

	pthread_exit(NULL);
&#125;

&#x2F;&#x2F; 测试函数
void* test() &#123;

	for (INT i &#x3D; 0; i &lt;&#x3D; 5; i++) &#123;

		l_raw_tot[i] &#x3D; (REAL *)calloc(threads, sizeof(REAL));
		l_filter_tot[i] &#x3D; (REAL *)calloc(threads, sizeof(REAL));
		r_raw_tot[i] &#x3D; (REAL *)calloc(threads, sizeof(REAL));
		r_filter_tot[i] &#x3D; (REAL *)calloc(threads, sizeof(REAL));

		l_raw_rank[i] &#x3D; (REAL *)calloc(threads, sizeof(REAL));
		l_filter_rank[i] &#x3D; (REAL *)calloc(threads, sizeof(REAL));
		r_raw_rank[i] &#x3D; (REAL *)calloc(threads, sizeof(REAL));
		r_filter_rank[i] &#x3D; (REAL *)calloc(threads, sizeof(REAL));
		
	&#125;

	&#x2F;&#x2F; 开启多线程测试
	pthread_t *pt &#x3D; (pthread_t *)malloc(threads * sizeof(pthread_t));
	for (long a &#x3D; 0; a &lt; threads; a++)
		pthread_create(&amp;pt[a], NULL, test_mode, (void*)a);
	for (long a &#x3D; 0; a &lt; threads; a++)
		pthread_join(pt[a], NULL);
	free(pt);

	&#x2F;&#x2F; 将各个线程的结果累加
	for (INT i &#x3D; 0; i &lt;&#x3D; 5; i++)
		for (INT a &#x3D; 1; a &lt; threads; a++) &#123;

			l_raw_tot[i][a] +&#x3D; l_raw_tot[i][a - 1];
			l_filter_tot[i][a] +&#x3D; l_filter_tot[i][a - 1];
			r_raw_tot[i][a] +&#x3D; r_raw_tot[i][a - 1];
			r_filter_tot[i][a] +&#x3D; r_filter_tot[i][a - 1];

			l_raw_rank[i][a] +&#x3D; l_raw_rank[i][a - 1];
			l_filter_rank[i][a] +&#x3D; l_filter_rank[i][a - 1];
			r_raw_rank[i][a] +&#x3D; r_raw_rank[i][a - 1];
			r_filter_rank[i][a] +&#x3D; r_filter_rank[i][a - 1];
			
		&#125;
	
	&#x2F;&#x2F; 总体结果
	printf(&quot;总体结果：\n\n&quot;);
	for (INT i &#x3D; 0; i &lt;&#x3D; 0; i++) &#123;
		printf(&quot;heads(raw) \t\t平均排名: %f, \tHits@10: %f\n&quot;, l_raw_rank[i][threads - 1] &#x2F; test_total,
			l_raw_tot[i][threads - 1] &#x2F; test_total);
		printf(&quot;heads(filter) \t\t平均排名: %f, \tHits@10: %f\n&quot;, l_filter_rank[i][threads - 1] &#x2F; test_total,
			l_filter_tot[i][threads - 1] &#x2F; test_total);
		printf(&quot;tails(raw) \t\t平均排名: %f, \tHits@10: %f\n&quot;, r_raw_rank[i][threads - 1] &#x2F; test_total,
			r_raw_tot[i][threads - 1] &#x2F; test_total);
		printf(&quot;tails(filter) \t\t平均排名: %f, \tHits@10: %f\n&quot;, r_filter_rank[i][threads - 1] &#x2F; test_total,
			r_filter_tot[i][threads - 1] &#x2F; test_total);
	&#125;

	&#x2F;&#x2F; 通过 type_constrain.txt 限制的总体结果
	printf(&quot;\n通过 type_constrain.txt 限制的总体结果：\n\n&quot;);
	for (INT i &#x3D; 5; i &lt;&#x3D; 5; i++) &#123;
		printf(&quot;heads(raw) \t\t平均排名: %f, \tHits@10: %f\n&quot;, l_raw_rank[i][threads - 1] &#x2F; test_total,
			l_raw_tot[i][threads - 1] &#x2F; test_total);
		printf(&quot;heads(filter) \t\t平均排名: %f, \tHits@10: %f\n&quot;, l_filter_rank[i][threads - 1] &#x2F; test_total,
			l_filter_tot[i][threads - 1] &#x2F; test_total);
		printf(&quot;tails(raw) \t\t平均排名: %f, \tHits@10: %f\n&quot;, r_raw_rank[i][threads - 1] &#x2F; test_total,
			r_raw_tot[i][threads - 1] &#x2F; test_total);
		printf(&quot;tails(filter) \t\t平均排名: %f, \tHits@10: %f\n&quot;, r_filter_rank[i][threads - 1] &#x2F; test_total,
			r_filter_tot[i][threads - 1] &#x2F; test_total);
	&#125;

	&#x2F;&#x2F; (关系: 1-1, 1-n, n-1, n-n) 测试三元组的结果
	printf(&quot;\n(关系: 1-1, 1-n, n-1, n-n) 测试三元组的结果：\n&quot;);

	std::string relation[] &#x3D; &#123;
		&quot;关系: 1-1&quot;,
		&quot;关系: 1-n&quot;,
		&quot;关系: n-1&quot;,
		&quot;关系: n-n&quot;
	&#125;;

	for (INT i &#x3D; 1; i &lt;&#x3D; 4; i++) &#123;

		printf(&quot;\n%s:\n\n&quot;, relation[i - 1].c_str());

		printf(&quot;heads(raw) \t\t平均排名: %f, \tHits@10: %f\n&quot;, l_raw_rank[i][threads - 1] &#x2F; nntotal[i],
			l_raw_tot[i][threads - 1] &#x2F; nntotal[i]);
		printf(&quot;heads(filter) \t\t平均排名: %f, \tHits@10: %f\n&quot;, l_filter_rank[i][threads - 1] &#x2F; nntotal[i],
			l_filter_tot[i][threads - 1] &#x2F; nntotal[i]);
		printf(&quot;tails(raw) \t\t平均排名: %f, \tHits@10: %f\n&quot;, r_raw_rank[i][threads - 1] &#x2F; nntotal[i],
			r_raw_tot[i][threads - 1] &#x2F; nntotal[i]);
		printf(&quot;tails(filter) \t\t平均排名: %f, \tHits@10: %f\n&quot;, r_filter_rank[i][threads - 1] &#x2F; nntotal[i],
			r_filter_tot[i][threads - 1] &#x2F; nntotal[i]);
		
	&#125;
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; Main function
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; 寻找特定参数的位置
INT arg_pos(char *str, INT argc, char **argv) &#123;
	
	INT a;
	for (a &#x3D; 1; a &lt; argc; a++) if (!strcmp(str, argv[a])) &#123;
		if (a &#x3D;&#x3D; argc - 1) &#123;
			printf(&quot;Argument missing for %s\n&quot;, str);
			exit(1);
		&#125;
		return a;
	&#125;
	return -1;
&#125;

void setparameters(INT argc, char **argv) &#123;
	INT i;
	if ((i &#x3D; arg_pos((char *)&quot;-load-binary&quot;, argc, argv)) &gt; 0) load_binary_flag &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-size&quot;, argc, argv)) &gt; 0) dimension &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-threads&quot;, argc, argv)) &gt; 0) threads &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-input&quot;, argc, argv)) &gt; 0) in_path &#x3D; argv[i + 1];
	if ((i &#x3D; arg_pos((char *)&quot;-load&quot;, argc, argv)) &gt; 0) load_path &#x3D; argv[i + 1];
	if ((i &#x3D; arg_pos((char *)&quot;-note&quot;, argc, argv)) &gt; 0) note &#x3D; argv[i + 1];
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; .&#x2F;test_transE [-load-binary 0&#x2F;1] [-size SIZE]
&#x2F;&#x2F;          [-threads THREAD] [-input INPUT]
&#x2F;&#x2F;          [-load LOAD] [-note NOTE]

&#x2F;&#x2F; optional arguments:
&#x2F;&#x2F; -load-binary [0&#x2F;1]   [1] 以二进制形式加载预训练嵌入，默认值为 [0]
&#x2F;&#x2F; -size SIZE           实体和关系嵌入维度，默认值为 [50]
&#x2F;&#x2F; -threads THREAD      number of worker threads. if unspecified, threads will default to 32
&#x2F;&#x2F; -input INPUT         folder of training data. if unspecified, in_path will default to &quot;..&#x2F;data&#x2F;FB15K&#x2F;&quot;
&#x2F;&#x2F; -load LOAD           folder of pretrained data. if unspecified, load_path will default to &quot;.&#x2F;build&#x2F;&quot;
&#x2F;&#x2F; -note NOTE           information you want to add to the filename. if unspecified, note will default to &quot;&quot;
&#x2F;&#x2F; ##################################################

INT main(INT argc, char **argv) &#123;

	printf(&quot;测试开始:\n\n&quot;);

	struct timeval start, end;
	gettimeofday(&amp;start, NULL);

	setparameters(argc, argv);
	init();
	load();
	test();

	gettimeofday(&amp;end, NULL);
	long double time_use &#x3D; 1000000 * (end.tv_sec - start.tv_sec) + end.tv_usec - start.tv_usec;

	printf(&quot;\n测试结束, 用时 %.6Lf 秒.\n\n&quot;, time_use&#x2F;1000000.0);
	printf(&quot;##################################################\n\n&quot;);

	return 0;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="run-sh"><a href="#run-sh" class="headerlink" title="run.sh"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/knowledge-representation-learning/C%2B%2B/TransE/run.sh">run.sh</a></h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>

<span class="token comment">##################################################</span>
<span class="token comment"># run.sh</span>
<span class="token comment"># 使用方法：$ bash run.sh</span>
<span class="token comment"># created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com></span>
<span class="token comment">#</span>
<span class="token comment"># 该 Shell 脚本用于模型训练和模型测试</span>
<span class="token comment">##################################################</span>

<span class="token comment"># 生成临时数据文件</span>
python3 data_preprocessing.py

<span class="token comment"># 创建 build 目录</span>
<span class="token builtin class-name">echo</span> <span class="token string">"##################################################"</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token function">mkdir</span> build
<span class="token builtin class-name">echo</span> <span class="token string">"./build 目录创建成功."</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>

<span class="token comment"># train</span>
g++ transE.cpp <span class="token parameter variable">-o</span> ./build/transE <span class="token parameter variable">-pthread</span> <span class="token parameter variable">-O3</span> <span class="token parameter variable">-march</span><span class="token operator">=</span>native
./build/transE
 
<span class="token comment"># test</span>
g++ test_transE.cpp <span class="token parameter variable">-o</span> ./build/test_transE <span class="token parameter variable">-pthread</span> <span class="token parameter variable">-O3</span> <span class="token parameter variable">-march</span><span class="token operator">=</span>native
./build/test_transE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="clean-sh"><a href="#clean-sh" class="headerlink" title="clean.sh"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/knowledge-representation-learning/C%2B%2B/TransE/clean.sh">clean.sh</a></h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>

<span class="token comment">##################################################</span>
<span class="token comment"># clean.sh</span>
<span class="token comment"># 使用方法：$ bash clean.sh</span>
<span class="token comment"># created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com></span>
<span class="token comment">#</span>
<span class="token comment"># 该 Shell 脚本用于清理临时文件</span>
<span class="token comment">##################################################</span>

<span class="token comment"># 删除目标文件和嵌入文件</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token builtin class-name">echo</span> <span class="token string">"##################################################"</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token function">rm</span> <span class="token parameter variable">-rf</span> ./build
<span class="token builtin class-name">echo</span> <span class="token string">"./build 目录递归删除成功."</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>

<span class="token comment"># 删除临时的数据文件</span>
<span class="token function">rm</span> <span class="token parameter variable">-f</span> <span class="token punctuation">..</span>/data/FB15K/1-1.txt <span class="token punctuation">..</span>/data/FB15K/1-n.txt <span class="token punctuation">..</span>/data/FB15K/n-1.txt <span class="token punctuation">..</span>/data/FB15K/n-n.txt <span class="token punctuation">..</span>/data/FB15K/test2id_all.txt <span class="token punctuation">..</span>/data/FB15K/type_constrain.txt
<span class="token builtin class-name">echo</span> <span class="token string">"已删除 ../data/FB15K/1-1.txt ../data/FB15K/1-n.txt ../data/FB15K/n-1.txt ../data/FB15K/n-n.txt ../data/FB15K/test2id_all.txt ../data/FB15K/type_constrain.txt."</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token builtin class-name">echo</span> <span class="token string">"##################################################"</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ls</span>
data  papers  README.md  TransE
$ <span class="token builtin class-name">cd</span> TransE/
$ <span class="token function">ls</span>
clean.sh  data_preprocessing.py  run.sh  test_transE.cpp  transE.cpp
$ <span class="token function">bash</span> run.sh 

<span class="token comment">##################################################</span>

数据预处理开始<span class="token punctuation">..</span>.

<span class="token punctuation">..</span>/data/FB15K/type_constrain.txt 创建成功.

<span class="token punctuation">..</span>/data/FB15K/1-1.txt <span class="token punctuation">..</span>/data/FB15K/1-n.txt <span class="token punctuation">..</span>/data/FB15K/n-1.txt <span class="token punctuation">..</span>/data/FB15K/n-n.txt <span class="token punctuation">..</span>/data/FB15K/test2id_all.txt 创建成功.

数据预处理结束.

<span class="token comment">##################################################</span>

./build 目录创建成功.

<span class="token comment">##################################################</span>

训练开始:

relation_total: <span class="token number">1345</span>
entity_total: <span class="token number">14951</span>
train_triple_total: <span class="token number">483142</span>

Epoch <span class="token number">50</span>/1000 - loss: <span class="token number">4220.165039</span>
Epoch <span class="token number">100</span>/1000 - loss: <span class="token number">3433.874268</span>
Epoch <span class="token number">150</span>/1000 - loss: <span class="token number">3082.582031</span>
Epoch <span class="token number">200</span>/1000 - loss: <span class="token number">2955.229492</span>
Epoch <span class="token number">250</span>/1000 - loss: <span class="token number">2860.262695</span>
Epoch <span class="token number">300</span>/1000 - loss: <span class="token number">2755.290527</span>
Epoch <span class="token number">350</span>/1000 - loss: <span class="token number">2776.718506</span>
Epoch <span class="token number">400</span>/1000 - loss: <span class="token number">2601.110596</span>
Epoch <span class="token number">450</span>/1000 - loss: <span class="token number">2654.754883</span>
Epoch <span class="token number">500</span>/1000 - loss: <span class="token number">2641.694824</span>
Epoch <span class="token number">550</span>/1000 - loss: <span class="token number">2517.212891</span>
Epoch <span class="token number">600</span>/1000 - loss: <span class="token number">2625.712402</span>
Epoch <span class="token number">650</span>/1000 - loss: <span class="token number">2474.082764</span>
Epoch <span class="token number">700</span>/1000 - loss: <span class="token number">2581.359863</span>
Epoch <span class="token number">750</span>/1000 - loss: <span class="token number">2460.039062</span>
Epoch <span class="token number">800</span>/1000 - loss: <span class="token number">2542.918213</span>
Epoch <span class="token number">850</span>/1000 - loss: <span class="token number">2456.383057</span>
Epoch <span class="token number">900</span>/1000 - loss: <span class="token number">2467.666748</span>
Epoch <span class="token number">950</span>/1000 - loss: <span class="token number">2437.669434</span>
Epoch <span class="token number">1000</span>/1000 - loss: <span class="token number">2396.724121</span>

输出预训练实体嵌入 <span class="token punctuation">(</span>./build/entity2vec.vec<span class="token punctuation">)</span> 成功.
输出预训练关系嵌入 <span class="token punctuation">(</span>./build/relation2vec.vec<span class="token punctuation">)</span> 成功.

训练结束, 用时 <span class="token number">49.974742</span> 秒.

<span class="token comment">##################################################</span>

测试开始:

加载预训练实体嵌入 <span class="token punctuation">(</span>./build/entity2vec.vec<span class="token punctuation">)</span> 成功.
加载预训练关系嵌入 <span class="token punctuation">(</span>./build/relation2vec.vec<span class="token punctuation">)</span> 成功.

总体结果：

heads<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">307.290955</span>, 	Hits@10: <span class="token number">0.376293</span>
heads<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">193.796234</span>, 	Hits@10: <span class="token number">0.499619</span>
tails<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">226.710876</span>, 	Hits@10: <span class="token number">0.452726</span>
tails<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">155.753433</span>, 	Hits@10: <span class="token number">0.567791</span>

通过 type_constrain.txt 限制的总体结果：

heads<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">201.278839</span>, 	Hits@10: <span class="token number">0.403362</span>
heads<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">87.784126</span>, 	Hits@10: <span class="token number">0.563898</span>
tails<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">138.802917</span>, 	Hits@10: <span class="token number">0.480710</span>
tails<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">67.845474</span>, 	Hits@10: <span class="token number">0.611315</span>

<span class="token punctuation">(</span>关系: <span class="token number">1</span>-1, <span class="token number">1</span>-n, n-1, n-n<span class="token punctuation">)</span> 测试三元组的结果：

关系: <span class="token number">1</span>-1:

heads<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">122.549644</span>, 	Hits@10: <span class="token number">0.698582</span>
heads<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">122.320328</span>, 	Hits@10: <span class="token number">0.702128</span>
tails<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">143.882980</span>, 	Hits@10: <span class="token number">0.692671</span>
tails<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">143.633575</span>, 	Hits@10: <span class="token number">0.699764</span>

关系: <span class="token number">1</span>-n:

heads<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">30.182560</span>, 	Hits@10: <span class="token number">0.833934</span>
heads<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">29.975924</span>, 	Hits@10: <span class="token number">0.838294</span>
tails<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">1288.020142</span>, 	Hits@10: <span class="token number">0.184645</span>
tails<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">895.189941</span>, 	Hits@10: <span class="token number">0.239621</span>

关系: n-1:

heads<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">1173.232788</span>, 	Hits@10: <span class="token number">0.132855</span>
heads<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">732.672363</span>, 	Hits@10: <span class="token number">0.200555</span>
tails<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">33.063072</span>, 	Hits@10: <span class="token number">0.844115</span>
tails<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">32.890060</span>, 	Hits@10: <span class="token number">0.846893</span>

关系: n-n:

heads<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">174.934845</span>, 	Hits@10: <span class="token number">0.363132</span>
heads<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">109.573875</span>, 	Hits@10: <span class="token number">0.513756</span>
tails<span class="token punctuation">(</span>raw<span class="token punctuation">)</span> 		平均排名: <span class="token number">139.707718</span>, 	Hits@10: <span class="token number">0.403733</span>
tails<span class="token punctuation">(</span>filter<span class="token punctuation">)</span> 		平均排名: <span class="token number">91.915115</span>, 	Hits@10: <span class="token number">0.549911</span>

测试结束, 用时 <span class="token number">12.542188</span> 秒.

<span class="token comment">##################################################</span>

$ tree
<span class="token builtin class-name">.</span>
├── build
│   ├── entity2vec.vec
│   ├── relation2vec.vec
│   ├── test_transE
│   └── transE
├── clean.sh
├── data_preprocessing.py
├── run.sh
├── test_transE.cpp
└── transE.cpp

<span class="token number">1</span> directory, <span class="token number">9</span> files
$ <span class="token function">bash</span> clean.sh 

<span class="token comment">##################################################</span>

./build 目录递归删除成功.

已删除 <span class="token punctuation">..</span>/data/FB15K/1-1.txt <span class="token punctuation">..</span>/data/FB15K/1-n.txt <span class="token punctuation">..</span>/data/FB15K/n-1.txt <span class="token punctuation">..</span>/data/FB15K/n-n.txt <span class="token punctuation">..</span>/data/FB15K/test2id_all.txt <span class="token punctuation">..</span>/data/FB15K/type_constrain.txt.

<span class="token comment">##################################################</span>

$ <span class="token function">ls</span>
clean.sh  data_preprocessing.py  run.sh  test_transE.cpp  transE.cpp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>运行结果显示: 训练集中的关系一共为 <em>1345</em> 个，实体一共为 <em>14951</em> 个，三元组一共 <em>483142</em> 个。训练一共用时 <strong>49.974742</strong> 秒。</p>
<p>可以发现类型为 <strong>1-TO-MANY</strong> 和 <strong>MANY-TO-1</strong> 的关系, 从 <strong>MANY</strong> 侧边预测 <strong>1</strong> 侧边具有很高的利用价值, 因为这种训练数据较多.</p>
<p>对于大型知识图谱, 用全部实体构建<code>负三元组</code>是极其耗时的, 因此用 <strong>type_constrain.txt</strong> 来构造负三元组. 该文件记录了<strong>数据集</strong> (训练集, 验证集, 测试集) 中各个关系 <strong>head</strong> 和 <strong>tail</strong> 出现过的种类.</p>
<h3 id="训练和测试的参数"><a href="#训练和测试的参数" class="headerlink" title="训练和测试的参数"></a>训练和测试的参数</h3><h4 id="transE-cpp-1"><a href="#transE-cpp-1" class="headerlink" title="transE.cpp"></a>transE.cpp</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">./transE <span class="token punctuation">[</span>-bern <span class="token number">0</span>/1<span class="token punctuation">]</span> <span class="token punctuation">[</span>-load-binary <span class="token number">0</span>/1<span class="token punctuation">]</span> <span class="token punctuation">[</span>-out-binary <span class="token number">0</span>/1<span class="token punctuation">]</span>
         <span class="token punctuation">[</span>-size SIZE<span class="token punctuation">]</span> <span class="token punctuation">[</span>-alpha ALPHA<span class="token punctuation">]</span> <span class="token punctuation">[</span>-margin MARGIN<span class="token punctuation">]</span>
         <span class="token punctuation">[</span>-nbatches NBATCHES<span class="token punctuation">]</span> <span class="token punctuation">[</span>-epochs EPOCHS<span class="token punctuation">]</span>
         <span class="token punctuation">[</span>-threads THREAD<span class="token punctuation">]</span> <span class="token punctuation">[</span>-input INPUT<span class="token punctuation">]</span> <span class="token punctuation">[</span>-output OUTPUT<span class="token punctuation">]</span>
         <span class="token punctuation">[</span>-load LOAD<span class="token punctuation">]</span> <span class="token punctuation">[</span>-note NOTE<span class="token punctuation">]</span>

optional arguments:
<span class="token parameter variable">-bern</span> <span class="token punctuation">[</span><span class="token number">0</span>/1<span class="token punctuation">]</span>          <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> 使用 bern 算法进行负采样，默认值为 <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
-load-binary <span class="token punctuation">[</span><span class="token number">0</span>/1<span class="token punctuation">]</span>   <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> 以二进制形式加载预训练嵌入，默认值为 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
-out-binary <span class="token punctuation">[</span><span class="token number">0</span>/1<span class="token punctuation">]</span>    <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> 以二进制形式输出嵌入，默认值为 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token parameter variable">-size</span> SIZE           实体和关系嵌入维度，默认值为 <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">]</span>
<span class="token parameter variable">-alpha</span> ALPHA         学习率，默认值为 <span class="token number">0.01</span>
<span class="token parameter variable">-margin</span> MARGIN       margin <span class="token keyword">in</span> max-margin loss <span class="token keyword">for</span> pairwise training，默认值为 <span class="token number">1.0</span>
<span class="token parameter variable">-nbatches</span> NBATCHES   number of batches <span class="token keyword">for</span> each epoch. <span class="token keyword">if</span> unspecified, nbatches will default to <span class="token number">1</span>
<span class="token parameter variable">-epochs</span> EPOCHS       number of epochs. <span class="token keyword">if</span> unspecified, epochs will default to <span class="token number">1000</span>
<span class="token parameter variable">-threads</span> THREAD      number of worker threads. <span class="token keyword">if</span> unspecified, threads will default to <span class="token number">32</span>
<span class="token parameter variable">-input</span> INPUT         folder of training data. <span class="token keyword">if</span> unspecified, in_path will default to <span class="token string">"../data/FB15K/"</span>
<span class="token parameter variable">-output</span> OUTPUT       folder of outputing results. <span class="token keyword">if</span> unspecified, out_path will default to <span class="token string">"./build/"</span>
<span class="token parameter variable">-load</span> LOAD           folder of pretrained data. <span class="token keyword">if</span> unspecified, load_path will default to <span class="token string">""</span>
<span class="token parameter variable">-note</span> NOTE           information you want to <span class="token function">add</span> to the filename. <span class="token keyword">if</span> unspecified, note will default to <span class="token string">""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="test-transE-cpp-1"><a href="#test-transE-cpp-1" class="headerlink" title="test_transE.cpp"></a>test_transE.cpp</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">./test_transE <span class="token punctuation">[</span>-load-binary <span class="token number">0</span>/1<span class="token punctuation">]</span> <span class="token punctuation">[</span>-size SIZE<span class="token punctuation">]</span>
         <span class="token punctuation">[</span>-threads THREAD<span class="token punctuation">]</span> <span class="token punctuation">[</span>-input INPUT<span class="token punctuation">]</span>
         <span class="token punctuation">[</span>-load LOAD<span class="token punctuation">]</span> <span class="token punctuation">[</span>-note NOTE<span class="token punctuation">]</span>

optional arguments:
-load-binary <span class="token punctuation">[</span><span class="token number">0</span>/1<span class="token punctuation">]</span>   <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> 以二进制形式加载预训练嵌入，默认值为 <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token parameter variable">-size</span> SIZE           实体和关系嵌入维度，默认值为 <span class="token punctuation">[</span><span class="token number">50</span><span class="token punctuation">]</span>
<span class="token parameter variable">-threads</span> THREAD      number of worker threads. <span class="token keyword">if</span> unspecified, threads will default to <span class="token number">32</span>
<span class="token parameter variable">-input</span> INPUT         folder of training data. <span class="token keyword">if</span> unspecified, in_path will default to <span class="token string">"../data/FB15K/"</span>
<span class="token parameter variable">-load</span> LOAD           folder of pretrained data. <span class="token keyword">if</span> unspecified, load_path will default to <span class="token string">"./build/"</span>
<span class="token parameter variable">-note</span> NOTE           information you want to <span class="token function">add</span> to the filename. <span class="token keyword">if</span> unspecified, note will default to <span class="token string">""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>第三十五篇博文写完，开心！！！！</p>
<p>今天，也是充满希望的一天。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">LuYF-Lemon-love</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://luyf-lemon-love.space/2022/10/10/00035-transe-yuan-lun-wen-xue-xi-bi-ji/">https://luyf-lemon-love.space/2022/10/10/00035-transe-yuan-lun-wen-xue-xi-bi-ji/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">LuYF-Lemon-love</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/C/">
                                    <span class="chip bg-color">C++</span>
                                </a>
                            
                                <a href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/">
                                    <span class="chip bg-color">多线程</span>
                                </a>
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                                    <span class="chip bg-color">知识图谱</span>
                                </a>
                            
                                <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/">
                                    <span class="chip bg-color">知识图谱补全</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">谢谢小主！</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162303.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162220.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2022/10/19/00036-ji-yu-yu-ju-ji-bie-xuan-ze-xing-zhu-yi-li-ji-zhi-de-guan-xi-chou-qu-mo-xing-yuan-lun-wen-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/20221019123505 (1).png" class="responsive-img" alt="00036-基于语句级别选择性注意力机制的关系抽取模型-原论文学习笔记">
                        
                        <span class="card-title">00036-基于语句级别选择性注意力机制的关系抽取模型-原论文学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-10-19
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Paper/" class="post-category">
                                    Paper
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/C/">
                        <span class="chip bg-color">C++</span>
                    </a>
                    
                    <a href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/">
                        <span class="chip bg-color">多线程</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                        <span class="chip bg-color">知识图谱</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/10/08/00034-pytorch-tutorials-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/20221008161018.png" class="responsive-img" alt="00034-PyTorch Tutorials 学习笔记">
                        
                        <span class="card-title">00034-PyTorch Tutorials 学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-10-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/PyTorch/" class="post-category">
                                    PyTorch
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/PyTorch/">
                        <span class="chip bg-color">PyTorch</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022-2025</span>
            
            <a href="/about" target="_blank">LuYF-Lemon-love</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "5";
                        var startDate = "7";
                        var startHour = "4";
                        var startMinute = "53";
                        var startSecond = "32";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
                <span id="icp"><img src="/medias/icp.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="https://beian.miit.gov.cn" target="_blank">冀ICP备2022012632号-1</a>
            </span>
            
            <br>
            
                <span id="gongan"><img src="https://cos.luyf-lemon-love.space/images/备案图标.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32011502011618" target="_blank">苏公网安备 32011502011618号</a>
            </span>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yanfeng98" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:luyanfeng_nlp@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
