<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="00036-基于语句级别选择性注意力机制的关系抽取模型-原论文学习笔记, NLP LLM DeepLearning LuYF-Lemon-love 自然语言处理 深度学习 大语言模型">
    <meta name="description" content="前言CNN+ATT 是一种基于语句级别选择性注意力机制的神经网络模型, 用于构建基于远程监督的关系抽取系统.它是一个著名的神经关系抽取 (Neural Relation Extraction, NRE) 模型。
本博文是 CNN+ATT 原">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>00036-基于语句级别选择性注意力机制的关系抽取模型-原论文学习笔记 | LuYF-Lemon-love の Blog</title>
    <link rel="icon" type="image/jpeg" href="https://cos.luyf-lemon-love.space/images/苏苏1.jpeg">
    
    <style>
        body{
            background-image: url(https://cdn.jsdelivr.net/gh/Tokisaki-Galaxy/res/site/medias/background.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <span class="logo-span">LuYF-Lemon-love の Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <div class="logo-name">LuYF-Lemon-love の Blog</div>
        <div class="logo-desc">
            
            天之道，损有余而补不足，人之道则不然，损不足以奉有余。
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/LuYF-Lemon-love/paper-is-all-you-need" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/LuYF-Lemon-love/paper-is-all-you-need" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cos.luyf-lemon-love.space/images/20221019123505 (1).png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">00036-基于语句级别选择性注意力机制的关系抽取模型-原论文学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/C/">
                                <span class="chip bg-color">C++</span>
                            </a>
                        
                            <a href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/">
                                <span class="chip bg-color">多线程</span>
                            </a>
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">深度学习</span>
                            </a>
                        
                            <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                                <span class="chip bg-color">知识图谱</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/Paper/" class="post-category">
                                Paper
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2022-10-19
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2024-12-28
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    31.3k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    171 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>CNN+ATT</strong> 是一种<strong>基于语句级别选择性注意力机制</strong>的<strong>神经网络模型</strong>, 用于构建基于<strong>远程监督</strong>的<strong>关系抽取</strong>系统.它是一个著名的<strong>神经关系抽取</strong> (Neural Relation Extraction, NRE) 模型。</p>
<p>本博文是 <strong>CNN+ATT</strong> 原论文学习笔记，包括代码实现。</p>
<p><strong>CNN+ATT</strong> 原论文链接：<a href="https://aclanthology.org/P16-1200v2.pdf">Neural Relation Extraction with Selective Attention over Instances</a>.</p>
<p><strong>代码仓库地址</strong>: <a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/neural-relation-extraction/C%2B%2B">https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/neural-relation-extraction/C%2B%2B</a> .</p>
<p>操作系统：Ubuntu 18.04.6 LTS</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><div id = "1"></div>

<ol>
<li><a href="https://aclanthology.org/P16-1200">Neural Relation Extraction with Selective Attention over Instances</a> (Lin et al., ACL 2016).</li>
</ol>
<div id = "2"></div>

<ol start="2">
<li><a href="https://github.com/thunlp/NRE">NRE</a>.</li>
</ol>
<div id = "3"></div>

<ol start="3">
<li>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of ACL-IJCNLP, pages 1003–1011.</li>
</ol>
<div id = "4"></div>

<ol start="4">
<li>Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao. 2015. Distant supervision for relation extraction via piecewise convolutional neural networks. In Proceedings of EMNLP.</li>
</ol>
<div id = "5"></div>

<ol start="5">
<li>知识图谱与深度学习, 作者 刘知远, 韩旭, 孙茂松, 由 清华大学出版社 出版, 书号 978-7-302-53852-3, 豆瓣链接: <a href="https://book.douban.com/subject/35093204/">https://book.douban.com/subject/35093204/</a> .</li>
</ol>
<div id = "6"></div>

<ol start="6">
<li>Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via convolutional deep neural network. In Proceedings of COLING, pages 2335–2344.</li>
</ol>
<div id = "7"></div>

<ol start="7">
<li>Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. JMLR, 15(1):1929–1958.</li>
</ol>
<div id = "8"></div>

<ol start="8">
<li>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Proceedings of ECML-PKDD, pages 148–163.</li>
</ol>
<div id = "9"></div>

<ol start="9">
<li><a href="https://code.google.com/p/word2vec/">https://code.google.com/p/word2vec/</a> .</li>
</ol>
<h2 id="CNN-ATT-原论文学习笔记"><a href="#CNN-ATT-原论文学习笔记" class="headerlink" title="CNN+ATT 原论文学习笔记"></a>CNN+ATT 原论文学习笔记</h2><p><strong>Neural Relation Extraction with Selective Attention over Instances</strong> (基于语句级别选择性注意力机制的神经网络模型) 提出于 <em>2016</em> 年, 发表于 <a href="https://aclanthology.org/volumes/P16-1/">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a>.</p>
<p><strong>远程监督关系抽取</strong>已经广泛地应用于从<strong>文本</strong>中发现<strong>新型的关系事实</strong>. 然而, 远程监督不可避免的伴随着<strong>错误标注</strong>的问题, 这些<strong>嘈杂的数据</strong>将大大损害关系抽取的性能.</p>
<p><strong>基于语句级别选择性注意力机制的关系出抽取神经网络模型</strong>能够缓解<strong>远程监督关系抽取</strong>的<strong>错误标签</strong>问题, 该模型使用<strong>卷机神经网络</strong>来<strong>嵌入句子的语义</strong>. 之后, 使用<strong>语句级别选择性注意力</strong>来<strong>动态地降低嘈杂实例 (句子) 的权重</strong>.</p>
<p>实验结果证明, 该模型可以充分利用每个句子的所有信息, 有效的减少了错误标记实例 (句子) 的影响.</p>
<h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><strong>介绍</strong></h3><p>最近几年, 各种大型知识库 (<strong>Freebase</strong>, <strong>DBpedia</strong>, <strong>YAGO</strong>) 已经被建立和广泛地应用于许多<strong>自然语言处理</strong> (natural language processing, NLP) 任务, 包括 <strong>web search</strong> 和 <strong>question answering</strong>. 这些知识库是由大量三元组 (格式为 (<em>Microsoft</em>, <em>founder</em>, <em>Bill Gates</em>)) 组成的.</p>
<p><strong>关系抽取</strong> (relation extraction, RE) —— 从纯文本生成关系数据的过程, 是一个自然语言处理的重要任务.</p>
<p>(Mintz et al., 2009)<a href="#3"><sup>3</sup></a> 提出<strong>远程监督</strong>, 通过<strong>对齐知识库和纯文本</strong>自动生成训练数据. 远程监督假设, <strong>如果两个实体在知识库中存在某种关系, 则包含这两个实体的所有句子都将表达这种关系</strong>. 例如, 三元组 (<em>Microsoft, founder, Bill Gates</em>) 是知识库中的关系事实, 远距离监督会把<strong>包含这两个实体的所有句子</strong>都视为关系 <em><strong>founder</strong></em> 的正例. 然而 <strong>“Bill Gates ’s turn to philanthropy was linked to the antitrust problems Microsoft had in the U.S. and the European union.”</strong> (比尔·盖茨转向慈善事业与微软在美国和欧盟的反垄断问题有关。) 这句话并没有表达关系 <em>founder</em>, 但仍然视为一个正例 (关系 <em>founder</em>).</p>
<p>因此有很多人 (2010 年, 2011 年, 2012 年) 采用<strong>多实例学习</strong> (<em>multi-instance learning</em>) 缓解远程监督错误标注的问题.  (Zeng et al., 2015)<a href="#4"><sup>4</sup></a>将<strong>多实例学习</strong>与<strong>神经网络模型</strong>相结合进一步缓解该问题. 该方法<strong>假设至少有一个提到这两个实体的句子</strong>将表达它们之间的<strong>关系</strong>, 并且<strong>只在训练和预测中为每个实体对选择最有可能的句子</strong>. 该方法<strong>将丢失大量包含在被忽视的句子中的丰富信息</strong>.</p>
<p>本论文提出了一种<strong>基于句子级注意力的卷积神经网络 (CNN)</strong> 用于<strong>远程监督关系提取</strong>. 该模型使用 CNN 来嵌入句子的语义, 如下图. 之后, 为了利用每个句子的所有信息, 将<strong>关系表示为句子嵌入的语义组合</strong>. 为了解决远程监督带来的错误标注问题, 该模型在这些实例的<strong>语义向量</strong>上构建<strong>语句级别的注意力机制</strong>, 从而动态地<strong>减少</strong>噪声实例所对应的权重, 同时<strong>提升</strong>有效实例所对应的权重. 最后, 将利用注意力机制计算的权重与对应实例向量的<strong>加权求和</strong>作为<strong>特征向量</strong>来进行关系抽取.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221019155759.png"></p>
<p>该论文的贡献总结如下:</p>
<ul>
<li><p>与现有的<strong>神经关系抽取模型</strong>相比, 该模型可以<strong>充分利用每个实体对的所有实例 (句子) 的信息</strong>.</p>
</li>
<li><p>为了解决远程监督的错误标注问题, <strong>该论文提出选择性注意力机制来忽视噪声数据</strong>.</p>
</li>
<li><p>实验表明, <strong>选择注意力机制</strong>对于两种 CNN 模型的<strong>关系抽取</strong>是有益的.</p>
</li>
</ul>
<h3 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h3><p><strong>关系抽取</strong>是一个重要的 <strong>NLP</strong> 任务, 很多人研究有监督的关系抽取. (Mintz et al., 2009)<a href="#3"><sup>3</sup></a> 提出<strong>远程监督</strong>, 通过<strong>对齐知识库和纯文本</strong>自动生成训练数据.</p>
<blockquote>
<ol>
<li><p>(Riedel et al., 2010) models distant supervision for relation extraction as a <strong>multi-instance single-label problem</strong>.</p>
</li>
<li><p>(Hoffmann et al., 2011; Surdeanu et al., 2012) adopt <strong>multi-instance multi-label learning in relation extraction</strong>.</p>
</li>
</ol>
</blockquote>
<hr>
<blockquote>
<p>Multi-instance learning was originally proposed to address the issue of <strong>ambiguously-labelled training data</strong> when predicting the activity of <strong>drugs</strong> (Dietterich et al., 1997)</p>
<p>(Bunescu and Mooney, 2007) connects weak supervision with multi-instance learning and extends it to relation extraction.</p>
</blockquote>
<p>所有<strong>基于特征的方法</strong>严重依赖 NLP 工具生成的<strong>特征的质量</strong>, 这将受到错误传播问题 (<strong>error propagation problem</strong>) 的困扰.</p>
<blockquote>
<p><strong>deep learning</strong> (Bengio, 2009) has been widely used for various areas, including <strong>computer vision</strong>, <strong>speech recognition</strong> and so on.</p>
<p>NLP tasks (successfully applied):</p>
<ol>
<li><p>part-of-speech tagging (Collobert et al., 2011)</p>
</li>
<li><p>sentiment analysis (dos Santos and Gatti, 2014)</p>
</li>
<li><p>parsing (Socher et al., 2013)</p>
</li>
<li><p>machine translation (Sutskever et al., 2014)</p>
</li>
</ol>
</blockquote>
<hr>
<blockquote>
<ol>
<li><p>(Socher et al., 2012) uses a <strong>recursive neural network</strong> in relation extraction.They parse the sentences first and then represent each node in the parsing tree as a vector.</p>
</li>
<li><p>(Zeng et al., 2014<a href="#6"><sup>6</sup></a>; dos Santos et al., 2015) adopt <strong>an end-to-end convolutional neural network for relation extraction</strong>.</p>
</li>
<li><p>(Xie et al., 2016) attempts to <strong>incorporate the text information of entities for relation extraction</strong>.</p>
</li>
</ol>
</blockquote>
<hr>
<p>虽然深度学习的方法取得了极大的成功, 这些模型仍然<strong>在句子级别上抽取关系</strong>, 并且<strong>缺乏足够的训练数据</strong>. 此外, <strong>传统方法的多实例学习策略不容易应用于神经网络模型</strong>.</p>
<blockquote>
<p>(Zeng et al., 2015)<a href="#4"><sup>4</sup></a> <strong>combines at-least-one multi-instance learning with neural network model</strong> to extract relations on distant supervision data. However, they <strong>assume that only one sentence is active for each entity pair</strong>. Hence, it will <strong>lose a large amount of rich information containing in those neglected sentences</strong>.</p>
</blockquote>
<p>因此, 本论文提出了<strong>对多个实例 (句子) 的语句级别选择性注意力机制</strong>, 它能<strong>充分利用每个实体对的所有实例 (句子) 的信息</strong>.</p>
<blockquote>
<ol>
<li><p>The attention-based models have attracted a lot of interests of researchers recently.</p>
</li>
<li><p><strong>The selectivity of attention-based models</strong> allows them to <strong>learn alignments between different modalities</strong>.</p>
</li>
</ol>
<p>It has been applied to various areas:</p>
<ol>
<li><p>image classification (Mnih et al., 2014)</p>
</li>
<li><p>speech recognition (Chorowski et al., 2014)</p>
</li>
<li><p>image caption generation (Xu et al., 2015)</p>
</li>
<li><p>machine translation (Bahdanau et al., 2014).</p>
</li>
</ol>
<p>To the best of our knowledge, this is <strong>the first effort to adopt attention-based model in distant supervised relation extraction</strong>.</p>
</blockquote>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p>给定一个句子集合 <strong>${x_1,x_2,\cdot\cdot\cdot,x_n}$</strong> 和<strong>两个相对应的实体 (头实体和尾实体)</strong>, 本论文的模型预测<strong>每个关系</strong> $r$ 成立的概率.</p>
<p><strong>模型包含两个部分:</strong></p>
<ul>
<li><p><strong>语句编码器</strong> (Sentence Encoder). 给定一个句子 $x$ 和两个目标实体 (头实体和尾实体), 使用一个卷积神经网络 (CNN) 来<strong>提取句子的向量表示 $x$</strong>. (原始句子和句子的向量都用 <strong>$x$</strong> 表示)</p>
</li>
<li><p><strong>选择性注意力机制</strong> (Selective Attention over Instances). 当获取到<strong>所有实例 (句子) 的向量表示</strong>后, 本论文的模型使用<strong>语句级别的选择性注意力机制</strong>来选择<strong>那些能够真正表达对应关系</strong>的语句, 并赋予其更高的权重.</p>
</li>
</ul>
<h4 id="语句编码器"><a href="#语句编码器" class="headerlink" title="语句编码器"></a>语句编码器</h4><p>如下图所示, <strong>CNN</strong> 将句子 $x$ 转换为它的向量表示 <strong>$x$</strong>. 首先, <strong>句子中的单词</strong>被转换成<strong>稠密实值特征向量</strong> (词嵌入, 实值: <strong>C&#x2F;C++</strong> 中的 <strong>float</strong> 类型, <strong>32</strong> 位). 然后, <strong>卷积层</strong>, <strong>Max 池化层</strong> 和 <strong>非线性激活函数</strong> 被用来提取<strong>句子的向量表示 $x$</strong>.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221019200710.png"></p>
<h5 id="输入表示"><a href="#输入表示" class="headerlink" title="输入表示"></a>输入表示</h5><p><strong>CNN</strong> 的输入是句子 $x$ 的<strong>原始单词</strong>. 首先将<strong>单词</strong>转换成<strong>低维向量</strong>. 本论文的模型通过<strong>词嵌入矩阵</strong>将<strong>输入的每一个单词</strong>转换成一个<strong>向量</strong>. 此外, 为了<strong>指定每个实体对的位置</strong>, 为句子中的<strong>每个单词</strong>使用了<strong>位置嵌入</strong>.</p>
<p><strong>词嵌入</strong> (<strong>Word Embeddings</strong>). <strong>词嵌入</strong>旨在将<strong>离散字符形式的单词</strong>转换为<strong>连续向量空间中分布式表示</strong>, 从而<strong>捕捉到单词句法和所对应的语义信息</strong>. 给定一个包含 $m$ 个单词的句子 $x &#x3D; {w_1,w_2,\cdot\cdot\cdot,w_m}$, 每一个单词 $w_i$ 都用一个<strong>实值向量</strong>表示. <strong>单词的表示</strong>用一个<strong>词嵌入矩阵</strong> <strong>$V \in \mathbb{R}^{d^a\times\mid V\mid}$</strong> 的<strong>列向量</strong>来编码, 其中 <strong>$V$</strong> 是一个<strong>固定大小的词汇表</strong> (单词的总数固定).</p>
<p><strong>位置嵌入</strong> (<strong>Position Embeddings</strong>). 在关系抽取的任务中, <strong>靠近目标实体的单词</strong>通常具有<strong>决定目标实体间关系的信息</strong>. 类似于 (Zeng et al., 2014)<a href="#6"><sup>6</sup></a> 的处理方法, <strong>由实体对指定的位置嵌入</strong>帮助 <strong>CNN</strong> 观察<strong>每一单词</strong>相对<strong>头实体</strong>或<strong>尾实体</strong>的<strong>相对距离</strong>, <strong>位置嵌入被定义为当前词相对头实体或尾实体的相对距离的组合</strong>. 例如, <strong>“Bill_Gates is the founder of Microsoft.”</strong>, <strong>单词 “founder” 到头实体 “Bill_Gates” 的相对距离是 3</strong>, <strong>到尾实体 “Microsoft” 的相对距离是 2</strong>.</p>
<p>上图中, 假定<strong>词嵌入的维度</strong> $d^a$ 是 <em>3</em>, <strong>位置嵌入的维度</strong> $d^b$ 是 <em>1</em>. 最后, 将<strong>所有单词的词嵌入和位置嵌入</strong>拼接 (<strong>concatenate</strong>) 起来, 表示成一个<strong>向量序列</strong> $w &#x3D; {w_1,w_2,\cdot\cdot\cdot,w_m}$, 其中 $w_i \in \mathbb{R}^d$ ($d &#x3D; d^a + d^b \times 2$).</p>
<h5 id="卷积层-Max-池化层-和-非线性激活函数"><a href="#卷积层-Max-池化层-和-非线性激活函数" class="headerlink" title="卷积层, Max 池化层 和 非线性激活函数"></a>卷积层, Max 池化层 和 非线性激活函数</h5><p>在关系抽取中, 主要的<strong>挑战</strong>是:</p>
<ol>
<li><p><strong>句子的长度是可变的</strong>.</p>
</li>
<li><p><strong>重要信息可能出现在句子的任何位置</strong>.</p>
</li>
</ol>
<p>因此, 应该<strong>利用所有的局部特征</strong>, 并在<strong>全局范围上进行关系预测</strong>. 可以使用一个<strong>卷积层</strong>来<strong>融合所有局部特征</strong>.</p>
<p><strong>卷积层</strong>首先使用一个在句子上滑动的长度为 $l$ 的窗口<strong>提取局部特征</strong> (<strong>一维卷积</strong>), 上图中, 假定<strong>滑动窗口的长度</strong>是 <em>3</em>. 然后, 通过一个 <strong>Max 池化层</strong>合并<strong>所有的局部特征</strong>, 进而为<strong>每一个输入的句子</strong>得到<strong>一个固定大小的向量</strong>.</p>
<p><strong>卷积</strong>被定义为<strong>一个向量序列</strong> $w$ 和<strong>一个卷积矩阵</strong> $W \in \mathbb{R}^{d^c \times (l \times d)}$ 间的操作, 其中 $d^c$ 是<strong>句子嵌入的维度</strong>. 向量 $q_i \in \mathbb{R}^{l \times d}$ 是第 $i$ 个窗口中的<strong>词嵌入 $w$ 序列</strong>的<strong>拼接</strong>.</p>
<p>$$<br>q_i &#x3D; w_{i - l + 1 : i}\quad\quad(1 \leq i \leq m + l - 1). \tag{1}<br>$$</p>
<p>当窗口<strong>在边界附近滑动</strong>时, 它可能<strong>在句子边界之外</strong>, 因此, 为<strong>句子</strong>设置了<strong>特殊的填充标记</strong>. 意味着将<strong>所有超出范围的输入向量</strong> $w_i(i &lt; 1\quad or\quad i &gt; m)$ 视为<strong>零向量</strong>.</p>
<p>卷积层的第 $i$ 个卷积输出为:</p>
<p>$$<br>p_i &#x3D; [Wq + b]_i \tag{2}<br>$$</p>
<p>其中 $b$ 是偏置向量. <strong>句子向量</strong> $x \in \mathbb{R}^{d^c}$ 的第 $i$ 个元素:</p>
<p>$$<br>[x]_i &#x3D; max(p_i), \tag{3}<br>$$</p>
<p>其中 $[x]_i$ 中的 $i$ 是<strong>句子向量</strong> $x \in \mathbb{R}^{d^c}$ 的第 $i$ 个元素, $p_i$ 中的 $i$ 是第 $i$ 窗口.</p>
<p>进一步, PCNN (Zeng et al., 2015)<a href="#4"><sup>4</sup></a>, 是一个 <strong>CNN</strong> 的变体, 采用了分段 Max 池化操作来进行关系抽取, 每一个卷积输出 $p_i$ 被头实体和尾实体划分成三个片段 $(p_{i1},p_{i2},p_{i3})$. <strong>最大池化过程</strong>分别在三个片段中执行. 定义如下:</p>
<p>$$<br>[x]<em>{ij} &#x3D; max(p</em>{ij}), \tag{4}<br>$$</p>
<p>句子向量 $[x]<em>i$ 是三部分池化结果 $[x]</em>{ij}$ 的拼接 (concatenation).</p>
<p>最后, 是一个<strong>非线性激活函数</strong>, 如<strong>双曲切线函数</strong> (<strong>the hyperbolic tangent</strong>).</p>
<p><strong>双曲正切函数</strong>（$tanh$）是<strong>双曲正弦函数</strong>（$sinh$）与<strong>双曲余弦函数</strong>（$cosh$）的比值，其解析形式为：</p>
<p>$$<br>tanh x &#x3D; \frac{sinh x}{cosh x} &#x3D; \frac{e^x - e^{-x}}{e^x + e^{-x}}<br>$$</p>
<p><strong>导数</strong></p>
<p>$$<br>(tanh x)^{‘} &#x3D; sech^2x &#x3D; \frac{1}{cosh^2x} &#x3D; 1 - tanh^2x<br>$$</p>
<p><strong>图像</strong></p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221007184613.png"></p>
<h4 id="面向多实例的选择性注意力机制"><a href="#面向多实例的选择性注意力机制" class="headerlink" title="面向多实例的选择性注意力机制"></a>面向多实例的选择性注意力机制</h4><p>假设有一个包含 $n$ 个句子的集合 $S &#x3D; {x_1,x_2,\cdot\cdot\cdot,x_n}$, 每一个句子都包含<strong>实体对</strong> $(head,tail)$.</p>
<p>为了<strong>利用所有句子的信息</strong>, 本论文的模型在预测关系 $r$ 时, 用<strong>实值向量</strong> $s$ 表示集合 $S$. 很容易想到, 集合 $S$ 的表示取决于所有句子的表示 $x_1,x_2,\cdot\cdot\cdot,x_n$. 每个句子表示 <strong>$x_i$</strong> 包含对于输入句子 $x_i$ 其中实体对 $(head,tail)$ 是否包含关系 $r$ 的信息.</p>
<p>集合向量 $s$ 被计算为这些句子向量 $x_i$ 的加权和:</p>
<p>$$<br>s &#x3D; \sum_i a_ix_i, \tag{5}<br>$$</p>
<p>其中 $a_i$ 是每一个句子向量 $x_i$ 的权重.</p>
<p>本论文中, $a_i$ 有两种方式的定义:</p>
<p><strong>Average:</strong> 假定所有的句子对于 $s$ 有相同的贡献, 所以集合 $S$ 的嵌入向量 $s$ 是所有句子向量的平均值:</p>
<p>$$<br>s &#x3D; \sum_i \frac{1}{n}x_i, \tag{6}<br>$$</p>
<p>这是选择性注意力机制<strong>最朴素的基线</strong>.</p>
<p><strong>Selective Attention:</strong> 远程监督不可避免的带来<strong>错误标注</strong>的问题, 因此, 如果简单将每个句子视为<strong>等价的</strong>, 错误标注的句子将在训练和测试过程中带来<strong>大量的噪声</strong>. 因此, 本论文的模型使用选择性注意力机制降噪 (<strong>de-emphasize the noisy sentence</strong>). $a_i$ 进一步被定义为:</p>
<p>$$<br>a_i &#x3D; \frac{exp(e_i)}{\sum_kexp(e_k)} \tag{7}<br>$$</p>
<p>其中, $e_i$ 被称为<strong>基于查询 (query-based) 的函数</strong>, 它<strong>对输入句子 $x_i$ 和预测关系 $r$ 的匹配程度进行评分</strong>. 本论文的模型选择在不同替代方案中<strong>实现最佳性能的双线性形式</strong> (the bilinear form):</p>
<p>$$<br>e_i &#x3D; x_iAr, \tag{8}<br>$$</p>
<p>其中, <strong>$A$</strong> 是一个<strong>加权对角矩阵</strong> (a weighted diagonal matrix), <strong>$r$ 是与关系 $r$ 相关联的查询向量</strong>, 它指示了关系 $r$ 的表示.</p>
<p>最终, 通过一个 <strong>softmax</strong> 层定义了<strong>条件概率</strong> $p(r\mid S, θ)$:</p>
<p>$$<br>p(r\mid S, θ) &#x3D; \frac{exp(o_r)}{\sum_{k&#x3D;1}^{n_r} exp(o_k)}, \tag{9}<br>$$</p>
<p>其中, $n_r$ 是<strong>关系的总数</strong>, $o$ 是神经网络的<strong>最终输出</strong>, 它表示对<strong>所有关系类型</strong>的<strong>预测评分</strong>, 被定义为:</p>
<p>$$<br>o &#x3D; Ms + d. \tag{10}<br>$$</p>
<p>其中 $d \in \mathbb{R}^{n_r}$ 是一个<strong>偏置向量</strong>, $M$ 是<strong>所有关系类型的表示矩阵</strong> (即<strong>所有关系类型对应的特征向量</strong>所构成的<strong>矩阵</strong>).</p>
<blockquote>
<p>(Zeng et al., 2015)<a href="#4"><sup>4</sup></a>follows the assumption that <strong>at least one mention of the entity pair will reflect their relation</strong>, and <strong>only uses the sentence with the highest probability in each set for training</strong>. Hence, the method which they adopted for multi-instance learning can be regarded as <strong>a special case as our selective attention</strong> when <strong>the weight of the sentence with the highest probability is set to 1 and others to 0</strong>.</p>
</blockquote>
<h4 id="优化和实现细节"><a href="#优化和实现细节" class="headerlink" title="优化和实现细节"></a>优化和实现细节</h4><p><strong>目标函数</strong>. <strong>交叉熵误差</strong> (cross entropy error), 定义如下:</p>
<p>$$<br>J(θ) &#x3D; \sum_{i&#x3D;1}^{s} log p(r_i \mid S_i, θ), \tag{11}<br>$$</p>
<p>其中, $s$ 是句子的个数, $θ$ 是模型的全部参数, $r_i$ 中的 $i$ 是第 $i$ 个关系, $S_i$ 中的 $i$ 是第 $i$ 个句子. 优化方法是<strong>随机梯度下降</strong> (stochastic gradient descent, <strong>SGD</strong>). 从训练集中<strong>随机选择一个小批次</strong> (mini-batch) 迭代训练直到模型收敛.</p>
<p>在最终的输出层使用 <strong>dropout</strong> (Srivastava et al., 2014)<a href="#7"><sup>7</sup></a> 预防<strong>过拟合</strong>. <strong>dropout</strong> 被定义为与一个向量 $h$ 的<strong>对应元素的乘法</strong> (<strong>element-wise multiplication</strong>), 该向量的元素是概率为 $p$ 的伯努利随机变量 (<strong>Bernoulli random variables</strong>), 因此公式 $(10)$ 被重写为:</p>
<p>$$<br>o &#x3D; M(s \circ h) + d. \tag{12}<br>$$</p>
<p>在测试阶段, 学习到的集合表示被 $p$ 缩放, 即 $\hat{s_i} &#x3D; ps_i$. 缩放过的集合向量 $\hat{o_i}$ 最终被用于预测关系.</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><blockquote>
<p>Our experiments are intended to demonstrate that <strong>our neural models with sentence-level selective attention can alleviate the wrong labelling problem</strong> and <strong>take full advantage of informative sentences for distant supervised relation extraction</strong>.</p>
</blockquote>
<h4 id="数据集和评测指标"><a href="#数据集和评测指标" class="headerlink" title="数据集和评测指标"></a>数据集和评测指标</h4><p>在关系抽取任务中, (Riedel et al., 2010)<a href="#8"><sup>8</sup></a> 开发的数据集被全世界研究者广泛应用. 该数据集是通过将 <strong>Freebase</strong> 知识图谱中的世界知识与 <strong>&lt;&lt;纽约时报&gt;&gt;</strong> 语料库 (NYT) 中的语料进行对齐而生成的 (This dataset was generated by aligning Freebase relations with the New York Times corpus (NYT)). 实体是使用<strong>斯坦福大学命名实体标记器</strong>找到的, 并进一步与 <strong>Freebase</strong> 实体名称相匹配 (Entity mentions are found using the Stanford named entity tagger (Finkel et al., 2005), and are further matched to the names of Freebase entities). 数据集包含两部分: <strong>训练集</strong>和<strong>测试集</strong>. 对齐了 <strong>2005-2006</strong> 年语料库中的句子, 并将它们视为<strong>训练实例</strong>. <strong>测试实例</strong>是 <strong>2007</strong> 年的对齐句子. 整个数据集合包含 <strong>53</strong> 种关系类型, 包含一种特殊类型关系 —— <strong>NA</strong>, 其表示头尾实体之间没有明确定义关系.</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center"><strong>number of sentences</strong></th>
<th align="center"><strong>number of entity pairs</strong></th>
<th align="center"><strong>number of relational facts (not NA)</strong></th>
<th align="center"><strong>number of sentences &#x2F; number of  entity pairs</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><strong>training set</strong></td>
<td align="center">522,611</td>
<td align="center">281,270</td>
<td align="center">18,252</td>
<td align="center">1.86</td>
</tr>
<tr>
<td align="center"><strong>testing set</strong></td>
<td align="center">172,448</td>
<td align="center">96,678</td>
<td align="center">1,950</td>
<td align="center">1.78</td>
</tr>
</tbody></table>
<p>通过比较模型在测试集中挖掘出的世界知识与 <strong>Freebase</strong> 中的世界知识的重合度来评估关系抽取效果.</p>
<blockquote>
<p>we evaluate our model in <strong>the held-out evaluation</strong>. It evaluates our model by comparing <strong>the relation facts discovered from the test articles</strong> with <strong>those in Freebase</strong>.</p>
<p><strong>It assumes that the testing systems have similar performances in relation facts inside and outside Freebase.</strong></p>
<p>Hence, the held-out evaluation <strong>provides an approximate measure of precision without time consumed human evaluation</strong>.</p>
</blockquote>
<p>具体的模型性能则通过<strong>精度——召回率曲线 (the aggregate curves precision&#x2F;recall curves)<strong>和</strong>最高置信度预测精度</strong> (<strong>Precision@N, P@N</strong>) 来体现.</p>
<h4 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h4><h5 id="词嵌入"><a href="#词嵌入" class="headerlink" title="词嵌入"></a>词嵌入</h5><p>使用 <strong>word2vec</strong><a href="#9"><sup>9</sup></a> 工具在 <strong>NYT 语料库</strong>训练<strong>词嵌入</strong>. 将<strong>语料库</strong>中<strong>出现超过 100 次的单词</strong>保留为<strong>词汇</strong>. 当一个实体有多个单词时, <strong>连接</strong> (<strong>concatenate</strong>) 它的单词.</p>
<h5 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h5><p>在<strong>训练集</strong>上使用<strong>三折交叉验证</strong> (<strong>three-fold validation</strong>) 调整模型, 使用网格搜索 <strong>(grid search)</strong> 确定最优参数.</p>
<p>对于<strong>训练</strong>, 将<strong>所有训练数据</strong>的<strong>迭代次数</strong>设置为 <strong>25</strong>.</p>
<p>最优超参数设置如下:</p>
<table>
<thead>
<tr>
<th align="center">参数</th>
<th align="center">值</th>
</tr>
</thead>
<tbody><tr>
<td align="center">卷积窗口大小  $l$</td>
<td align="center">3</td>
</tr>
<tr>
<td align="center">句子表示维度  $d^c$</td>
<td align="center">230</td>
</tr>
<tr>
<td align="center">词向量维度  $d^a$</td>
<td align="center">50</td>
</tr>
<tr>
<td align="center">位置向量维度  $d^b$</td>
<td align="center">5</td>
</tr>
<tr>
<td align="center">训练批次大小  $B$</td>
<td align="center">160</td>
</tr>
<tr>
<td align="center">学习率  $\lambda$</td>
<td align="center">0.01</td>
</tr>
<tr>
<td align="center">Dropout probability  $p$</td>
<td align="center">0.5</td>
</tr>
</tbody></table>
<h4 id="选择性注意力机制的有效性验证"><a href="#选择性注意力机制的有效性验证" class="headerlink" title="选择性注意力机制的有效性验证"></a>选择性注意力机制的有效性验证</h4><p>为了证明<code>语句级别选择性注意力机制</code>的有效性, 通过<code>保留评估</code> ( <strong>held-out evaluation</strong>) 比较不同的方法. 选择 <code>Zeng</code> 等人<a href="#4"><sup>4</sup></a><a href="#6"><sup>6</sup></a>提出的<code>卷积神经网路模型</code> <code>CNN</code> 及其变种模型 <code>PCNN</code> 作为句子编码器 (implement them by ourselves which achieve comparable results as the authors reported). 作者将<code>两种不同类型</code>的<code>卷积神经网络</code>分别与<code>句子级别注意力机制 ATT</code>、<code>ATT 的基线版本 AVE</code> (在该版本中, <code>每个实例集合的向量</code>表示为<code>集合内部实例的平均向量</code>) 及 Zeng 等人<a href="#4"><sup>4</sup></a>提出的<code>多实例学习方法 ONE</code> 进行了结合, 并比较了它们的表现.</p>
<hr>
<p><strong>句子编码器</strong>:</p>
<ol>
<li><p>the <strong>CNN</strong> model proposed in (Zeng et al., 2014)<a href="#6"><sup>6</sup></a></p>
</li>
<li><p>the <strong>PCNN</strong> model proposed in (Zeng et al., 2015)<a href="#4"><sup>4</sup></a></p>
</li>
</ol>
<p>比较了<strong>两种 CNN</strong>, 它们<strong>带有句子级别注意力机制的版本 (ATT)</strong>, 它们的<strong>朴素版本 (AVE)</strong>, 它们的<strong>多实例学习方法</strong><a href="#4"><sup>4</sup></a> (the at-least-one multi-instance learning, ONE) 的<strong>表现</strong>.</p>
<hr>
<p><code>Precion/recall curves</code> of <code>CNN</code>, <code>CNN+ONE</code>, <code>CNN+AVE</code>, <code>CNN+ATT</code></p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221020185854.png"></p>
<p><code>Precion/recall curves</code> of <code>PCNN</code>, <code>PCNN+ONE</code>, <code>PCNN+AVE</code>, <code>PCNN+ATT</code></p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221020185913.png"></p>
<p>从上图, 作者得到了如下<code>观察结果</code>:</p>
<ol>
<li><p>对于 <code>CNN</code> 和 <code>PCNN</code>, <code>ONE</code> 方法与 <code>CNN/PCNN</code> 相比<code>具有更好的性能</code>. 原因在于<code>原始的基于远程监督得到的训练数据</code>包含<code>大量的噪声数据</code>, 而<code>噪声数据</code>会损害<code>关系抽取的性能</code>. <strong><code>ONE 方法</code>引入<code>多实例学习</code>, 这<code>在一定程度上</code>减缓了该问题.</strong></p>
</li>
<li><p>对于 <code>CNN</code> 和 <code>PCNN</code>, 与 <code>CNN/PCNN</code> 相比, <code>AVE 方法</code>对<code>关系抽取模型</code>的<code>效果提升</code>是有作用的. 这表明<code>考虑更多的实例</code>有利于<code>关系抽取</code>, 因为<code>噪声信息</code>可以通过<code>信息的互补</code>来<code>减少负面影响</code>, <strong><code>更多的实例也带来了更多的信息</code>.</strong></p>
</li>
<li><p>对于 <code>CNN</code> 和 <code>PCNN</code>, <code>AVE 方法</code>与 <code>ONE 方法</code>相比具有<code>相似</code>的性能. 这说明, 尽管 <code>AVE</code> 方法引入了<code>更多的实例信息</code>, 但由于它将<code>每个句子</code>赋予<code>同等的权重</code>, 它也会<code>从错误标注的语句中得到负面的噪声信息</code>, 从而<code>损害</code>关系抽取的性能. <strong>所以 <code>AVE</code> 方法与 <code>ONE</code> 方法<code>难以分出优劣</code>.</strong></p>
</li>
<li><p>对于 <code>CNN</code> 和 <code>PCNN</code>, 与包括 <code>AVE</code> 方法在内的<code>其他方法</code>相比, <code>ATT 方法</code>在<code>整个召回范围内</code>实现了<code>最高的精度</code>. 它表明, 所提出的<strong>选择性注意力机制</strong>是有益的. 它<code>可以有效地滤除无意义的句子</code>, <code>解决基于远程监督的关系抽取中的错误标注问题</code>, <strong><code>并尽可能地充分利用每一个实例的信息进行关系抽取</code>.</strong></p>
</li>
</ol>
<h4 id="实例数量的影响分析"><a href="#实例数量的影响分析" class="headerlink" title="实例数量的影响分析"></a>实例数量的影响分析</h4><p>在<code>原始测试数据集</code>中, 有 <code>74,857</code> 个实体对<code>仅对应于一个句子</code>, 几乎占所有实体对的 <code>3/4</code>. 由于<code>选择性注意力机制的优势</code>在于<code>处理包含多个实例的实体对</code>, 所以实验比较了 <code>CNN/PCNN+ONE</code>、<code>CNN/PCNN+AVE</code>、以及采用了<code>注意力机制</code>的 <code>CNN/PCNN+ATT</code> 在<code>具有不同实例数量的实体对集合</code>上的表现. 具体有以下 <code>3</code> 个实验场景.</p>
<ul>
<li><p><strong>One</strong>: 对于<code>每个测试实体对</code>, <code>随机选择</code>其对应的实例集合中的<code>一个实例</code>, 并将<code>这个实例</code>用作关系预测.</p>
</li>
<li><p><strong>Two</strong>: 对于<code>每个测试实体对</code>, <code>随机选择</code>其对应的实例集合中的<code>两个实例</code>, 并将<code>这两个实例</code>用作关系预测.</p>
</li>
<li><p><strong>All</strong>: 对于<code>每个测试实体对</code>, 使用其对应的实例集合中的<code>所有实例</code>进行<code>关系预测</code>.</p>
</li>
</ul>
<p><strong>值得注意的是</strong>, 在训练过程中, <strong><code>使用了所有实例</code></strong>. 实验汇报了<code>所有预测中评分最高的 N 项预测</code>的<code>预测精度 P@N</code>, 具体有 <code>P@100</code>、<code>P@200</code>、<code>P@300</code> 及它们的<code>平均值</code>. 各个模型<code>在实体对拥有不同实例数目情况下</code>的 <code>P@N 的效果对比</code>如下表所示.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221020203352.png"></p>
<p>从上表中, 可以观察到:</p>
<ol>
<li><p>对于 <code>CNN</code> 和 <code>PCNN</code>, <code>ATT 方法</code>在<code>所有测试设置</code>中<code>均达到最佳性能</code>. 它表明了<code>句子级选择性注意力机制</code>对于<code>多实例学习</code>的<code>有效性</code>.</p>
</li>
<li><p>对于 <code>CNN</code> 和 <code>PCNN</code>, <code>AVE 方法</code>在 <code>One</code> 测试设置下, <code>效果与 ATT 方法相当</code>. 然而, 当<code>每个实体对</code>的<code>测试实例数量</code>增加时, <code>AVE 方法的性能</code>几乎没有改善. 随着<code>实例的增加</code>, 它甚至在 <code>P@100</code>、<code>P@200</code> 中<code>逐渐下降</code>. 原因在于, 由于 <code>AVE</code> 方法<code>对每个实例同等看待</code>, <code>实例包含的不表达任何关系的噪声数据</code>对于<code>关系抽取</code>的表现<code>会产生负面影响</code>.</p>
</li>
<li><p>在 <code>One</code> 测试设置下, <code>CNN+AVE</code> 和 <code>CNN+ATT</code> 与 <code>CNN+ONE</code> 相比有 <code>5 ～ 8</code> 个百分点的改进. <code>每个实体对</code>在这个测试设置中<code>只有一个实例</code>, 这些方法的<code>唯一区别</code>来自<code>训练方式的不同</code>. 因此, 实验结果表明<code>利用所有的实例会带来更多的信息</code>, 尽管这也可能<code>带来一些额外的噪声</code>. <strong><code>这些附带的信息</code>在训练过程中<code>提升了模型效果</code>.</strong></p>
</li>
<li><p>对于 <code>CNN</code> 和 <code>PCNN</code>, <code>ATT 方法</code>在 <code>Two</code> 和 <code>All</code> 测试设置中<code>优于</code>其他两个基线 (over <code>5%</code> and <code>9%</code>). 这表明, 通过<code>考虑更多有用的信息</code>, <code>CNN+ATT 排名较高的关系事实</code>更可靠, 更有利于<code>关系提取</code>.</p>
</li>
</ol>
<h4 id="与基于人工特征工程的方法的性能比较"><a href="#与基于人工特征工程的方法的性能比较" class="headerlink" title="与基于人工特征工程的方法的性能比较"></a>与基于人工特征工程的方法的性能比较</h4><p>为了<code>验证</code>所提出的方法, 作者选择了<code>以下 3 种基于人工特征的方法</code>来进行<code>性能比较</code>.</p>
<ul>
<li><p><strong>Mintz</strong> (Mintz et al., 2009) 是一个<code>传统的基于远程监督</code>的模型.</p>
</li>
<li><p><strong>MultiR</strong> (Hoffmann et al., 2011) 提出了<code>一个概率图模型</code>用于<code>多实例学习</code>, 它的特点<code>在于可以处理关系类型之间的重合</code>.</p>
</li>
<li><p><strong>MIML</strong> (Surdeanu et al., 2012) 同时考虑了<code>多实例</code>和<code>多关系类型</code>两种情况 (即<code>每个实体对</code>可能有<code>多个句子</code>, 也可能有<code>多个关系类型</code>).</p>
</li>
</ul>
<blockquote>
<p>We implement them with the source codes released by the authors.</p>
</blockquote>
<p>每个方法的<code>精度-召回率曲线</code>如下图所示.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221020203439.png"></p>
<p>从上图中, 可以观察到:</p>
<ol>
<li><p>在<code>整个召回率范围</code>内, <code>CNN/PCNN+ATT</code> <strong>显著优于</strong>所有基于人工特征的方法. 当<code>召回率 &gt; 0.1</code> 时, <code>基于特征的方法</code>的性能<code>迅速下降</code>. 相比之下, 在<code>召回率达到约 0.3 之前</code>, 该论文的模型<code>都具有合理的准确率</code>. 这表明<code>人工设计的特征</code>不能简洁地<code>表达实例的语义含义</code>, 而<code>自然语言处理工具</code>带来的<code>错误</code>则会<code>损害</code>关系抽取的性能. 相比之下, 可以<code>自主学习每个实例向量表示</code>的 <code>CNN/PCNN+ATT 模型</code>可以很好地<code>表达每个实例的语义信息</code>.</p>
</li>
<li><p>在<code>整个召回率范围</code>内, <code>PCNN+ATT</code> 与 <code>CNN+ATT</code> 相比<code>表现要好得多</code>. 这意味着<code>选择性注意力机制</code>可以很好地<code>考虑所有实例的全局信息</code>, 但无法使模型<code>对于单个实例</code>的理解和表示变好. 因此, 如果有<code>更好的句子编码器</code>, 那么<code>模型的性能</code>可以<code>进一步提高</code>.</p>
</li>
</ol>
<h4 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h4><p>下表显示了<code>测试数据</code>中<code>选择性注意力机制</code>的<code>两个示例</code>. <code>对于每个关系</code>, 展示了其对应的<code>拥有高注意力权值的句子</code>和<code>拥有低注意力权值的句子</code>, 并且对<code>每个实体对</code>都进行了<code>加粗显示</code>.</p>
<p><img src="https://cos.luyf-lemon-love.space/images/20221020203630.png"></p>
<blockquote>
<p>From the table we find that: <code>The former example</code> is related to <code>the relation employer of</code>. <code>The sentence with low attention weight</code> does not express the relation between two entities, while <code>the high one</code> shows that <strong><code>Mel Karmazin is the chief executive of Sirius Satellite Radio</code></strong>. <code>The later example</code> is related to <code>the relation place of birth</code>. <code>The sentence with low attention weight</code> expresses <code>where Ernst Haefliger is died in</code>, while <code>the high one</code> expresses <code>where he is born in</code>.</p>
</blockquote>
<h3 id="Conclusion-and-Future-Works"><a href="#Conclusion-and-Future-Works" class="headerlink" title="Conclusion and Future Works"></a>Conclusion and Future Works</h3><blockquote>
<p>In this paper, we develop <code>CNN with sentence-level selective attention</code>. Our model can <code>make full use of all informative sentences</code> and <code>alleviate the wrong labelling problem for distant supervised relation extraction</code>. In experiments, we <code>evaluate our model on relation extraction task</code>. The experimental results show that <code>our model significantly and consistently outperforms state-of-the-art feature-based methods and neural network methods</code>.</p>
</blockquote>
<hr>
<blockquote>
<p>In the future, we will explore the following directions:</p>
<ul>
<li><p>Our model <code>incorporates multi-instance learning with neural network via instance-level selective attention</code>. <code>It can be used in not only distant supervised relation extraction but also other multi-instance learning tasks.</code> We will <code>explore our model in other area</code> such as <code>text categorization</code>.</p>
</li>
<li><p><code>CNN</code> is one of the effective neural networks for neural relation extraction. Researchers also propose many other neural network models for relation extraction. In the future, we will <code>incorporate our instance-level selective attention technique with those models for relation extraction</code>.</p>
</li>
</ul>
</blockquote>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><p><strong>代码仓库地址</strong>: <a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/neural-relation-extraction/C%2B%2B">https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/neural-relation-extraction/C%2B%2B</a> .</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ tree
<span class="token builtin class-name">.</span>
├── CNN+ATT
│   ├── clean.sh
│   ├── init.h
│   ├── output
│   │   ├── attention_weights.txt
│   │   ├── conv_1d.txt
│   │   ├── position_vec.txt
│   │   ├── pr.txt
│   │   ├── relation_matrix.txt
│   │   └── word2vec.txt
│   ├── run.sh
│   ├── test.cpp
│   ├── test.h
│   └── train.cpp
├── data
│   ├── relation.txt
│   ├── test.txt
│   ├── train.txt
│   └── vec.bin
├── data.zip
├── papers
│   └── Neural Relation Extraction with Selective Attention over Instances.pdf
└── README.md

<span class="token number">4</span> directories, <span class="token number">19</span> files
$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><h4 id="NYT10"><a href="#NYT10" class="headerlink" title="NYT10"></a>NYT10</h4><p>链接:<a href="https://pan.baidu.com/s/1SIswYS8vvuDAPiJd2L0d5A">https://pan.baidu.com/s/1SIswYS8vvuDAPiJd2L0d5A</a> 提取码:g90p .</p>
<p>The original data of NYT10 can be downloaded from:</p>
<p>Relation Extraction:  NYT10 is originally released by the paper “Sebastian Riedel, Limin Yao, and Andrew McCallum. Modeling relations and their mentions without labeled text.” <a href="http://iesl.cs.umass.edu/riedel/ecml/">[Download]</a></p>
<p>Pre-Trained Word Vectors are learned from New York Times Annotated Corpus (LDC Data LDC2008T19), which should be obtained from LDC (<a href="https://catalog.ldc.upenn.edu/LDC2008T19">https://catalog.ldc.upenn.edu/LDC2008T19</a>).</p>
<p>The train set is generated by merging all training data of manual and held-out datasets, deleted those data that have overlap with the test set, and used the remain one as our training data.</p>
<p>To run the code, the dataset should be put in the folder <strong>data&#x2F;</strong> using the following format, containing four files</p>
<ul>
<li><p><strong>train.txt</strong>: training file, format (fb_mid_e1, fb_mid_e2, e1_name, e2_name, relation, sentence).</p>
</li>
<li><p><strong>test.txt</strong>: test file, same format as train.txt.</p>
</li>
<li><p><strong>relation.txt</strong>: all relations, one per line.</p>
</li>
<li><p><strong>vec.bin</strong>: the pre-train word embedding file.</p>
</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ tree
<span class="token builtin class-name">.</span>
├── relation.txt
├── test.txt
├── train.txt
└── vec.bin

<span class="token number">0</span> directories, <span class="token number">4</span> files
$ <span class="token function">head</span> relation.txt 
NA
/location/neighborhood/neighborhood_of
/location/fr_region/capital
/location/cn_province/capital
/location/in_state/administrative_capital
/base/locations/countries/states_provinces_within
/business/company/founders
/location/country/languages_spoken
/people/person/place_of_birth
/people/deceased_person/place_of_death
$ <span class="token function">head</span> test.txt 
m.01l443l	m.04t_bj	dave_holland	barry_altschul	NA	the occasion was suitably exceptional <span class="token builtin class-name">:</span> a reunion of the 1970s-era sam rivers trio , with dave_holland on bass and barry_altschul on drums <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.01l443l	m.04t_bj	dave_holland	barry_altschul	NA	tonight he brings his energies and expertise to the miller theater <span class="token keyword">for</span> the festival <span class="token string">'s thrilling finale : a reunion of the 1970s sam rivers trio , with dave_holland on bass and barry_altschul on drums .	###END###
m.04t_bj	m.01l443l	barry_altschul	dave_holland	NA	the occasion was suitably exceptional : a reunion of the 1970s-era sam rivers trio , with dave_holland on bass and barry_altschul on drums .	###END###
m.04t_bj	m.01l443l	barry_altschul	dave_holland	NA	tonight he brings his energies and expertise to the miller theater for the festival '</span>s thrilling finale <span class="token builtin class-name">:</span> a reunion of the 1970s sam rivers trio , with dave_holland on bass and barry_altschul on drums <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0frkwp	m.04mh_g	ruth	little_neck	NA	shapiro -- ruth of little_neck , ny <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.04mh_g	m.0frkwp	little_neck	ruth	NA	shapiro -- ruth of little_neck , ny <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.02bv2x	m.01w7tkh	henry	nicole	NA	cherished grandmother of henry , stephanie , harrison and jill shapiro and nicole and eric beinhorn <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.01w7tkh	m.02bv2x	nicole	henry	NA	cherished grandmother of henry , stephanie , harrison and jill shapiro and nicole and eric beinhorn <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0124lx	m.07hjs9	lewis	john_gross	NA	beloved wife of the late dr. frederick e. lane , and mother of joseph , ila lane gross , lewis , and edward <span class="token punctuation">;</span> mother-in-law of bobbi , john_gross , nancy , and judy <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0124lx	m.07hjs9	lewis	john_gross	NA	beloved wife of the late dr. frederick e. lane , and mother of joseph , ila lane gross , lewis , and edward <span class="token punctuation">;</span> mother-in-law of bobbi , john_gross , nancy , and judy <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
$ <span class="token function">head</span> train.txt 
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	sen. charles e. schumer called on federal safety officials yesterday to reopen their investigation into the fatal crash of a passenger jet <span class="token keyword">in</span> belle_harbor , queens , because equipment failure , not pilot error , might have been the cause <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	but instead there was a funeral , at st. francis de sales roman catholic church , <span class="token keyword">in</span> belle_harbor , queens , the parish of his birth <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	rosemary antonelle , the daughter of teresa l. antonelle and patrick antonelle of belle_harbor , queens , was married yesterday afternoon to lt. thomas joseph quast , a son of peggy b. quast and vice adm. philip m. quast of carmel , calif. <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	one was <span class="token keyword">for</span> st. francis de sales roman catholic church <span class="token keyword">in</span> belle_harbor <span class="token punctuation">;</span> another board studded with electromechanical magnets will go under the pipes of an organ at the evangelical lutheran church of christ <span class="token keyword">in</span> rosedale , queens <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	the firefighter , whom a fire department official identified as joseph moore , of belle_harbor , queens , was taken to newyork-presbyterian<span class="token punctuation">\</span>/weill cornell hospital , where he was <span class="token keyword">in</span> critical but stable condition last night , the police said <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	<span class="token keyword">in</span> st. francis de sales roman catholic church <span class="token keyword">in</span> belle_harbor , queens , the second verse of the opening hymn , <span class="token string">''</span> be not afraid , <span class="token string">''</span> seemed to connect katrina and sept. <span class="token number">11</span> <span class="token builtin class-name">:</span> <span class="token string">''</span> <span class="token keyword">if</span> you pass through raging waters <span class="token keyword">in</span> the sea , you shall not drown <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	on nov. <span class="token number">12</span> , <span class="token keyword">while</span> walking his dog near his home <span class="token keyword">in</span> belle_harbor , queens , he saw a passenger plane plunge to the ground <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	colm j. neilson , of belle_harbor , queens , said he thought the conductors <span class="token string">' role was overrated . '</span>'	<span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	she is a daughter of marion i. rabbin and dr. murvin rabbin of belle_harbor , queens <span class="token builtin class-name">.</span><span class="token comment">###END###</span>
m.0ccvx	m.05gf08	queens	belle_harbor	/location/location/contains	he is a son of vera and william lichtenberg of belle_harbor , queens <span class="token builtin class-name">.</span>	<span class="token comment">###END###</span>
$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="CNN-ATT"><a href="#CNN-ATT" class="headerlink" title="CNN+ATT"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/tree/main/neural-relation-extraction/C%2B%2B/CNN%2BATT">CNN+ATT</a></h3><ul>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/init.h">init.h</a>: 该 C++ 文件用于初始化, 即读取训练数据和测试数据.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/test.h">test.h</a>: 该 C++ 文件用于模型测试.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/train.cpp">train.cpp</a>: 该 C++ 文件用于模型训练.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/test.cpp">test.cpp</a>: 该 C++ 文件用于模型测试.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/run.sh">run.sh</a>: 该 Shell 脚本用于模型训练和模型测试.</p>
</li>
<li><p><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/clean.sh">clean.sh</a>: 该 Shell 脚本用于清理临时文件.</p>
</li>
</ul>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ tree
<span class="token builtin class-name">.</span>
├── clean.sh
├── init.h
├── output
│   ├── attention_weights.txt
│   ├── conv_1d.txt
│   ├── position_vec.txt
│   ├── pr.txt
│   ├── relation_matrix.txt
│   └── word2vec.txt
├── run.sh
├── test.cpp
├── test.h
└── train.cpp

<span class="token number">1</span> directory, <span class="token number">12</span> files
$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="init-h"><a href="#init-h" class="headerlink" title="init.h"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/init.h">init.h</a></h4><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; init.h
&#x2F;&#x2F;
&#x2F;&#x2F; created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com&gt;
&#x2F;&#x2F; 
&#x2F;&#x2F; 该 C++ 文件用于初始化, 即读取训练数据和测试数据
&#x2F;&#x2F;
&#x2F;&#x2F; prerequisites:
&#x2F;&#x2F;     ..&#x2F;data&#x2F;vec.bin
&#x2F;&#x2F;     ..&#x2F;data&#x2F;relation.txt
&#x2F;&#x2F;     ..&#x2F;data&#x2F;train.txt
&#x2F;&#x2F;     ..&#x2F;data&#x2F;test.txt

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 包含标准库
&#x2F;&#x2F; ##################################################

#ifndef INIT_H
#define INIT_H

#include &lt;cstdio&gt;          &#x2F;&#x2F; FILE, fscanf, fopen, fclose, fgetc, feof, fread
#include &lt;cstdlib&gt;         &#x2F;&#x2F; malloc, calloc, free, rand, RAND_MAX
#include &lt;cmath&gt;           &#x2F;&#x2F; exp, fabs
#include &lt;cstring&gt;         &#x2F;&#x2F; memcpy
#include &lt;cfloat&gt;          &#x2F;&#x2F; FLT_MAX
#include &lt;cassert&gt;         &#x2F;&#x2F; assert
#include &lt;pthread.h&gt;       &#x2F;&#x2F; pthread_create, pthread_join, pthread_mutex_t
#include &lt;sys&#x2F;time.h&gt;      &#x2F;&#x2F; timeval, gettimeofday
#include &lt;vector&gt;          &#x2F;&#x2F; std::vector, std::vector::resize, std::vector::operator[], std::vector::push_back, std::vector::size
#include &lt;map&gt;             &#x2F;&#x2F; std::map, std::map::operator[], std::map::clear, std::map::size
#include &lt;string&gt;          &#x2F;&#x2F; std::string, std::string::c_str
#include &lt;algorithm&gt;       &#x2F;&#x2F; std::sort, std::min
#include &lt;utility&gt;         &#x2F;&#x2F; std::make_pair

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 声明和定义超参数变量
&#x2F;&#x2F; ##################################################

#define INT int
#define REAL float

&#x2F;&#x2F; batch: batch size
&#x2F;&#x2F; num_threads: number of threads
&#x2F;&#x2F; alpha: learning rate
&#x2F;&#x2F; current_rate: init rate of learning rate
&#x2F;&#x2F; reduce_epoch: reduce of init rate of learning rate per epoch
&#x2F;&#x2F; epochs: epochs
&#x2F;&#x2F; limit: 限制句子中 (头, 尾) 实体相对每个单词的最大距离
&#x2F;&#x2F; dimension_pos: position dimension
&#x2F;&#x2F; window: window size
&#x2F;&#x2F; dimension_c: sentence embedding size
&#x2F;&#x2F; dropout_probability: dropout probability
&#x2F;&#x2F; output_model: 是否保存模型, 1: 保存模型, 0: 不保存模型
&#x2F;&#x2F; note: 保存模型时, 文件名的额外的信息, (&quot;.&#x2F;output&#x2F;word2vec&quot; + note + &quot;.txt&quot;)
&#x2F;&#x2F; data_path: folder of data
&#x2F;&#x2F; output_path: folder of outputing results (precion&#x2F;recall curves) and models
INT batch &#x3D; 40;
INT num_threads &#x3D; 32;
REAL alpha &#x3D; 0.00125;
REAL current_rate &#x3D; 1.0;
REAL reduce_epoch &#x3D; 0.98;
INT epochs &#x3D; 25;
INT limit &#x3D; 30;
INT dimension_pos &#x3D; 5;
INT window &#x3D; 3;
INT dimension_c &#x3D; 230;
REAL dropout_probability &#x3D; 0.5;
INT output_model &#x3D; 0;
std::string note &#x3D; &quot;&quot;;
std::string data_path &#x3D; &quot;..&#x2F;data&#x2F;&quot;;
std::string output_path &#x3D; &quot;.&#x2F;output&#x2F;&quot;;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 声明和定义保存训练数据和测试数据的变量
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; word_total: 词汇总数, 包括 &quot;UNK&quot;
&#x2F;&#x2F; dimension: 词嵌入维度
&#x2F;&#x2F; word_vec (word_total * dimension): 词嵌入矩阵
&#x2F;&#x2F; word2id (word_total): word2id[name] -&gt; name 对应的词汇 id
INT word_total, dimension;
REAL *word_vec;
std::map&lt;std::string, INT&gt; word2id;

&#x2F;&#x2F; relation_total: 关系总数
&#x2F;&#x2F; id2relation (relation_total): id2relation[id] -&gt; id 对应的关系名
&#x2F;&#x2F; relation2id (relation_total): relation2id[name] -&gt; name 对应的关系 id
INT relation_total;
std::vector&lt;std::string&gt; id2relation;
std::map&lt;std::string, INT&gt; relation2id;

&#x2F;&#x2F; position_min_head: 保存数据集 (训练集, 测试集) 句子中头实体相对每个单词的最小距离, 理论上取值范围为 -limit
&#x2F;&#x2F; position_max_head: 保存数据集 (训练集, 测试集) 句子中头实体相对每个单词的最大距离, 理论上取值范围为 limit
&#x2F;&#x2F; position_min_tail: 保存数据集 (训练集, 测试集) 句子中尾实体相对每个单词的最小距离, 理论上取值范围为 -limit
&#x2F;&#x2F; position_max_tail: 保存数据集 (训练集, 测试集) 句子中尾实体相对每个单词的最大距离, 理论上取值范围为 limit
&#x2F;&#x2F; position_total_head &#x3D; position_max_head - position_min_head + 1
&#x2F;&#x2F; position_total_tail &#x3D; position_max_tail - position_min_tail + 1
INT position_min_head, position_max_head, position_min_tail, position_max_tail;
INT position_total_head, position_total_tail;

&#x2F;&#x2F; bags_train: key -&gt; (头实体 + &quot;\t&quot; + 尾实体 + &quot;\t&quot; + 关系名), value -&gt; 句子索引 (训练文件中该句子的位置)
&#x2F;&#x2F; train_relation_list: 保存训练集每个句子的关系 id, 按照训练文件句子的读取顺序排列
&#x2F;&#x2F; train_length: 保存训练集每个句子的单词个数, 按照训练文件句子的读取顺序排列
&#x2F;&#x2F; train_sentence_list: 保存训练集中的句子, 按照训练文件句子的读取顺序排列
&#x2F;&#x2F; train_position_head: 保存训练集每个句子的头实体相对每个单词的距离, 理论上取值范围为 [0, 2 * limit], 其中头实体对应单词的取值为 limit
&#x2F;&#x2F; train_position_tail: 保存训练集每个句子的尾实体相对每个单词的距离, 理论上取值范围为 [0, 2 * limit], 其中尾实体对应单词的取值为 limit
std::map&lt;std::string, std::vector&lt;INT&gt; &gt; bags_train;
std::vector&lt;INT&gt; train_relation_list, train_length;
std::vector&lt;INT *&gt; train_sentence_list, train_position_head, train_position_tail;

&#x2F;&#x2F; bags_test: key -&gt; (头实体 + &quot;\t&quot; + 尾实体), value -&gt; 句子索引 (测试文件中该句子的位置)
&#x2F;&#x2F; test_relation_list: 保存测试集每个句子的关系 id, 按照测试文件句子的读取顺序排列
&#x2F;&#x2F; test_length: 保存测试集每个句子的单词个数, 按照测试文件句子的读取顺序排列
&#x2F;&#x2F; test_sentence_list: 保存测试集中的句子, 按照测试文件句子的读取顺序排列
&#x2F;&#x2F; test_position_head: 保存测试集每个句子的头实体相对每个单词的距离, 理论上取值范围为 [0, 2 * limit], 其中头实体对应单词的取值为 limit
&#x2F;&#x2F; test_position_tail: 保存测试集每个句子的尾实体相对每个单词的距离, 理论上取值范围为 [0, 2 * limit], 其中尾实体对应单词的取值为 limit
std::map&lt;std::string, std::vector&lt;INT&gt; &gt; bags_test;
std::vector&lt;INT&gt; test_relation_list, test_length;
std::vector&lt;INT *&gt; test_sentence_list, test_position_head, test_position_tail;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 声明和定义模型的权重矩阵
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; position_vec_head (position_total_head * dimension_pos): 头实体的位置嵌入矩阵
&#x2F;&#x2F; position_vec_tail (position_total_tail * dimension_pos): 尾实体的位置嵌入矩阵
REAL *position_vec_head, *position_vec_tail;

&#x2F;&#x2F; conv_1d_word (dimension_c * window * dimension): 一维卷积的权重矩阵 (词嵌入)
&#x2F;&#x2F; conv_1d_position_head (dimension_c * window * dimension_pos): 一维卷积的权重矩阵 (头实体的位置嵌入)
&#x2F;&#x2F; conv_1d_position_tail (dimension_c * window * dimension_pos): 一维卷积的权重矩阵 (尾实体的位置嵌入)
&#x2F;&#x2F; conv_1d_bias (dimension_c): 一维卷积的偏置向量
REAL *conv_1d_word, *conv_1d_position_head, *conv_1d_position_tail, *conv_1d_bias;

&#x2F;&#x2F; attention_weights (relation_total * dimension_c * dimension_c): 注意力权重矩阵
std::vector&lt;std::vector&lt;std::vector&lt;REAL&gt; &gt; &gt; attention_weights;

&#x2F;&#x2F; relation_matrix (relation_total * dimension_c): the representation matrix of relation
&#x2F;&#x2F; relation_matrix_bias (relation_total): the bias vector of the representation matrix of relation
REAL *relation_matrix, *relation_matrix_bias;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 声明和定义模型的权重矩阵的副本, 用于每一训练批次计算损失值
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; word_vec_copy (word_total * dimension): 词嵌入矩阵副本, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
&#x2F;&#x2F; position_vec_head_copy (position_total_head * dimension_pos): 头实体的位置嵌入矩阵副本, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
&#x2F;&#x2F; position_vec_tail_copy (position_total_tail * dimension_pos): 尾实体的位置嵌入矩阵副本, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
REAL *word_vec_copy, *position_vec_head_copy, *position_vec_tail_copy;

&#x2F;&#x2F; conv_1d_word_copy (dimension_c * window * dimension): 一维卷积的权重矩阵 (词嵌入) 副本, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
&#x2F;&#x2F; conv_1d_position_head_copy (dimension_c * window * dimension_pos): 一维卷积的权重矩阵 (头实体的位置嵌入) 副本, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
&#x2F;&#x2F; conv_1d_position_tail_copy (dimension_c * window * dimension_pos): 一维卷积的权重矩阵 (尾实体的位置嵌入) 副本, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
&#x2F;&#x2F; conv_1d_bias_copy (dimension_c): 一维卷积的偏置向量副本, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
REAL *conv_1d_word_copy, *conv_1d_position_head_copy, *conv_1d_position_tail_copy, *conv_1d_bias_copy;

&#x2F;&#x2F; attention_weights_copy (relation_total * dimension_c * dimension_c): 注意力权重矩阵副本, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
std::vector&lt;std::vector&lt;std::vector&lt;REAL&gt; &gt; &gt; attention_weights_copy;

&#x2F;&#x2F; relation_matrix_copy (relation_total * dimension_c): the copy of the representation matrix of relation, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
&#x2F;&#x2F; relation_matrix_bias_copy (relation_total): the copy of the bias vector of the representation matrix of relation, 由于使用多线程训练模型, 该副本用于每一训练批次计算损失值
REAL *relation_matrix_copy, *relation_matrix_bias_copy;

&#x2F;&#x2F; 初始化函数, 即读取训练数据和测试数据
void init() &#123;
	
	printf(&quot;\n##################################################\n\nInit start...\n\n&quot;);

	INT tmp;

	&#x2F;&#x2F; 读取预训练词嵌入
	FILE *f &#x3D; fopen((data_path + &quot;vec.bin&quot;).c_str(), &quot;rb&quot;);
	tmp &#x3D; fscanf(f, &quot;%d&quot;, &amp;word_total);
	tmp &#x3D; fscanf(f, &quot;%d&quot;, &amp;dimension);
	word_vec &#x3D; (REAL *)malloc((word_total + 1) * dimension * sizeof(REAL));
	word2id[&quot;UNK&quot;] &#x3D; 0;
	for (INT i &#x3D; 1; i &lt;&#x3D; word_total; i++) &#123;
		std::string name &#x3D; &quot;&quot;;
		while (1) &#123;
			char ch &#x3D; fgetc(f);
			if (feof(f) || ch &#x3D;&#x3D; &#39; &#39;) break;
			if (ch !&#x3D; &#39;\n&#39;) name &#x3D; name + ch;
		&#125;
		word2id[name] &#x3D; i;

		long long last &#x3D; i * dimension;
		REAL sum &#x3D; 0;
		for (INT a &#x3D; 0; a &lt; dimension; a++) &#123;
			tmp &#x3D; fread(&amp;word_vec[last + a], sizeof(REAL), 1, f);
			sum +&#x3D; word_vec[last + a] * word_vec[last + a];
		&#125;
		sum &#x3D; sqrt(sum);
		for (INT a &#x3D; 0; a &lt; dimension; a++)
			word_vec[last + a] &#x3D; word_vec[last + a] &#x2F; sum;
	&#125;
	word_total +&#x3D; 1;
	fclose(f);

	&#x2F;&#x2F; 读取 relation.txt 文件
	char buffer[1000];
	f &#x3D; fopen((data_path + &quot;relation.txt&quot;).c_str(), &quot;r&quot;);
	while (fscanf(f, &quot;%s&quot;, buffer) &#x3D;&#x3D; 1) &#123;
		relation2id[(std::string)(buffer)] &#x3D; relation_total++;
		id2relation.push_back((std::string)(buffer));
	&#125;
	fclose(f);
	
	&#x2F;&#x2F; 读取训练文件 (train.txt)
	position_min_head &#x3D; 0;
	position_max_head &#x3D; 0;
	position_min_tail &#x3D; 0;
	position_max_tail &#x3D; 0;
	f &#x3D; fopen((data_path + &quot;train.txt&quot;).c_str(), &quot;r&quot;);
	while (fscanf(f, &quot;%s&quot;, buffer) &#x3D;&#x3D; 1)  &#123;
		std::string e1 &#x3D; buffer;
		tmp &#x3D; fscanf(f, &quot;%s&quot;, buffer);
		std::string e2 &#x3D; buffer;

		tmp &#x3D; fscanf(f, &quot;%s&quot;, buffer);
		std::string head_s &#x3D; (std::string)(buffer);
		tmp &#x3D; fscanf(f, &quot;%s&quot;, buffer);
		std::string tail_s &#x3D; (std::string)(buffer);
			
		tmp &#x3D; fscanf(f, &quot;%s&quot;, buffer);
		bags_train[e1 + &quot;\t&quot; + e2 + &quot;\t&quot; + (std::string)(buffer)].push_back(train_relation_list.size());
		INT relation_id &#x3D; relation2id[(std::string)(buffer)];

		INT len_s &#x3D; 0, head_pos &#x3D; 0, tail_pos &#x3D; 0;
		std::vector&lt;INT&gt; sentence;
		while (fscanf(f, &quot;%s&quot;, buffer) &#x3D;&#x3D; 1) &#123;
			std::string word &#x3D; buffer;
			if (word &#x3D;&#x3D; &quot;###END###&quot;) break;
			INT word_id &#x3D; word2id[word];
			if (word &#x3D;&#x3D; head_s) head_pos &#x3D; len_s;
			if (word &#x3D;&#x3D; tail_s) tail_pos &#x3D; len_s;
			len_s++;
			sentence.push_back(word_id);
		&#125;

		train_relation_list.push_back(relation_id);
		train_length.push_back(len_s);
		
		INT *sentence_ptr &#x3D; (INT *)calloc(len_s, sizeof(INT));
		INT *sentence_head_pos &#x3D; (INT *)calloc(len_s, sizeof(INT));
		INT *sentence_tail_pos &#x3D; (INT *)calloc(len_s, sizeof(INT));
		for (INT i &#x3D; 0; i &lt; len_s; i++) &#123;
			sentence_ptr[i] &#x3D; sentence[i];
			sentence_head_pos[i] &#x3D; head_pos - i;
			sentence_tail_pos[i] &#x3D; tail_pos - i;
			if (sentence_head_pos[i] &gt;&#x3D; limit) sentence_head_pos[i] &#x3D; limit;
			if (sentence_tail_pos[i] &gt;&#x3D; limit) sentence_tail_pos[i] &#x3D; limit;
			if (sentence_head_pos[i] &lt;&#x3D; -limit) sentence_head_pos[i] &#x3D; -limit;
			if (sentence_tail_pos[i] &lt;&#x3D; -limit) sentence_tail_pos[i] &#x3D; -limit;
			if (sentence_head_pos[i] &gt; position_max_head) position_max_head &#x3D; sentence_head_pos[i];
			if (sentence_tail_pos[i] &gt; position_max_tail) position_max_tail &#x3D; sentence_tail_pos[i];
			if (sentence_head_pos[i] &lt; position_min_head) position_min_head &#x3D; sentence_head_pos[i];
			if (sentence_tail_pos[i] &lt; position_min_tail) position_min_tail &#x3D; sentence_tail_pos[i];
		&#125;

		train_sentence_list.push_back(sentence_ptr);
		train_position_head.push_back(sentence_head_pos);
		train_position_tail.push_back(sentence_tail_pos);
	&#125;
	fclose(f);

	&#x2F;&#x2F; 读取测试文件 (test.txt)
	f &#x3D; fopen((data_path + &quot;test.txt&quot;).c_str(), &quot;r&quot;);
	while (fscanf(f, &quot;%s&quot;, buffer)&#x3D;&#x3D;1)  &#123;
		std::string e1 &#x3D; buffer;
		tmp &#x3D; fscanf(f, &quot;%s&quot;, buffer);
		std::string e2 &#x3D; buffer;

		tmp &#x3D; fscanf(f, &quot;%s&quot;, buffer);
		std::string head_s &#x3D; (std::string)(buffer);
		tmp &#x3D; fscanf(f, &quot;%s&quot;, buffer);
		std::string tail_s &#x3D; (std::string)(buffer);

		tmp &#x3D; fscanf(f, &quot;%s&quot;, buffer);
		bags_test[e1 + &quot;\t&quot; + e2].push_back(test_relation_list.size());	
		INT relation_id &#x3D; relation2id[(std::string)(buffer)];

		INT len_s &#x3D; 0 , head_pos &#x3D; 0, tail_pos &#x3D; 0;
		std::vector&lt;INT&gt; sentence;
		while (fscanf(f, &quot;%s&quot;, buffer) &#x3D;&#x3D; 1) &#123;
			std::string word &#x3D; buffer;
			if (word&#x3D;&#x3D;&quot;###END###&quot;) break;
			INT word_id &#x3D; word2id[word];
			if (head_s &#x3D;&#x3D; word) head_pos &#x3D; len_s;
			if (tail_s &#x3D;&#x3D; word) tail_pos &#x3D; len_s;
			len_s++;
			sentence.push_back(word_id);
		&#125;

		test_relation_list.push_back(relation_id);
		test_length.push_back(len_s);

		INT *sentence_ptr&#x3D;(INT *)calloc(len_s, sizeof(INT));
		INT *sentence_head_pos&#x3D;(INT *)calloc(len_s, sizeof(INT));
		INT *sentence_tail_pos&#x3D;(INT *)calloc(len_s, sizeof(INT));
		for (INT i &#x3D; 0; i &lt; len_s; i++) &#123;
			sentence_ptr[i] &#x3D; sentence[i];
			sentence_head_pos[i] &#x3D; head_pos - i;
			sentence_tail_pos[i] &#x3D; tail_pos - i;
			if (sentence_head_pos[i] &gt;&#x3D; limit) sentence_head_pos[i] &#x3D; limit;
			if (sentence_tail_pos[i] &gt;&#x3D; limit) sentence_tail_pos[i] &#x3D; limit;
			if (sentence_head_pos[i] &lt;&#x3D; -limit) sentence_head_pos[i] &#x3D; -limit;
			if (sentence_tail_pos[i] &lt;&#x3D; -limit) sentence_tail_pos[i] &#x3D; -limit;
			if (sentence_head_pos[i] &gt; position_max_head) position_max_head &#x3D; sentence_head_pos[i];
			if (sentence_tail_pos[i] &gt; position_max_tail) position_max_tail &#x3D; sentence_tail_pos[i];
			if (sentence_head_pos[i] &lt; position_min_head) position_min_head &#x3D; sentence_head_pos[i];
			if (sentence_tail_pos[i] &lt; position_min_tail) position_min_tail &#x3D; sentence_tail_pos[i];
		&#125;

		test_sentence_list.push_back(sentence_ptr);
		test_position_head.push_back(sentence_head_pos);
		test_position_tail.push_back(sentence_tail_pos);
	&#125;
	fclose(f);

	&#x2F;&#x2F; 将 train_position_head, train_position_tail, test_position_head, test_position_tail 的元素值转换到 [0, 2 * limit] 范围内
	for (INT i &#x3D; 0; i &lt; train_position_head.size(); i++) &#123;
		INT len_s &#x3D; train_length[i];
		INT *position &#x3D; train_position_head[i];
		for (INT j &#x3D; 0; j &lt; len_s; j++)
			position[j] &#x3D; position[j] - position_min_head;
		position &#x3D; train_position_tail[i];
		for (INT j &#x3D; 0; j &lt; len_s; j++)
			position[j] &#x3D; position[j] - position_min_tail;
	&#125;

	for (INT i &#x3D; 0; i &lt; test_position_head.size(); i++) &#123;
		INT len_s &#x3D; test_length[i];
		INT *position &#x3D; test_position_head[i];
		for (INT j &#x3D; 0; j &lt; len_s; j++)
			position[j] &#x3D; position[j] - position_min_head;
		position &#x3D; test_position_tail[i];
		for (INT j &#x3D; 0; j &lt; len_s; j++)
			position[j] &#x3D; position[j] - position_min_tail;
	&#125;

	position_total_head &#x3D; position_max_head - position_min_head + 1;
	position_total_tail &#x3D; position_max_tail - position_min_tail + 1;

	printf(&quot;训练数据和测试数据加载成功!\n\n&quot;);
&#125;

&#x2F;&#x2F; 打印一些重要的信息
void print_information() &#123;
	std::string save_model[] &#x3D; &#123;&quot;不会保存模型.&quot;, &quot;将会保存模型.&quot;&#125;;

	printf(&quot;batch: %d\nnumber of threads: %d\nlearning rate: %.8f\n&quot;, batch, num_threads, alpha);
	printf(&quot;init_rate: %.2f\nreduce_epoch: %.2f\nepochs: %d\n\n&quot;, current_rate, reduce_epoch, epochs);
	printf(&quot;word_total: %d\nword dimension: %d\n\n&quot;, word_total, dimension);
	printf(&quot;limit: %d\nposition_total_head: %d\nposition_total_tail: %d\ndimension_pos: %d\n\n&quot;,
		limit, position_total_head, position_total_tail, dimension_pos);
	printf(&quot;window: %d\ndimension_c: %d\n\n&quot;, window, dimension_c);
	printf(&quot;relation_total: %d\ndropout_probability: %.2f\n\n&quot;, relation_total, dropout_probability);
	printf(&quot;%s\nnote: %s\n\n&quot;, save_model[output_model].c_str(), note.c_str());
	printf(&quot;folder of data: %s\n&quot;, data_path.c_str());
	printf(&quot;folder of outputing results (precion&#x2F;recall curves) and models: %s\n\n&quot;, output_path.c_str());

	printf(&quot;number of training samples: %7d - average sentence number of per training sample: %.2f\n&quot;,
		INT(bags_train.size()), float(float(train_sentence_list.size()) &#x2F; bags_train.size()));
	printf(&quot;number of testing samples:  %7d - average sentence number of per testing sample:  %.2f\n\n&quot;,
		INT(bags_test.size()), float(float(test_sentence_list.size()) &#x2F; bags_test.size()));
	
	printf(&quot;Init end.\n\n&quot;);
&#125;

&#x2F;&#x2F; 寻找特定参数的位置
INT arg_pos(char *str, INT argc, char **argv) &#123;
	INT a;
	for (a &#x3D; 1; a &lt; argc; a++) if (!strcmp(str, argv[a])) &#123;
		if (a &#x3D;&#x3D; argc - 1) &#123;
			printf(&quot;Argument missing for %s\n&quot;, str);
			exit(1);
		&#125;
		return a;
	&#125;
	return -1;
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 数学函数
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; 计算双曲正切函数（tanh）
REAL calc_tanh(REAL value) &#123;
	if (value &gt; 20) return 1.0;
	if (value &lt; -20) return -1.0;
	REAL sinhx &#x3D; exp(value) - exp(-value);
	REAL coshx &#x3D; exp(value) + exp(-value);
	return sinhx &#x2F; coshx;
&#125;

&#x2F;&#x2F; 返回取值为 [min, max) 的伪随机整数
INT get_rand_i(INT min, INT max) &#123;
	INT d &#x3D; max - min;
	INT res &#x3D; rand() % d;
	if (res &lt; 0)
		res +&#x3D; d;
	return res + min;
&#125;

&#x2F;&#x2F; 返回取值为 [min, max) 的伪随机浮点数 
REAL get_rand_u(REAL min, REAL max) &#123;
	return min + (max - min) * rand() &#x2F; (RAND_MAX + 1.0);
&#125;

#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="test-h"><a href="#test-h" class="headerlink" title="test.h"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/test.h">test.h</a></h4><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; test.h
&#x2F;&#x2F;
&#x2F;&#x2F; created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com&gt;
&#x2F;&#x2F;
&#x2F;&#x2F; 该 C++ 文件用于模型测试
&#x2F;&#x2F;
&#x2F;&#x2F; 输出 precion&#x2F;recall curves
&#x2F;&#x2F; output:
&#x2F;&#x2F;     .&#x2F;output&#x2F;pr + note + .txt
&#x2F;&#x2F;
&#x2F;&#x2F; 输出模型 (可选)
&#x2F;&#x2F; output:
&#x2F;&#x2F;     .&#x2F;output&#x2F;word2vec + note + .txt
&#x2F;&#x2F;     .&#x2F;output&#x2F;position_vec + note + .txt
&#x2F;&#x2F;     .&#x2F;output&#x2F;conv_1d + note + .txt
&#x2F;&#x2F;     .&#x2F;output&#x2F;attention_weights + note + .txt
&#x2F;&#x2F;     .&#x2F;output&#x2F;relation_matrix + note + .txt

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 包含标准库和头文件
&#x2F;&#x2F; ##################################################

#ifndef TEST_H
#define TEST_H
#include &quot;init.h&quot;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 声明和定义变量
&#x2F;&#x2F; ##################################################

&#x2F;&#x2F; predict_relation_vector: 每一个元素的 key -&gt; (头实体 + &quot;\t&quot; + 尾实体 + &quot;\t&quot; + 预测关系名)
&#x2F;&#x2F; value 的 key -&gt; (0 或 1, 0 表示关系预测错误, 1 表示关系预测正确)
&#x2F;&#x2F; value 的 value -&gt; 模型给出的该关系成立的概率
&#x2F;&#x2F; 以模型给出的关系成立的概率降序排列
std::vector&lt;std::pair&lt;std::string, std::pair&lt;INT,double&gt; &gt; &gt; predict_relation_vector;

&#x2F;&#x2F; num_test_non_NA: 计算测试集中样本数 (其中 relation 非 NA,每个样本包含 n 个句子, 每个句子包含相同的 head, relation (label), tail)
&#x2F;&#x2F; bags_test_key: 保存 bags_test 的 key (头实体 + &quot;\t&quot; + 尾实体), 按照 bags_test 的迭代顺序
&#x2F;&#x2F; thread_first_bags_test (num_threads + 1): 保存每个线程第一个样本在 bags_test_key 中的位置
&#x2F;&#x2F; test_mutex: 互斥锁, 线程同步 predict_relation_vector 变量
INT num_test_non_NA;
std::vector&lt;std::string&gt; bags_test_key;
std::vector&lt;INT&gt; thread_first_bags_test;
pthread_mutex_t test_mutex;

struct timeval test_start, test_end;

&#x2F;&#x2F; 为 std::sort() 定义比较函数
&#x2F;&#x2F; 以模型给出的关系成立的概率降序排列, 用于 predict_relation_vector 变量
bool cmp_predict_probability(std::pair&lt;std::string, std::pair&lt;INT,double&gt; &gt; a,
	std::pair&lt;std::string, std::pair&lt;INT,double&gt; &gt;b)
&#123;
    return a.second.second &gt; b.second.second;
&#125;

&#x2F;&#x2F; 计算句子的一维卷积
std::vector&lt;REAL&gt; calc_conv_1d(INT *sentence, INT *test_position_head,
	INT *test_position_tail, INT sentence_length) &#123;
	
	std::vector&lt;REAL&gt; conv_1d_result_k;
	conv_1d_result_k.resize(dimension_c, 0);
	
	for (INT i &#x3D; 0; i &lt; dimension_c; i++) &#123;
		INT last_word &#x3D; i * window * dimension;
		INT last_pos &#x3D; i * window * dimension_pos;
		REAL max_pool_1d &#x3D; -FLT_MAX;
		for (INT last_window &#x3D; 0; last_window &lt;&#x3D; sentence_length - window; last_window++) &#123;
			REAL sum &#x3D; 0;
			INT total_word &#x3D; 0;
			INT total_pos &#x3D; 0;
			for (INT j &#x3D; last_window; j &lt; last_window + window; j++)  &#123;
				INT last_word_vec &#x3D; sentence[j] * dimension;
			 	for (INT k &#x3D; 0; k &lt; dimension; k++) &#123;
			 		sum +&#x3D; conv_1d_word[last_word + total_word] * word_vec[last_word_vec + k];
			 		total_word++;
			 	&#125;
			 	INT last_pos_head &#x3D; test_position_head[j] * dimension_pos;
			 	INT last_pos_tail &#x3D; test_position_tail[j] * dimension_pos;
			 	for (INT k &#x3D; 0; k &lt; dimension_pos; k++) &#123;
			 		sum +&#x3D; conv_1d_position_head[last_pos + total_pos] * position_vec_head[last_pos_head + k];
			 		sum +&#x3D; conv_1d_position_tail[last_pos + total_pos] * position_vec_tail[last_pos_tail + k];
			 		total_pos++;
			 	&#125;
			&#125;

			&#x2F;&#x2F; 对应于论文中的公式 (3), [x]_i &#x3D; max(p_i), 其中 x \in R^&#123;d^c&#125;
			if (sum &gt; max_pool_1d) max_pool_1d &#x3D; sum;
		&#125;
		conv_1d_result_k[i] &#x3D; max_pool_1d + conv_1d_bias[i];
	&#125;

	for (INT i &#x3D; 0; i &lt; dimension_c; i++)
		conv_1d_result_k[i] &#x3D; calc_tanh(conv_1d_result_k[i]);
	return conv_1d_result_k;
&#125;

&#x2F;&#x2F; 单个线程内运行的任务
void* test_mode(void *thread_id) 
&#123;
	INT id;
	id &#x3D; (unsigned long long)(thread_id);
	INT left &#x3D; thread_first_bags_test[id];
	INT right;
	if (id &#x3D;&#x3D; num_threads-1)
		right &#x3D; bags_test_key.size();
	else
		right &#x3D; thread_first_bags_test[id + 1];

	&#x2F;&#x2F; 保存样本的正确标签 (关系)
	std::map&lt;INT,INT&gt; sample_relation_list;

	for (INT i_sample &#x3D; left; i_sample &lt; right; i_sample++)
	&#123;
		&#x2F;&#x2F; 一维卷积部分
		sample_relation_list.clear();
		std::vector&lt;std::vector&lt;REAL&gt; &gt; conv_1d_result;
		INT bags_size &#x3D; bags_test[bags_test_key[i_sample]].size();
		for (INT k &#x3D; 0; k &lt; bags_size; k++)
		&#123;
			INT i &#x3D; bags_test[bags_test_key[i_sample]][k];
			sample_relation_list[test_relation_list[i]] &#x3D; 1;

			conv_1d_result.push_back(calc_conv_1d(test_sentence_list[i],
				test_position_head[i], test_position_tail[i], test_length[i]));
		&#125;

		&#x2F;&#x2F; 对应于论文中的公式 (8), e_i &#x3D; x_iAr, 其中 r is the query vector associated with relation r which
		&#x2F;&#x2F; indicates the representation of relation r, 也就是 predict 时, 需要用每一个关系依次查询.
		std::vector&lt;float&gt; result_final;
		result_final.resize(relation_total, 0.0);
		for (INT index_r &#x3D; 0; index_r &lt; relation_total; index_r++) &#123;
			
			&#x2F;&#x2F; 获取每一个句子的权重
			std::vector&lt;REAL&gt; weight;
			REAL weight_sum &#x3D; 0;
			for (INT k &#x3D; 0; k &lt; bags_size; k++)
			&#123;
				REAL s &#x3D; 0;
				for (INT i_r &#x3D; 0; i_r &lt; dimension_c; i_r++) 
				&#123;
					REAL temp &#x3D; 0;
					for (INT i_x &#x3D; 0; i_x &lt; dimension_c; i_x++)
						temp +&#x3D; conv_1d_result[k][i_x] * attention_weights[index_r][i_x][i_r];
					s +&#x3D; temp * relation_matrix[index_r * dimension_c + i_r];
				&#125;
				s &#x3D; exp(s);
				weight.push_back(s);
				weight_sum +&#x3D; s;
			&#125;

			for (INT k &#x3D; 0; k &lt; bags_size; k++)
				weight[k] &#x2F;&#x3D; weight_sum;
			
			&#x2F;&#x2F; 获取 s, i.e., s indicates the representation of the sentence set
			std::vector&lt;REAL&gt; result_sentence;
			result_sentence.resize(dimension_c);
			for (INT i &#x3D; 0; i &lt; dimension_c; i++) 
				for (INT k &#x3D; 0; k &lt; bags_size; k++)
					result_sentence[i] +&#x3D; conv_1d_result[k][i] * weight[k];

			&#x2F;&#x2F; 获取关系 (id 为 index_r) 成立的概率
			std::vector&lt;REAL&gt; result_final_r;
			double temp &#x3D; 0;
			for (INT i_r &#x3D; 0; i_r &lt; relation_total; i_r++) &#123;
				REAL s &#x3D; 0;
				for (INT i_s &#x3D; 0; i_s &lt; dimension_c; i_s++)
					s +&#x3D;  dropout_probability * result_sentence[i_s] *
						relation_matrix[i_r * dimension_c + i_s];
				s +&#x3D; relation_matrix_bias[i_r];
				s &#x3D; exp(s);
				temp +&#x3D; s;
				result_final_r.push_back(s);
			&#125;
			result_final[index_r] &#x3D; result_final_r[index_r]&#x2F;temp;
		&#125;

		&#x2F;&#x2F; 保存该测试样本各个关系 (非 NA) 成立的概率, 使用线程同步
		pthread_mutex_lock (&amp;test_mutex);
		for (INT i_r &#x3D; 1; i_r &lt; relation_total; i_r++) 
		&#123;
			predict_relation_vector.push_back(std::make_pair(bags_test_key[i_sample] + &quot;\t&quot; + id2relation[i_r],
				std::make_pair(sample_relation_list.count(i_r), result_final[i_r])));
		&#125;
		pthread_mutex_unlock(&amp;test_mutex);
	&#125;
&#125;

&#x2F;&#x2F; 测试函数
void test() &#123;

	printf(&quot;##################################################\n\nTest start...\n\n&quot;);

	gettimeofday(&amp;test_start, NULL);

	num_test_non_NA &#x3D; 0;
	bags_test_key.clear();
	thread_first_bags_test.clear();
	predict_relation_vector.clear();

	std::vector&lt;INT&gt; sample_sum;
	sample_sum.clear();
	for (std::map&lt;std::string, std::vector&lt;INT&gt; &gt;::iterator it &#x3D; bags_test.begin();
		it !&#x3D; bags_test.end(); it++)
	&#123;
		std::map&lt;INT, INT&gt; sample_relation_list;
		sample_relation_list.clear();
		for (INT i &#x3D; 0; i &lt; it-&gt;second.size(); i++)
		&#123;
			INT pos &#x3D; it-&gt;second[i];
			if (test_relation_list[pos] &gt; 0)
				sample_relation_list[test_relation_list[pos]] &#x3D; 1;
		&#125;
		num_test_non_NA +&#x3D; sample_relation_list.size();
		bags_test_key.push_back(it-&gt;first);
		sample_sum.push_back(it-&gt;second.size());
	&#125;

	for (INT i &#x3D; 1; i &lt; sample_sum.size(); i++)
		sample_sum[i] +&#x3D; sample_sum[i - 1];
	
	INT thread_id &#x3D; 0;
	thread_first_bags_test.resize(num_threads + 1);
	for (INT i &#x3D; 0; i &lt; sample_sum.size(); i++)
		if (sample_sum[i] &gt;&#x3D; (sample_sum[sample_sum.size()-1] &#x2F; num_threads) * thread_id)
		&#123;
			thread_first_bags_test[thread_id] &#x3D; i;
			thread_id +&#x3D; 1;
		&#125;
	printf(&quot;Number of test samples for non NA relation: %d\n\n&quot;, num_test_non_NA);

	&#x2F;&#x2F; 多线程模型测试
	pthread_t *pt &#x3D; (pthread_t *)malloc(num_threads * sizeof(pthread_t));
	for (long a &#x3D; 0; a &lt; num_threads; a++)
		pthread_create(&amp;pt[a], NULL, test_mode,  (void *)a);
	for (long a &#x3D; 0; a &lt; num_threads; a++)
		pthread_join(pt[a], NULL);
	free(pt);

	&#x2F;&#x2F; 以模型给出的关系成立的概率降序排列
	std::sort(predict_relation_vector.begin(),predict_relation_vector.end(), cmp_predict_probability);

	&#x2F;&#x2F; 输出 precion&#x2F;recall curves
	REAL correct &#x3D; 0;
	FILE* f &#x3D; fopen((output_path + &quot;pr&quot; + note + &quot;.txt&quot;).c_str(), &quot;w&quot;);
	INT top_2000 &#x3D; std::min(2000, INT(predict_relation_vector.size()));
	for (INT i &#x3D; 0; i &lt; top_2000; i++)
	&#123;
		if (predict_relation_vector[i].second.first !&#x3D; 0)
			correct++;	
		REAL precision &#x3D; correct &#x2F; (i + 1);
		REAL recall &#x3D; correct &#x2F; num_test_non_NA;
		if ((i+1) % 50 &#x3D;&#x3D; 0)
			printf(&quot;precion&#x2F;recall curves %4d &#x2F; %4d - precision: %.3lf - recall: %.3lf\n&quot;, (i + 1), top_2000, precision, recall);
		fprintf(f, &quot;precision: %.3lf  recall: %.3lf  correct: %d  predict_probability: %.2lf  predict_triplet: %s\n&quot;,
			precision, recall, predict_relation_vector[i].second.first, predict_relation_vector[i].second.second,
			predict_relation_vector[i].first.c_str());	
	&#125;
	fclose(f);

	gettimeofday(&amp;test_end, NULL);
	long double time_use &#x3D; (1000000 * (test_end.tv_sec - test_start.tv_sec)
		+ test_end.tv_usec - test_start.tv_usec) &#x2F; 1000000.0;
	printf(&quot;\ntest use time - %02d:%02d:%02d\n\n&quot;, INT(time_use &#x2F; 3600.0),
		INT(time_use) % 3600 &#x2F; 60, INT(time_use) % 60);

	if (!output_model)return;

	&#x2F;&#x2F; 输出词嵌入
	FILE *fout &#x3D; fopen((output_path + &quot;word2vec&quot; + note + &quot;.txt&quot;).c_str(), &quot;w&quot;);
	fprintf(fout, &quot;%d\t%d\n&quot;, word_total, dimension);
	for (INT i &#x3D; 0; i &lt; word_total; i++)
	&#123;
		for (INT j &#x3D; 0; j &lt; dimension; j++)
			fprintf(fout, &quot;%f\t&quot;, word_vec[i * dimension + j]);
		fprintf(fout, &quot;\n&quot;);
	&#125;
	fclose(fout);

	&#x2F;&#x2F; 输出位置嵌入
	fout &#x3D; fopen((output_path + &quot;position_vec&quot; + note + &quot;.txt&quot;).c_str(), &quot;w&quot;);
	fprintf(fout, &quot;%d\t%d\t%d\n&quot;, position_total_head, position_total_tail, dimension_pos);
	for (INT i &#x3D; 0; i &lt; position_total_head; i++) &#123;
		for (INT j &#x3D; 0; j &lt; dimension_pos; j++)
			fprintf(fout, &quot;%f\t&quot;, position_vec_head[i * dimension_pos + j]);
		fprintf(fout, &quot;\n&quot;);
	&#125;
	for (INT i &#x3D; 0; i &lt; position_total_tail; i++) &#123;
		for (INT j &#x3D; 0; j &lt; dimension_pos; j++)
			fprintf(fout, &quot;%f\t&quot;, position_vec_tail[i * dimension_pos + j]);
		fprintf(fout, &quot;\n&quot;);
	&#125;
	fclose(fout);

	&#x2F;&#x2F; 输出一维卷积权重矩阵和对应的偏置向量
	fout &#x3D; fopen((output_path + &quot;conv_1d&quot; + note + &quot;.txt&quot;).c_str(), &quot;w&quot;);
	fprintf(fout,&quot;%d\t%d\t%d\t%d\n&quot;, dimension_c, window, dimension, dimension_pos);
	for (INT i &#x3D; 0; i &lt; dimension_c; i++) &#123;
		for (INT j &#x3D; 0; j &lt; window * dimension; j++)
			fprintf(fout, &quot;%f\t&quot;, conv_1d_word[i * window * dimension + j]);
		for (INT j &#x3D; 0; j &lt; window * dimension_pos; j++)
			fprintf(fout, &quot;%f\t&quot;, conv_1d_position_head[i * window * dimension_pos + j]);
		for (INT j &#x3D; 0; j &lt; window * dimension_pos; j++)
			fprintf(fout, &quot;%f\t&quot;, conv_1d_position_tail[i * window * dimension_pos + j]);
		fprintf(fout, &quot;%f\n&quot;, conv_1d_bias[i]);
	&#125;
	fclose(fout);

	&#x2F;&#x2F; 输出注意力权重矩阵
	fout &#x3D; fopen((output_path + &quot;attention_weights&quot; + note + &quot;.txt&quot;).c_str(), &quot;w&quot;);
	fprintf(fout,&quot;%d\t%d\n&quot;, relation_total, dimension_c);
	for (INT r &#x3D; 0; r &lt; relation_total; r++) &#123;
		for (INT i_x &#x3D; 0; i_x &lt; dimension_c; i_x++)
		&#123;
			for (INT i_r &#x3D; 0; i_r &lt; dimension_c; i_r++)
				fprintf(fout, &quot;%f\t&quot;, attention_weights[r][i_x][i_r]);
			fprintf(fout, &quot;\n&quot;);
		&#125;
	&#125;
	fclose(fout);

	&#x2F;&#x2F; 输出 relation_matrix 和对应的偏置向量
	fout &#x3D; fopen((output_path + &quot;relation_matrix&quot; + note + &quot;.txt&quot;).c_str(), &quot;w&quot;);
	fprintf(fout, &quot;%d\t%d\t%f\n&quot;, relation_total, dimension_c, dropout_probability);
	for (INT i_r &#x3D; 0; i_r &lt; relation_total; i_r++) &#123;
		for (INT i_s &#x3D; 0; i_s &lt; dimension_c; i_s++)
			fprintf(fout, &quot;%f\t&quot;, relation_matrix[i_r * dimension_c + i_s]);
		fprintf(fout, &quot;\n&quot;);
	&#125;
	for (INT i_r &#x3D; 0; i_r &lt; relation_total; i_r++) 
		fprintf(fout, &quot;%f\t&quot;, relation_matrix_bias[i_r]);
	fprintf(fout, &quot;\n&quot;);
	fclose(fout);

	printf(&quot;模型保存成功, 保存目录为: %s\n\n&quot;, output_path.c_str());
&#125;

#endif<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="train-cpp"><a href="#train-cpp" class="headerlink" title="train.cpp"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/train.cpp">train.cpp</a></h4><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; train.cpp
&#x2F;&#x2F;
&#x2F;&#x2F; 使用方法:
&#x2F;&#x2F;     编译:
&#x2F;&#x2F;           $ g++ train.cpp -o .&#x2F;build&#x2F;train -pthread -O3 -march&#x3D;native
&#x2F;&#x2F;     运行:
&#x2F;&#x2F;           $ .&#x2F;build&#x2F;train
&#x2F;&#x2F;
&#x2F;&#x2F; created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com&gt;
&#x2F;&#x2F;
&#x2F;&#x2F; 该 C++ 文件用于模型训练

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 包含标准库和头文件
&#x2F;&#x2F; ##################################################

#include &quot;init.h&quot;
#include &quot;test.h&quot;

&#x2F;&#x2F; bags_test_key: 保存 bags_train 的 key (头实体 + &quot;\t&quot; + 尾实体 + &quot;\t&quot; + 关系名), 按照 bags_train 的迭代顺序
&#x2F;&#x2F; total_loss: 每一轮次的总损失
&#x2F;&#x2F; current_alpha: 当前轮次的学习率
&#x2F;&#x2F; current_sample, final_sample: 由于使用多线程训练模型, 这两个变量用于确定当前训练批次是否完成, 进而更新各种权重矩阵的副本, 如 word_vec_copy
&#x2F;&#x2F; train_mutex: 互斥锁, 线程同步 current_sample 变量
&#x2F;&#x2F; len &#x3D; bags_train.size()
&#x2F;&#x2F; nbatches  &#x3D;  len &#x2F; (batch * num_threads)
std::vector&lt;std::string&gt; bags_train_key;
double total_loss &#x3D; 0;
REAL current_alpha;
double current_sample &#x3D; 0, final_sample &#x3D; 0;
pthread_mutex_t train_mutex;
INT len;
INT nbatches;

struct timeval train_start, train_end;

&#x2F;&#x2F; 计算句子的一维卷积
std::vector&lt;REAL&gt; calc_conv_1d(INT *sentence, INT *train_position_head,
	INT *train_position_tail, INT sentence_length, std::vector&lt;INT&gt; &amp;max_pool_window_k) &#123;
	
	std::vector&lt;REAL&gt; conv_1d_result_k;
	conv_1d_result_k.resize(dimension_c, 0);

	for (INT i &#x3D; 0; i &lt; dimension_c; i++) &#123;
		INT last_word &#x3D; i * window * dimension;
		INT last_pos &#x3D; i * window * dimension_pos;
		REAL max_pool_1d &#x3D; -FLT_MAX;
		for (INT last_window &#x3D; 0; last_window &lt;&#x3D; sentence_length - window; last_window++) &#123;
			REAL sum &#x3D; 0;
			INT total_word &#x3D; 0;
			INT total_pos &#x3D; 0;
			for (INT j &#x3D; last_window; j &lt; last_window + window; j++)  &#123;
				INT last_word_vec &#x3D; sentence[j] * dimension;
			 	for (INT k &#x3D; 0; k &lt; dimension; k++) &#123;
			 		sum +&#x3D; conv_1d_word_copy[last_word + total_word] * word_vec_copy[last_word_vec + k];
			 		total_word++;
			 	&#125;
			 	INT last_pos_head &#x3D; train_position_head[j] * dimension_pos;
			 	INT last_pos_tail &#x3D; train_position_tail[j] * dimension_pos;
			 	for (INT k &#x3D; 0; k &lt; dimension_pos; k++) &#123;
			 		sum +&#x3D; conv_1d_position_head_copy[last_pos + total_pos] * position_vec_head_copy[last_pos_head + k];
			 		sum +&#x3D; conv_1d_position_tail_copy[last_pos + total_pos] * position_vec_tail_copy[last_pos_tail + k];
			 		total_pos++;
			 	&#125;
			&#125;

			&#x2F;&#x2F; 对应于论文中的公式 (3), [x]_i &#x3D; max(p_i), 其中 x \in R^&#123;d^c&#125;
			if (sum &gt; max_pool_1d) &#123;
				max_pool_1d &#x3D; sum;
				max_pool_window_k[i] &#x3D; last_window;
			&#125;
		&#125;
		conv_1d_result_k[i] &#x3D; max_pool_1d + conv_1d_bias_copy[i];
	&#125;

	for (INT i &#x3D; 0; i &lt; dimension_c; i++) &#123;
		conv_1d_result_k[i] &#x3D; calc_tanh(conv_1d_result_k[i]);
	&#125;
	return conv_1d_result_k;
&#125;

&#x2F;&#x2F; 根据梯度更新一维卷积的权重矩阵, 位置嵌入矩阵, 词嵌入矩阵
void gradient_conv_1d(INT *sentence, INT *train_position_head, INT *train_position_tail,
	std::vector&lt;REAL&gt; &amp;conv_1d_result_k, std::vector&lt;INT&gt; &amp;max_pool_window_k, std::vector&lt;REAL&gt; &amp;grad_x_k)
&#123;
	for (INT i &#x3D; 0; i &lt; dimension_c; i++) &#123;
		if (fabs(grad_x_k[i]) &lt; 1e-8)
			continue;
		INT last_word &#x3D; i * window * dimension;
		INT last_pos &#x3D; i * window * dimension_pos;
		INT total_word &#x3D; 0;
		INT total_pos &#x3D; 0;
		&#x2F;&#x2F; (tanh x)^&#123;&#39;&#125; &#x3D; sech^2x &#x3D; \frac&#123;1&#125;&#123;cosh^2x&#125; &#x3D; 1 - tanh^2x
		REAL grad_word_pos &#x3D; grad_x_k[i] * (1 -  conv_1d_result_k[i] * conv_1d_result_k[i]);
		for (INT j &#x3D; 0; j &lt; window; j++)  &#123;
			INT last_word_vec &#x3D; sentence[max_pool_window_k[i] + j] * dimension;
			for (INT k &#x3D; 0; k &lt; dimension; k++) &#123;
				conv_1d_word[last_word + total_word] -&#x3D; grad_word_pos * word_vec_copy[last_word_vec + k];
				word_vec[last_word_vec + k] -&#x3D; grad_word_pos * conv_1d_word_copy[last_word + total_word];
				total_word++;
			&#125;
			INT last_pos_head &#x3D; train_position_head[max_pool_window_k[i] + j] * dimension_pos;
			INT last_pos_tail &#x3D; train_position_tail[max_pool_window_k[i] + j] * dimension_pos;
			for (INT k &#x3D; 0; k &lt; dimension_pos; k++) &#123;
				conv_1d_position_head[last_pos + total_pos] -&#x3D; grad_word_pos * position_vec_head_copy[last_pos_head + k];
				conv_1d_position_tail[last_pos + total_pos] -&#x3D; grad_word_pos * position_vec_tail_copy[last_pos_tail + k];
				position_vec_head[last_pos_head + k] -&#x3D; grad_word_pos * conv_1d_position_head_copy[last_pos + total_pos];
				position_vec_tail[last_pos_tail + k] -&#x3D; grad_word_pos * conv_1d_position_tail_copy[last_pos + total_pos];
				total_pos++;
			&#125;
		&#125;
		conv_1d_bias[i] -&#x3D; grad_word_pos;
	&#125;
&#125;

&#x2F;&#x2F; 训练一个样本
REAL train_bags(std::string bags_name)
&#123;
	&#x2F;&#x2F; ##################################################
	&#x2F;&#x2F; 正向传播
	&#x2F;&#x2F; ##################################################

	&#x2F;&#x2F; 一维卷积部分
	&#x2F;&#x2F; relation: 该训练样本的正确标签 (关系)
	INT relation &#x3D; -1;
	INT bags_size &#x3D; bags_train[bags_name].size();
	std::vector&lt;std::vector&lt;INT&gt; &gt; max_pool_window;
	max_pool_window.resize(bags_size);
	std::vector&lt;std::vector&lt;REAL&gt; &gt; conv_1d_result;
	
	for (INT k &#x3D; 0; k &lt; bags_size; k++)
	&#123;
		max_pool_window[k].resize(dimension_c);
		INT pos &#x3D; bags_train[bags_name][k];
		if (relation &#x3D;&#x3D; -1)
			relation &#x3D; train_relation_list[pos];
		else
			assert(relation &#x3D;&#x3D; train_relation_list[pos]);
		conv_1d_result.push_back(calc_conv_1d(train_sentence_list[pos], train_position_head[pos],
			train_position_tail[pos], train_length[pos], max_pool_window[k]));
	&#125;

	&#x2F;&#x2F; 获取每一个句子的权重
	std::vector&lt;REAL&gt; weight;
	REAL weight_sum &#x3D; 0;
	for (INT k &#x3D; 0; k &lt; bags_size; k++)
	&#123;
		REAL s &#x3D; 0;
		for (INT i_r &#x3D; 0; i_r &lt; dimension_c; i_r++) 
		&#123;
			REAL temp &#x3D; 0;
			for (INT i_x &#x3D; 0; i_x &lt; dimension_c; i_x++)
				temp +&#x3D; conv_1d_result[k][i_x] * attention_weights_copy[relation][i_x][i_r];
			s +&#x3D; temp * relation_matrix_copy[relation * dimension_c + i_r];
		&#125;
		s &#x3D; exp(s); 
		weight.push_back(s);
		weight_sum +&#x3D; s;
	&#125;

	for (INT k &#x3D; 0; k &lt; bags_size; k++)
		weight[k] &#x2F;&#x3D; weight_sum;

	&#x2F;&#x2F; 获取 s, i.e., s indicates the representation of the sentence set
	std::vector&lt;REAL&gt; result_sentence;
	result_sentence.resize(dimension_c);
	for (INT i &#x3D; 0; i &lt; dimension_c; i++) 
		for (INT k &#x3D; 0; k &lt; bags_size; k++)
			result_sentence[i] +&#x3D; conv_1d_result[k][i] * weight[k];
	
	&#x2F;&#x2F; 计算各种关系成立的概率
	std::vector&lt;REAL&gt; result_final;
	std::vector&lt;INT&gt; dropout;
	for (INT i_s &#x3D; 0; i_s &lt; dimension_c; i_s++)
		dropout.push_back((REAL)(rand()) &#x2F; (RAND_MAX + 1.0) &lt; dropout_probability);

	REAL sum &#x3D; 0;
	for (INT i_r &#x3D; 0; i_r &lt; relation_total; i_r++) &#123;
		REAL s &#x3D; 0;
		for (INT i_s &#x3D; 0; i_s &lt; dimension_c; i_s++) &#123;
			s +&#x3D; dropout[i_s] * result_sentence[i_s] * relation_matrix_copy[i_r * dimension_c + i_s];
		&#125;
		s +&#x3D; relation_matrix_bias_copy[i_r];
		s &#x3D; exp(s);
		sum +&#x3D; s;
		result_final.push_back(s);
	&#125;

	&#x2F;&#x2F; 计算损失值
	double loss &#x3D; -(log(result_final[relation]) - log(sum));

	&#x2F;&#x2F; ##################################################
	&#x2F;&#x2F; 反向传播
	&#x2F;&#x2F; ##################################################
	
	&#x2F;&#x2F; 更新 relation_matrix, 对应于论文中的公式 (12), o &#x3D; M(s \circ h) + d
	std::vector&lt;REAL&gt; grad_s;
	grad_s.resize(dimension_c);

	for (INT i_r &#x3D; 0; i_r &lt; relation_total; i_r++)
	&#123;
		&#x2F;&#x2F; 由于损失函数是 cross-entropy, 负标签是 0
		&#x2F;&#x2F; 对于负标签 (关系) 的梯度是计算的概率, 即 result_final[i_r] &#x2F; sum
		&#x2F;&#x2F; 这样做, 能省略一层 softmax
		REAL grad_final &#x3D; result_final[i_r] &#x2F; sum * current_alpha;
		
		&#x2F;&#x2F; 正标签是 0, 对于正标签 (关系) 的梯度是计算的概率 - 1, 即 result_final[i_r] &#x2F; sum - 1
		&#x2F;&#x2F; 这样做, 能省略一层 softmax
		if (i_r &#x3D;&#x3D; relation)
			grad_final -&#x3D; current_alpha;

		for (INT i_s &#x3D; 0; i_s &lt; dimension_c; i_s++) 
		&#123;
			REAL grad_i_s &#x3D; 0;
			if (dropout[i_s] !&#x3D; 0)
			&#123;
				grad_i_s +&#x3D; grad_final * relation_matrix_copy[i_r * dimension_c + i_s];
				relation_matrix[i_r * dimension_c + i_s] -&#x3D; grad_final * result_sentence[i_s];
			&#125;
			grad_s[i_s] +&#x3D; grad_i_s;
		&#125;
		relation_matrix_bias[i_r] -&#x3D; grad_final;
	&#125;

	&#x2F;&#x2F; 更新注意力权重矩阵和 relation_matrix, 对应于论文中的公式 (5), (7), (8)
	std::vector&lt;std::vector&lt;REAL&gt; &gt; grad_x;
	grad_x.resize(bags_size);

	for (INT k &#x3D; 0; k &lt; bags_size; k++)
		grad_x[k].resize(dimension_c);

	for (INT i_r &#x3D; 0; i_r &lt; dimension_c; i_r++) 
	&#123;
		REAL grad_i_s &#x3D; grad_s[i_r];
		double a_denominator_sum_exp &#x3D; 0;

		for (INT k &#x3D; 0; k &lt; bags_size; k++)
		&#123;
			&#x2F;&#x2F; grad_i_s * weight[k] 对应于论文中的公式 5
			grad_x[k][i_r] +&#x3D; grad_i_s * weight[k];
			for (INT i_x &#x3D; 0; i_x &lt; dimension_c; i_x++)
			&#123;
				&#x2F;&#x2F; 对应于论文中的公式 7 中分子 (exp(e_i)) 的公式 8 中的 x_i
				grad_x[k][i_x] +&#x3D; grad_i_s * conv_1d_result[k][i_r] * weight[k] *
					relation_matrix_copy[relation * dimension_c + i_r] *
					attention_weights_copy[relation][i_x][i_r];

				&#x2F;&#x2F; 对应于论文中的公式 7 中分子 (exp(e_i)) 的公式 8 中的 r
				relation_matrix[relation * dimension_c + i_r] -&#x3D; grad_i_s *
					conv_1d_result[k][i_r] * weight[k] * conv_1d_result[k][i_x] *
					attention_weights_copy[relation][i_x][i_r];
				
				&#x2F;&#x2F; 对应于论文中的公式 7 中分子 (exp(e_i)) 的公式 8 中的 A
				if (i_r &#x3D;&#x3D; i_x)
					attention_weights[relation][i_x][i_r] -&#x3D; grad_i_s * conv_1d_result[k][i_r] *
						weight[k] * conv_1d_result[k][i_x] *
						relation_matrix_copy[relation * dimension_c + i_r];
			&#125;

			&#x2F;&#x2F; 由于 1&#x2F;x 的导数是 -1&#x2F;x^2, exp(x) 的导数是 exp(x)
			&#x2F;&#x2F; 所以论文中的公式 (7) 中分母 (exp(e_i)) 的公式 8 的求导需要一个和 (exp(x_1), exp(x_2) ,...)
			&#x2F;&#x2F; 并且需要多乘一次 weight[k]
			a_denominator_sum_exp +&#x3D; conv_1d_result[k][i_r] * weight[k];
		&#125;	
		for (INT k &#x3D; 0; k &lt; bags_size; k++)
		&#123;
			for (INT i_x &#x3D; 0; i_x &lt; dimension_c; i_x++)
			&#123;
				&#x2F;&#x2F; 对应于论文中的公式 7 中分母 (exp(e_i)) 的公式 8 中的 x_i
				grad_x[k][i_x]-&#x3D; grad_i_s * a_denominator_sum_exp * weight[k] *
					relation_matrix_copy[relation * dimension_c + i_r] *
					attention_weights_copy[relation][i_x][i_r];
				
				&#x2F;&#x2F; 对应于论文中的公式 7 中分母 (exp(e_i)) 的公式 8 中的 r
				relation_matrix[relation * dimension_c + i_r] +&#x3D; grad_i_s *
					a_denominator_sum_exp * weight[k] * conv_1d_result[k][i_x] *
					attention_weights_copy[relation][i_x][i_r];
				
				&#x2F;&#x2F; 对应于论文中的公式 7 中分母 (exp(e_i)) 的公式 8 中的 A
				if (i_r &#x3D;&#x3D; i_x)
					attention_weights[relation][i_x][i_r] +&#x3D; grad_i_s * a_denominator_sum_exp *
						weight[k] * conv_1d_result[k][i_x] *
						relation_matrix_copy[relation * dimension_c + i_r];
			&#125;
		&#125;
	&#125;

	&#x2F;&#x2F; 根据梯度更新一维卷积的权重矩阵, 位置嵌入矩阵, 词嵌入矩阵
	for (INT k &#x3D; 0; k &lt; bags_size; k++)
	&#123;
		INT pos &#x3D; bags_train[bags_name][k];
		gradient_conv_1d(train_sentence_list[pos], train_position_head[pos], train_position_tail[pos],
			conv_1d_result[k], max_pool_window[k], grad_x[k]);
	&#125;
	return loss;
&#125;

&#x2F;&#x2F; 单个线程内运行的任务
void* train_mode(void *id) &#123;
	while (true)
	&#123;
		pthread_mutex_lock (&amp;train_mutex);
		if (current_sample &gt;&#x3D; final_sample)
		&#123;
			pthread_mutex_unlock (&amp;train_mutex);
			break;
		&#125;
		current_sample +&#x3D; 1;
		pthread_mutex_unlock (&amp;train_mutex);
		INT i &#x3D; get_rand_i(0, len);
		total_loss +&#x3D; train_bags(bags_train_key[i]);
	&#125;
&#125;

&#x2F;&#x2F; 训练函数
void train() &#123;

	len &#x3D; bags_train.size();
	nbatches  &#x3D;  len &#x2F; (batch * num_threads);

	bags_train_key.clear();
	for (std::map&lt;std::string, std::vector&lt;INT&gt; &gt;:: iterator it &#x3D; bags_train.begin();
		it !&#x3D; bags_train.end(); it++)
	&#123;
		bags_train_key.push_back(it-&gt;first);
	&#125;

	&#x2F;&#x2F; 为模型的权重矩阵分配内存空间
	position_vec_head &#x3D; (REAL *)calloc(position_total_head * dimension_pos, sizeof(REAL));
	position_vec_tail &#x3D; (REAL *)calloc(position_total_tail * dimension_pos, sizeof(REAL));
	conv_1d_word &#x3D; (REAL*)calloc(dimension_c * window * dimension, sizeof(REAL));
	conv_1d_position_head &#x3D; (REAL *)calloc(dimension_c * window * dimension_pos, sizeof(REAL));
	conv_1d_position_tail &#x3D; (REAL *)calloc(dimension_c * window * dimension_pos, sizeof(REAL));
	conv_1d_bias &#x3D; (REAL*)calloc(dimension_c, sizeof(REAL));
	attention_weights.resize(relation_total);
	for (INT i &#x3D; 0; i &lt; relation_total; i++)
	&#123;
		attention_weights[i].resize(dimension_c);
		for (INT j &#x3D; 0; j &lt; dimension_c; j++)
		&#123;
			attention_weights[i][j].resize(dimension_c);
			attention_weights[i][j][j] &#x3D; 1.00;
		&#125;
	&#125;
	relation_matrix &#x3D; (REAL *)calloc(relation_total * dimension_c, sizeof(REAL));
	relation_matrix_bias &#x3D; (REAL *)calloc(relation_total, sizeof(REAL));

	&#x2F;&#x2F; 为模型的权重矩阵的副本分配内存空间
	word_vec_copy &#x3D; (REAL *)calloc(dimension * word_total, sizeof(REAL));
	position_vec_head_copy &#x3D; (REAL *)calloc(position_total_head * dimension_pos, sizeof(REAL));
	position_vec_tail_copy &#x3D; (REAL *)calloc(position_total_tail * dimension_pos, sizeof(REAL));
	conv_1d_word_copy &#x3D;  (REAL*)calloc(dimension_c * window * dimension, sizeof(REAL));
	conv_1d_position_head_copy &#x3D; (REAL *)calloc(dimension_c * window * dimension_pos, sizeof(REAL));
	conv_1d_position_tail_copy &#x3D; (REAL *)calloc(dimension_c * window * dimension_pos, sizeof(REAL));
	conv_1d_bias_copy &#x3D;  (REAL*)calloc(dimension_c, sizeof(REAL));
	attention_weights_copy &#x3D; attention_weights;
	relation_matrix_copy &#x3D; (REAL *)calloc(relation_total * dimension_c, sizeof(REAL));
	relation_matrix_bias_copy &#x3D; (REAL *)calloc(relation_total, sizeof(REAL));

	&#x2F;&#x2F; 模型的权重矩阵初始化
	REAL relation_matrix_init &#x3D; sqrt(6.0 &#x2F; (relation_total + dimension_c));
	REAL conv_1d_position_vec_init &#x3D; sqrt(6.0 &#x2F; ((dimension + dimension_pos) * window));

	for (INT i &#x3D; 0; i &lt; position_total_head; i++) &#123;
		for (INT j &#x3D; 0; j &lt; dimension_pos; j++) &#123;
			position_vec_head[i * dimension_pos + j] &#x3D; get_rand_u(-conv_1d_position_vec_init,
				conv_1d_position_vec_init);
		&#125;
	&#125;
	for (INT i &#x3D; 0; i &lt; position_total_tail; i++) &#123;
		for (INT j &#x3D; 0; j &lt; dimension_pos; j++) &#123;
			position_vec_tail[i * dimension_pos + j] &#x3D; get_rand_u(-conv_1d_position_vec_init,
				conv_1d_position_vec_init);
		&#125;
	&#125;
	for (INT i &#x3D; 0; i &lt; dimension_c; i++) &#123;
		INT last &#x3D; i * window * dimension;
		for (INT j &#x3D; 0; j &lt; window * dimension; j++)
			conv_1d_word[last + j] &#x3D; get_rand_u(-conv_1d_position_vec_init, conv_1d_position_vec_init);
		last &#x3D; i * window * dimension_pos;
		for (INT j &#x3D; dimension_pos * window - 1; j &gt;&#x3D;0; j--) &#123;
			conv_1d_position_head[last + j] &#x3D; get_rand_u(-conv_1d_position_vec_init, conv_1d_position_vec_init);
			conv_1d_position_tail[last + j] &#x3D; get_rand_u(-conv_1d_position_vec_init, conv_1d_position_vec_init);
		&#125;
		conv_1d_bias[i] &#x3D; get_rand_u(-conv_1d_position_vec_init, conv_1d_position_vec_init);
	&#125;
	for (INT i &#x3D; 0; i &lt; relation_total; i++) 
	&#123;
		for (INT j &#x3D; 0; j &lt; dimension_c; j++)
			relation_matrix[i * dimension_c + j] &#x3D; get_rand_u(-relation_matrix_init, relation_matrix_init);
		relation_matrix_bias[i] &#x3D; get_rand_u(-relation_matrix_init, relation_matrix_init);
	&#125;

	printf(&quot;##################################################\n\nTrain start...\n\n&quot;);

	for (INT epoch &#x3D; 1; epoch &lt;&#x3D; epochs; epoch++) &#123;

		&#x2F;&#x2F; 更新当前 epoch 的学习率		
		current_alpha &#x3D; alpha * current_rate;

		current_sample &#x3D; 0;
		final_sample &#x3D; 0;
		total_loss &#x3D; 0;

		gettimeofday(&amp;train_start, NULL);

		for (INT i &#x3D; 1; i &lt;&#x3D; nbatches; i++) &#123;
			final_sample +&#x3D; batch * num_threads;
			
			memcpy(word_vec_copy, word_vec, word_total * dimension * sizeof(REAL));
			memcpy(position_vec_head_copy, position_vec_head, position_total_head * dimension_pos * sizeof(REAL));
			memcpy(position_vec_tail_copy, position_vec_tail, position_total_tail * dimension_pos * sizeof(REAL));
			memcpy(conv_1d_word_copy, conv_1d_word, dimension_c * window * dimension * sizeof(REAL));
			memcpy(conv_1d_position_head_copy, conv_1d_position_head, dimension_c * window * dimension_pos * sizeof(REAL));
			memcpy(conv_1d_position_tail_copy, conv_1d_position_tail, dimension_c * window * dimension_pos * sizeof(REAL));
			memcpy(conv_1d_bias_copy, conv_1d_bias, dimension_c * sizeof(REAL));
			attention_weights_copy &#x3D; attention_weights;
			memcpy(relation_matrix_copy, relation_matrix, relation_total * dimension_c * sizeof(REAL));
			memcpy(relation_matrix_bias_copy, relation_matrix_bias, relation_total * sizeof(REAL));
			
			pthread_t *pt &#x3D; (pthread_t *)malloc(num_threads * sizeof(pthread_t));
			for (long a &#x3D; 0; a &lt; num_threads; a++)
				pthread_create(&amp;pt[a], NULL, train_mode,  (void *)a);
			for (long a &#x3D; 0; a &lt; num_threads; a++)
				pthread_join(pt[a], NULL);
			free(pt);
		&#125;

		gettimeofday(&amp;train_end, NULL);
		long double time_use &#x3D; (1000000 * (train_end.tv_sec - train_start.tv_sec)
			+ train_end.tv_usec - train_start.tv_usec) &#x2F; 1000000.0;

		printf(&quot;Epoch %d&#x2F;%d - current_alpha: %.8f - loss: %f - %02d:%02d:%02d\n\n&quot;, epoch, epochs,
			current_alpha, total_loss &#x2F; final_sample, INT(time_use &#x2F; 3600.0),
			INT(time_use) % 3600 &#x2F; 60, INT(time_use) % 60);
		test();
		printf(&quot;Test end.\n\n##################################################\n\n&quot;);

		current_rate &#x3D; current_rate * reduce_epoch;
	&#125;
	printf(&quot;Train end.\n\n##################################################\n\n&quot;);
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; Main function
&#x2F;&#x2F; ##################################################

void setparameters(INT argc, char **argv) &#123;
	INT i;
	if ((i &#x3D; arg_pos((char *)&quot;-batch&quot;, argc, argv)) &gt; 0) batch &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-threads&quot;, argc, argv)) &gt; 0) num_threads &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-alpha&quot;, argc, argv)) &gt; 0) alpha &#x3D; atof(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-init_rate&quot;, argc, argv)) &gt; 0) current_rate &#x3D; atof(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-reduce_epoch&quot;, argc, argv)) &gt; 0) reduce_epoch &#x3D; atof(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-epochs&quot;, argc, argv)) &gt; 0) epochs &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-limit&quot;, argc, argv)) &gt; 0) limit &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-dimension_pos&quot;, argc, argv)) &gt; 0) dimension_pos &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-window&quot;, argc, argv)) &gt; 0) window &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-dimension_c&quot;, argc, argv)) &gt; 0) dimension_c &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-dropout&quot;, argc, argv)) &gt; 0) dropout_probability &#x3D; atof(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-output_model&quot;, argc, argv)) &gt; 0) output_model &#x3D; atoi(argv[i + 1]);	
	if ((i &#x3D; arg_pos((char *)&quot;-note&quot;, argc, argv)) &gt; 0) note &#x3D; argv[i + 1];
	if ((i &#x3D; arg_pos((char *)&quot;-data_path&quot;, argc, argv)) &gt; 0) data_path &#x3D; argv[i + 1];
	if ((i &#x3D; arg_pos((char *)&quot;-output_path&quot;, argc, argv)) &gt; 0) output_path &#x3D; argv[i + 1];
&#125;

void print_train_help() &#123;
	std::string str &#x3D; R&quot;(
&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; .&#x2F;train [-batch BATCH] [-threads THREAD] [-alpha ALPHA]
&#x2F;&#x2F;         [-init_rate INIT_RATE] [-reduce_epoch REDUCE_EPOCH]
&#x2F;&#x2F;         [-epochs EPOCHS] [-limit LIMIT] [-dimension_pos DIMENSION_POS]
&#x2F;&#x2F;         [-window WINDOW] [-dimension_c DIMENSION_C]
&#x2F;&#x2F;         [-dropout DROPOUT] [-output_model 0&#x2F;1]
&#x2F;&#x2F;         [-note NOTE] [-data_path DATA_PATH]
&#x2F;&#x2F;         [-output_path OUTPUT_PATH] [--help]

&#x2F;&#x2F; optional arguments:
&#x2F;&#x2F; -batch BATCH                   batch size. if unspecified, batch will default to [40]
&#x2F;&#x2F; -threads THREAD                number of worker threads. if unspecified, num_threads will default to [32]
&#x2F;&#x2F; -alpha ALPHA                   learning rate. if unspecified, alpha will default to [0.00125]
&#x2F;&#x2F; -init_rate INIT_RATE           init rate of learning rate. if unspecified, current_rate will default to [1.0]
&#x2F;&#x2F; -reduce_epoch REDUCE_EPOCH     reduce of init rate of learning rate per epoch. if unspecified, reduce_epoch will default to [0.98]
&#x2F;&#x2F; -epochs EPOCHS                 number of epochs. if unspecified, epochs will default to [25]
&#x2F;&#x2F; -limit LIMIT                   限制句子中 (头, 尾) 实体相对每个单词的最大距离. 默认值为 [30]
&#x2F;&#x2F; -dimension_pos DIMENSION_POS   位置嵌入维度，默认值为 [5]
&#x2F;&#x2F; -window WINDOW                 一维卷积的 window 大小. 默认值为 [3]
&#x2F;&#x2F; -dimension_c DIMENSION_C       sentence embedding size, if unspecified, dimension_c will default to [230]
&#x2F;&#x2F; -dropout DROPOUT               dropout probability. if unspecified, dropout_probability will default to [0.5]
&#x2F;&#x2F; -output_model 0&#x2F;1              [1] 保存模型, [0] 不保存模型. 默认值为 [1]
&#x2F;&#x2F; -note NOTE                     information you want to add to the filename, like (&quot;.&#x2F;output&#x2F;word2vec&quot; + note + &quot;.txt&quot;). if unspecified, note will default to &quot;&quot;
&#x2F;&#x2F; -data_path DATA_PATH           folder of data. if unspecified, data_path will default to &quot;..&#x2F;data&#x2F;&quot;
&#x2F;&#x2F; -output_path OUTPUT_PATH       folder of outputing results (precion&#x2F;recall curves) and models. if unspecified, output_path will default to &quot;.&#x2F;output&#x2F;&quot;
&#x2F;&#x2F; --help                         print help information of .&#x2F;train
&#x2F;&#x2F; ##################################################
)&quot;;

	printf(&quot;%s\n&quot;, str.c_str());
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; .&#x2F;train [-batch BATCH] [-threads THREAD] [-alpha ALPHA]
&#x2F;&#x2F;         [-init_rate INIT_RATE] [-reduce_epoch REDUCE_EPOCH]
&#x2F;&#x2F;         [-epochs EPOCHS] [-limit LIMIT] [-dimension_pos DIMENSION_POS]
&#x2F;&#x2F;         [-window WINDOW] [-dimension_c DIMENSION_C]
&#x2F;&#x2F;         [-dropout DROPOUT] [-output_model 0&#x2F;1]
&#x2F;&#x2F;         [-note NOTE] [-data_path DATA_PATH]
&#x2F;&#x2F;         [-output_path OUTPUT_PATH] [--help]

&#x2F;&#x2F; optional arguments:
&#x2F;&#x2F; -batch BATCH                   batch size. if unspecified, batch will default to [40]
&#x2F;&#x2F; -threads THREAD                number of worker threads. if unspecified, num_threads will default to [32]
&#x2F;&#x2F; -alpha ALPHA                   learning rate. if unspecified, alpha will default to [0.00125]
&#x2F;&#x2F; -init_rate INIT_RATE           init rate of learning rate. if unspecified, current_rate will default to [1.0]
&#x2F;&#x2F; -reduce_epoch REDUCE_EPOCH     reduce of init rate of learning rate per epoch. if unspecified, reduce_epoch will default to [0.98]
&#x2F;&#x2F; -epochs EPOCHS                 number of epochs. if unspecified, epochs will default to [25]
&#x2F;&#x2F; -limit LIMIT                   限制句子中 (头, 尾) 实体相对每个单词的最大距离. 默认值为 [30]
&#x2F;&#x2F; -dimension_pos DIMENSION_POS   位置嵌入维度，默认值为 [5]
&#x2F;&#x2F; -window WINDOW                 一维卷积的 window 大小. 默认值为 [3]
&#x2F;&#x2F; -dimension_c DIMENSION_C       sentence embedding size, if unspecified, dimension_c will default to [230]
&#x2F;&#x2F; -dropout DROPOUT               dropout probability. if unspecified, dropout_probability will default to [0.5]
&#x2F;&#x2F; -output_model 0&#x2F;1              [1] 保存模型, [0] 不保存模型. 默认值为 [1]
&#x2F;&#x2F; -note NOTE                     information you want to add to the filename, like (&quot;.&#x2F;output&#x2F;word2vec&quot; + note + &quot;.txt&quot;). if unspecified, note will default to &quot;&quot;
&#x2F;&#x2F; -data_path DATA_PATH           folder of data. if unspecified, data_path will default to &quot;..&#x2F;data&#x2F;&quot;
&#x2F;&#x2F; -output_path OUTPUT_PATH       folder of outputing results (precion&#x2F;recall curves) and models. if unspecified, output_path will default to &quot;.&#x2F;output&#x2F;&quot;
&#x2F;&#x2F; --help                         print help information of .&#x2F;train
&#x2F;&#x2F; ##################################################

INT main(INT argc, char **argv) &#123;
	for (INT a &#x3D; 1; a &lt; argc; a++) if (!strcmp((char *)&quot;--help&quot;, argv[a])) &#123;
		print_train_help();
		return 0;
	&#125;
	output_model &#x3D; 1;
	setparameters(argc, argv);
	init();
	print_information();
	train();
	return 0;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="test-cpp"><a href="#test-cpp" class="headerlink" title="test.cpp"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/test.cpp">test.cpp</a></h4><pre class="line-numbers language-c++" data-language="c++"><code class="language-c++">&#x2F;&#x2F; test.cpp
&#x2F;&#x2F;
&#x2F;&#x2F; 使用方法:
&#x2F;&#x2F;     编译:
&#x2F;&#x2F;           $ g++ test.cpp -o .&#x2F;build&#x2F;test -pthread -O3 -march&#x3D;native
&#x2F;&#x2F;     运行:
&#x2F;&#x2F;           $ .&#x2F;build&#x2F;test
&#x2F;&#x2F;
&#x2F;&#x2F; created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com&gt;
&#x2F;&#x2F;
&#x2F;&#x2F; 该 C++ 文件用于模型测试
&#x2F;&#x2F;
&#x2F;&#x2F; 加载模型
&#x2F;&#x2F; prerequisites:
&#x2F;&#x2F;     .&#x2F;output&#x2F;word2vec + note + .txt
&#x2F;&#x2F;     .&#x2F;output&#x2F;position_vec + note + .txt
&#x2F;&#x2F;     .&#x2F;output&#x2F;conv_1d + note + .txt
&#x2F;&#x2F;     .&#x2F;output&#x2F;attention_weights + note + .txt
&#x2F;&#x2F;     .&#x2F;output&#x2F;relation_matrix + note + .txt

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; 包含标准库和头文件
&#x2F;&#x2F; ##################################################

#include &quot;init.h&quot;
#include &quot;test.h&quot;

&#x2F;&#x2F; 加载模型
void load_model()
&#123;
	&#x2F;&#x2F; 为模型的权重矩阵分配内存空间
	position_vec_head &#x3D; (REAL *)calloc(position_total_head * dimension_pos, sizeof(REAL));
	position_vec_tail &#x3D; (REAL *)calloc(position_total_tail * dimension_pos, sizeof(REAL));

	conv_1d_word &#x3D; (REAL*)calloc(dimension_c * dimension * window, sizeof(REAL));
	conv_1d_position_head &#x3D; (REAL *)calloc(dimension_c * dimension_pos * window, sizeof(REAL));
	conv_1d_position_tail &#x3D; (REAL *)calloc(dimension_c * dimension_pos * window, sizeof(REAL));
	conv_1d_bias &#x3D; (REAL*)calloc(dimension_c, sizeof(REAL));

	attention_weights.resize(relation_total);
	for (INT i &#x3D; 0; i &lt; relation_total; i++)
	&#123;
		attention_weights[i].resize(dimension_c);
		for (INT j &#x3D; 0; j &lt; dimension_c; j++)
			attention_weights[i][j].resize(dimension_c);
	&#125;

	relation_matrix &#x3D; (REAL *)calloc(relation_total * dimension_c, sizeof(REAL));
	relation_matrix_bias &#x3D; (REAL *)calloc(relation_total, sizeof(REAL));
	
	INT tmp;

	&#x2F;&#x2F; 加载词嵌入
	FILE *fout &#x3D; fopen((output_path + &quot;word2vec&quot; + note + &quot;.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fout,&quot;%d%d&quot;, &amp;word_total, &amp;dimension);
	for (INT i &#x3D; 0; i &lt; word_total; i++)
	&#123;
		for (INT j &#x3D; 0; j &lt; dimension; j++)
			tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;word_vec[i * dimension + j]);
	&#125;
	fclose(fout);

	&#x2F;&#x2F; 加载位置嵌入
	fout &#x3D; fopen((output_path + &quot;position_vec&quot; + note + &quot;.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fout, &quot;%d%d%d&quot;, &amp;position_total_head, &amp;position_total_tail, &amp;dimension_pos);
	for (INT i &#x3D; 0; i &lt; position_total_head; i++) &#123;
		for (INT j &#x3D; 0; j &lt; dimension_pos; j++)
			tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;position_vec_head[i * dimension_pos + j]);
	&#125;
	for (INT i &#x3D; 0; i &lt; position_total_tail; i++) &#123;
		for (INT j &#x3D; 0; j &lt; dimension_pos; j++)
			tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;position_vec_tail[i * dimension_pos + j]);
	&#125;
	fclose(fout);

	&#x2F;&#x2F; 加载一维卷积权重矩阵和对应的偏置向量
	fout &#x3D; fopen((output_path + &quot;conv_1d&quot; + note + &quot;.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fout, &quot;%d%d%d%d&quot;, &amp;dimension_c, &amp;window, &amp;dimension, &amp;dimension_pos);
	for (INT i &#x3D; 0; i &lt; dimension_c; i++) &#123;
		for (INT j &#x3D; 0; j &lt; window * dimension; j++)
			tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;conv_1d_word[i * window * dimension + j]);
		for (INT j &#x3D; 0; j &lt; window * dimension_pos; j++)
			tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;conv_1d_position_head[i * window * dimension_pos + j]);
		for (INT j &#x3D; 0; j &lt; window * dimension_pos; j++)
			tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;conv_1d_position_tail[i * window * dimension_pos + j]);
		tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;conv_1d_bias[i]);
	&#125;
	fclose(fout);

	&#x2F;&#x2F; 加载注意力权重矩阵
	fout &#x3D; fopen((output_path + &quot;attention_weights&quot; + note + &quot;.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fout,&quot;%d%d&quot;, &amp;relation_total, &amp;dimension_c);
	for (INT r &#x3D; 0; r &lt; relation_total; r++) &#123;
		for (INT i_x &#x3D; 0; i_x &lt; dimension_c; i_x++)
		&#123;
			for (INT i_r &#x3D; 0; i_r &lt; dimension_c; i_r++)
				tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;attention_weights[r][i_x][i_r]);
		&#125;
	&#125;
	fclose(fout);

	&#x2F;&#x2F; 加载 relation_matrix 和对应的偏置向量
	fout &#x3D; fopen((output_path + &quot;relation_matrix&quot; + note + &quot;.txt&quot;).c_str(), &quot;r&quot;);
	tmp &#x3D; fscanf(fout, &quot;%d%d%f&quot;, &amp;relation_total, &amp;dimension_c, &amp;dropout_probability);
	for (INT i_r &#x3D; 0; i_r &lt; relation_total; i_r++) &#123;
		for (INT i_s &#x3D; 0; i_s &lt; dimension_c; i_s++)
			tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;relation_matrix[i_r * dimension_c + i_s]);
	&#125;
	for (INT i_r &#x3D; 0; i_r &lt; relation_total; i_r++) 
		tmp &#x3D; fscanf(fout, &quot;%f&quot;, &amp;relation_matrix_bias[i_r]);
	fclose(fout);

	printf(&quot;模型加载成功!\n\n&quot;);
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; Main function
&#x2F;&#x2F; ##################################################

void setparameters(INT argc, char **argv) &#123;
	INT i;
	if ((i &#x3D; arg_pos((char *)&quot;-threads&quot;, argc, argv)) &gt; 0) num_threads &#x3D; atoi(argv[i + 1]);
	if ((i &#x3D; arg_pos((char *)&quot;-note&quot;, argc, argv)) &gt; 0) note &#x3D; argv[i + 1];
	if ((i &#x3D; arg_pos((char *)&quot;-data_path&quot;, argc, argv)) &gt; 0) data_path &#x3D; argv[i + 1];
	if ((i &#x3D; arg_pos((char *)&quot;-load_path&quot;, argc, argv)) &gt; 0) output_path &#x3D; argv[i + 1];
&#125;

void print_test_help() &#123;
	std::string str &#x3D; R&quot;(
&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; .&#x2F;test [-threads THREAD] [-dropout DROPOUT]
&#x2F;&#x2F;        [-note NOTE] [-data_path DATA_PATH]
&#x2F;&#x2F;        [-load_path LOAD_PATH] [--help]

&#x2F;&#x2F; optional arguments:
&#x2F;&#x2F; -threads THREAD                number of worker threads. if unspecified, num_threads will default to [32]
&#x2F;&#x2F; -note NOTE                     information you want to add to the filename, like (&quot;.&#x2F;output&#x2F;word2vec&quot; + note + &quot;.txt&quot;). if unspecified, note will default to &quot;&quot;
&#x2F;&#x2F; -data_path DATA_PATH           folder of data. if unspecified, data_path will default to &quot;..&#x2F;data&#x2F;&quot;
&#x2F;&#x2F; -load_path LOAD_PATH           folder of pretrained models. if unspecified, load_path will default to &quot;.&#x2F;output&#x2F;&quot;
&#x2F;&#x2F; --help                         print help information of .&#x2F;test
&#x2F;&#x2F; ##################################################
)&quot;;

	printf(&quot;%s\n&quot;, str.c_str());
&#125;

&#x2F;&#x2F; ##################################################
&#x2F;&#x2F; .&#x2F;test [-threads THREAD] [-dropout DROPOUT]
&#x2F;&#x2F;        [-note NOTE] [-data_path DATA_PATH]
&#x2F;&#x2F;        [-load_path LOAD_PATH] [--help]

&#x2F;&#x2F; optional arguments:
&#x2F;&#x2F; -threads THREAD                number of worker threads. if unspecified, num_threads will default to [32]
&#x2F;&#x2F; -note NOTE                     information you want to add to the filename, like (&quot;.&#x2F;output&#x2F;word2vec&quot; + note + &quot;.txt&quot;). if unspecified, note will default to &quot;&quot;
&#x2F;&#x2F; -data_path DATA_PATH           folder of data. if unspecified, data_path will default to &quot;..&#x2F;data&#x2F;&quot;
&#x2F;&#x2F; -load_path LOAD_PATH           folder of pretrained models. if unspecified, load_path will default to &quot;.&#x2F;output&#x2F;&quot;
&#x2F;&#x2F; --help                         print help information of .&#x2F;test
&#x2F;&#x2F; ##################################################

INT main(INT argc, char **argv) &#123;
	for (INT a &#x3D; 1; a &lt; argc; a++) if (!strcmp((char *)&quot;--help&quot;, argv[a])) &#123;
		print_test_help();
		return 0;
	&#125;	
	setparameters(argc, argv);
	init();
	load_model();
	print_information();
	test();
	printf(&quot;Test end.\n\n##################################################\n\n&quot;);
	return 0;
&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="run-sh"><a href="#run-sh" class="headerlink" title="run.sh"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/run.sh">run.sh</a></h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>

<span class="token comment">##################################################</span>
<span class="token comment"># run.sh</span>
<span class="token comment"># 使用方法：$ bash run.sh</span>
<span class="token comment"># created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com></span>
<span class="token comment">#</span>
<span class="token comment"># 该 Shell 脚本用于模型训练和模型测试</span>
<span class="token comment">##################################################</span>

<span class="token comment"># 创建 build 目录</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token builtin class-name">echo</span> <span class="token string">"##################################################"</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token function">mkdir</span> <span class="token parameter variable">-p</span> build
<span class="token function">mkdir</span> <span class="token parameter variable">-p</span> output
<span class="token builtin class-name">echo</span> <span class="token string">"./build 和 ./output 目录创建成功."</span>

<span class="token comment"># compile</span>
g++ train.cpp <span class="token parameter variable">-o</span> ./build/train <span class="token parameter variable">-pthread</span> <span class="token parameter variable">-O3</span> <span class="token parameter variable">-march</span><span class="token operator">=</span>native
g++ test.cpp <span class="token parameter variable">-o</span> ./build/test <span class="token parameter variable">-pthread</span> <span class="token parameter variable">-O3</span> <span class="token parameter variable">-march</span><span class="token operator">=</span>native

<span class="token comment"># train</span>
./build/train<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="clean-sh"><a href="#clean-sh" class="headerlink" title="clean.sh"></a><a href="https://github.com/LuYF-Lemon-love/susu-knowledge-graph/blob/main/neural-relation-extraction/C%2B%2B/CNN%2BATT/clean.sh">clean.sh</a></h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token shebang important">#!/bin/bash</span>

<span class="token comment">##################################################</span>
<span class="token comment"># clean.sh</span>
<span class="token comment"># 使用方法：$ bash clean.sh</span>
<span class="token comment"># created by LuYF-Lemon-love &lt;luyanfeng_nlp@qq.com></span>
<span class="token comment">#</span>
<span class="token comment"># 该 Shell 脚本用于清理临时文件</span>
<span class="token comment">##################################################</span>

<span class="token comment"># 删除目标文件</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token builtin class-name">echo</span> <span class="token string">"##################################################"</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token function">rm</span> <span class="token parameter variable">-rf</span> ./build
<span class="token builtin class-name">echo</span> <span class="token string">"./build 目录递归删除成功."</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span>
<span class="token builtin class-name">echo</span> <span class="token string">"##################################################"</span>
<span class="token builtin class-name">echo</span> <span class="token string">""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">$ <span class="token function">ls</span>
clean.sh  init.h  run.sh  test.cpp  test.h  train.cpp
$ <span class="token function">bash</span> run.sh 

<span class="token comment">##################################################</span>

./build 和 ./output 目录创建成功.

<span class="token comment">##################################################</span>

Init start<span class="token punctuation">..</span>.

训练数据和测试数据加载成功<span class="token operator">!</span>

batch: <span class="token number">40</span>
number of threads: <span class="token number">32</span>
learning rate: <span class="token number">0.00125000</span>
init_rate: <span class="token number">1.00</span>
reduce_epoch: <span class="token number">0.98</span>
epochs: <span class="token number">25</span>

word_total: <span class="token number">114043</span>
word dimension: <span class="token number">50</span>

limit: <span class="token number">30</span>
position_total_head: <span class="token number">61</span>
position_total_tail: <span class="token number">61</span>
dimension_pos: <span class="token number">5</span>

window: <span class="token number">3</span>
dimension_c: <span class="token number">230</span>

relation_total: <span class="token number">53</span>
dropout_probability: <span class="token number">0.50</span>

将会保存模型.
note: 

folder of data: <span class="token punctuation">..</span>/data/
folder of outputing results <span class="token punctuation">(</span>precion/recall curves<span class="token punctuation">)</span> and models: ./output/

number of training samples:  <span class="token number">281270</span> - average sentence number of per training sample: <span class="token number">1.86</span>
number of testing samples:    <span class="token number">96678</span> - average sentence number of per testing sample:  <span class="token number">1.78</span>

Init end.

<span class="token comment">##################################################</span>

Train start<span class="token punctuation">..</span>.

Epoch <span class="token number">1</span>/25 - current_alpha: <span class="token number">0.00125000</span> - loss: <span class="token number">0.392392</span> - 00:04:00

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.280</span> - recall: <span class="token number">0.007</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.210</span> - recall: <span class="token number">0.011</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.187</span> - recall: <span class="token number">0.014</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.185</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.164</span> - recall: <span class="token number">0.021</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.147</span> - recall: <span class="token number">0.023</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.134</span> - recall: <span class="token number">0.024</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.125</span> - recall: <span class="token number">0.026</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.120</span> - recall: <span class="token number">0.028</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.122</span> - recall: <span class="token number">0.031</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.125</span> - recall: <span class="token number">0.035</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.118</span> - recall: <span class="token number">0.036</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.118</span> - recall: <span class="token number">0.039</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.116</span> - recall: <span class="token number">0.042</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.109</span> - recall: <span class="token number">0.042</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.109</span> - recall: <span class="token number">0.045</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.105</span> - recall: <span class="token number">0.046</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.104</span> - recall: <span class="token number">0.048</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.102</span> - recall: <span class="token number">0.050</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.101</span> - recall: <span class="token number">0.052</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.102</span> - recall: <span class="token number">0.055</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.099</span> - recall: <span class="token number">0.056</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.097</span> - recall: <span class="token number">0.057</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.094</span> - recall: <span class="token number">0.058</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.092</span> - recall: <span class="token number">0.059</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.090</span> - recall: <span class="token number">0.060</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.087</span> - recall: <span class="token number">0.061</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.085</span> - recall: <span class="token number">0.061</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.083</span> - recall: <span class="token number">0.062</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.085</span> - recall: <span class="token number">0.065</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.084</span> - recall: <span class="token number">0.067</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.083</span> - recall: <span class="token number">0.068</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.082</span> - recall: <span class="token number">0.069</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.081</span> - recall: <span class="token number">0.071</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.081</span> - recall: <span class="token number">0.073</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.081</span> - recall: <span class="token number">0.075</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.082</span> - recall: <span class="token number">0.078</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.080</span> - recall: <span class="token number">0.078</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.080</span> - recall: <span class="token number">0.080</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.079</span> - recall: <span class="token number">0.081</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:21

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">2</span>/25 - current_alpha: <span class="token number">0.00122500</span> - loss: <span class="token number">0.312926</span> - 00:04:58

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.014</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.540</span> - recall: <span class="token number">0.028</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.573</span> - recall: <span class="token number">0.044</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.555</span> - recall: <span class="token number">0.057</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.536</span> - recall: <span class="token number">0.069</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.517</span> - recall: <span class="token number">0.079</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.483</span> - recall: <span class="token number">0.087</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.468</span> - recall: <span class="token number">0.096</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.433</span> - recall: <span class="token number">0.100</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.412</span> - recall: <span class="token number">0.106</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.404</span> - recall: <span class="token number">0.114</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.388</span> - recall: <span class="token number">0.119</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.375</span> - recall: <span class="token number">0.125</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.370</span> - recall: <span class="token number">0.133</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.359</span> - recall: <span class="token number">0.138</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.350</span> - recall: <span class="token number">0.144</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.339</span> - recall: <span class="token number">0.148</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.332</span> - recall: <span class="token number">0.153</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.322</span> - recall: <span class="token number">0.157</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.312</span> - recall: <span class="token number">0.160</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.304</span> - recall: <span class="token number">0.164</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.294</span> - recall: <span class="token number">0.166</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.285</span> - recall: <span class="token number">0.168</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.279</span> - recall: <span class="token number">0.172</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.277</span> - recall: <span class="token number">0.177</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.271</span> - recall: <span class="token number">0.181</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.264</span> - recall: <span class="token number">0.183</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.256</span> - recall: <span class="token number">0.184</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.253</span> - recall: <span class="token number">0.188</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.249</span> - recall: <span class="token number">0.191</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.245</span> - recall: <span class="token number">0.194</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.238</span> - recall: <span class="token number">0.195</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.233</span> - recall: <span class="token number">0.197</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.228</span> - recall: <span class="token number">0.198</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.225</span> - recall: <span class="token number">0.202</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.220</span> - recall: <span class="token number">0.203</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.216</span> - recall: <span class="token number">0.205</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.212</span> - recall: <span class="token number">0.207</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.208</span> - recall: <span class="token number">0.208</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.204</span> - recall: <span class="token number">0.209</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">3</span>/25 - current_alpha: <span class="token number">0.00120050</span> - loss: <span class="token number">0.263319</span> - 00:04:04

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.500</span> - recall: <span class="token number">0.013</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.550</span> - recall: <span class="token number">0.028</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.043</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.585</span> - recall: <span class="token number">0.060</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.556</span> - recall: <span class="token number">0.071</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.527</span> - recall: <span class="token number">0.081</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.506</span> - recall: <span class="token number">0.091</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.490</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.460</span> - recall: <span class="token number">0.106</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.448</span> - recall: <span class="token number">0.115</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.433</span> - recall: <span class="token number">0.122</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.420</span> - recall: <span class="token number">0.129</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.405</span> - recall: <span class="token number">0.135</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.394</span> - recall: <span class="token number">0.142</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.379</span> - recall: <span class="token number">0.146</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.371</span> - recall: <span class="token number">0.152</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.362</span> - recall: <span class="token number">0.158</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.353</span> - recall: <span class="token number">0.163</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.348</span> - recall: <span class="token number">0.170</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.340</span> - recall: <span class="token number">0.174</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.330</span> - recall: <span class="token number">0.177</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.325</span> - recall: <span class="token number">0.183</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.319</span> - recall: <span class="token number">0.188</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.313</span> - recall: <span class="token number">0.193</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.307</span> - recall: <span class="token number">0.197</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.302</span> - recall: <span class="token number">0.201</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.295</span> - recall: <span class="token number">0.204</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.288</span> - recall: <span class="token number">0.207</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.283</span> - recall: <span class="token number">0.211</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.277</span> - recall: <span class="token number">0.213</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.270</span> - recall: <span class="token number">0.214</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.262</span> - recall: <span class="token number">0.215</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.258</span> - recall: <span class="token number">0.218</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.255</span> - recall: <span class="token number">0.223</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.251</span> - recall: <span class="token number">0.225</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.248</span> - recall: <span class="token number">0.229</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.243</span> - recall: <span class="token number">0.230</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.239</span> - recall: <span class="token number">0.233</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.235</span> - recall: <span class="token number">0.235</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.231</span> - recall: <span class="token number">0.237</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:21

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">4</span>/25 - current_alpha: <span class="token number">0.00117649</span> - loss: <span class="token number">0.234492</span> - 00:03:50

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.015</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.031</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.046</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.590</span> - recall: <span class="token number">0.061</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.072</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.540</span> - recall: <span class="token number">0.083</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.534</span> - recall: <span class="token number">0.096</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.507</span> - recall: <span class="token number">0.104</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.484</span> - recall: <span class="token number">0.112</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.480</span> - recall: <span class="token number">0.123</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.475</span> - recall: <span class="token number">0.134</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.470</span> - recall: <span class="token number">0.145</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.457</span> - recall: <span class="token number">0.152</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.451</span> - recall: <span class="token number">0.162</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.443</span> - recall: <span class="token number">0.170</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.438</span> - recall: <span class="token number">0.179</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.431</span> - recall: <span class="token number">0.188</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.416</span> - recall: <span class="token number">0.192</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.407</span> - recall: <span class="token number">0.198</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.401</span> - recall: <span class="token number">0.206</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.399</span> - recall: <span class="token number">0.215</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.391</span> - recall: <span class="token number">0.221</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.384</span> - recall: <span class="token number">0.227</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.376</span> - recall: <span class="token number">0.231</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.369</span> - recall: <span class="token number">0.236</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.366</span> - recall: <span class="token number">0.244</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.361</span> - recall: <span class="token number">0.250</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.356</span> - recall: <span class="token number">0.256</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.350</span> - recall: <span class="token number">0.260</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.341</span> - recall: <span class="token number">0.263</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.336</span> - recall: <span class="token number">0.267</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.333</span> - recall: <span class="token number">0.273</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.327</span> - recall: <span class="token number">0.277</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.321</span> - recall: <span class="token number">0.279</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.314</span> - recall: <span class="token number">0.282</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.310</span> - recall: <span class="token number">0.286</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.306</span> - recall: <span class="token number">0.290</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.302</span> - recall: <span class="token number">0.294</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.298</span> - recall: <span class="token number">0.298</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.294</span> - recall: <span class="token number">0.301</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:21

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">5</span>/25 - current_alpha: <span class="token number">0.00115296</span> - loss: <span class="token number">0.211013</span> - 00:03:39

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.015</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.031</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.046</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.590</span> - recall: <span class="token number">0.061</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.580</span> - recall: <span class="token number">0.074</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.086</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.569</span> - recall: <span class="token number">0.102</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.562</span> - recall: <span class="token number">0.115</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.538</span> - recall: <span class="token number">0.124</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.530</span> - recall: <span class="token number">0.136</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.522</span> - recall: <span class="token number">0.147</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.512</span> - recall: <span class="token number">0.157</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.497</span> - recall: <span class="token number">0.166</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.487</span> - recall: <span class="token number">0.175</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.477</span> - recall: <span class="token number">0.184</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.466</span> - recall: <span class="token number">0.191</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.449</span> - recall: <span class="token number">0.196</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.443</span> - recall: <span class="token number">0.205</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.438</span> - recall: <span class="token number">0.213</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.438</span> - recall: <span class="token number">0.225</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.428</span> - recall: <span class="token number">0.230</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.418</span> - recall: <span class="token number">0.236</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.410</span> - recall: <span class="token number">0.242</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.404</span> - recall: <span class="token number">0.249</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.399</span> - recall: <span class="token number">0.256</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.392</span> - recall: <span class="token number">0.262</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.386</span> - recall: <span class="token number">0.267</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.377</span> - recall: <span class="token number">0.271</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.371</span> - recall: <span class="token number">0.276</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.367</span> - recall: <span class="token number">0.283</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.360</span> - recall: <span class="token number">0.286</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.357</span> - recall: <span class="token number">0.293</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.351</span> - recall: <span class="token number">0.297</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.344</span> - recall: <span class="token number">0.300</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.340</span> - recall: <span class="token number">0.305</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.335</span> - recall: <span class="token number">0.309</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.329</span> - recall: <span class="token number">0.312</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.325</span> - recall: <span class="token number">0.317</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.323</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.317</span> - recall: <span class="token number">0.325</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:23

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">6</span>/25 - current_alpha: <span class="token number">0.00112990</span> - loss: <span class="token number">0.201362</span> - 00:04:17

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.660</span> - recall: <span class="token number">0.017</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.620</span> - recall: <span class="token number">0.032</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.046</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.610</span> - recall: <span class="token number">0.063</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.592</span> - recall: <span class="token number">0.076</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.563</span> - recall: <span class="token number">0.087</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.567</span> - recall: <span class="token number">0.116</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.129</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.552</span> - recall: <span class="token number">0.142</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.540</span> - recall: <span class="token number">0.152</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.528</span> - recall: <span class="token number">0.163</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.515</span> - recall: <span class="token number">0.172</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.504</span> - recall: <span class="token number">0.181</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.496</span> - recall: <span class="token number">0.191</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.485</span> - recall: <span class="token number">0.199</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.472</span> - recall: <span class="token number">0.206</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.463</span> - recall: <span class="token number">0.214</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.452</span> - recall: <span class="token number">0.220</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.447</span> - recall: <span class="token number">0.229</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.438</span> - recall: <span class="token number">0.236</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.432</span> - recall: <span class="token number">0.244</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.427</span> - recall: <span class="token number">0.252</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.421</span> - recall: <span class="token number">0.259</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.418</span> - recall: <span class="token number">0.268</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.412</span> - recall: <span class="token number">0.274</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.405</span> - recall: <span class="token number">0.281</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.398</span> - recall: <span class="token number">0.286</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.391</span> - recall: <span class="token number">0.291</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.385</span> - recall: <span class="token number">0.296</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.379</span> - recall: <span class="token number">0.302</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.373</span> - recall: <span class="token number">0.306</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.369</span> - recall: <span class="token number">0.312</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.361</span> - recall: <span class="token number">0.315</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.355</span> - recall: <span class="token number">0.319</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.351</span> - recall: <span class="token number">0.324</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.345</span> - recall: <span class="token number">0.327</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.342</span> - recall: <span class="token number">0.333</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.337</span> - recall: <span class="token number">0.337</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.331</span> - recall: <span class="token number">0.339</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">7</span>/25 - current_alpha: <span class="token number">0.00110730</span> - loss: <span class="token number">0.189826</span> - 00:03:58

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.640</span> - recall: <span class="token number">0.016</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.620</span> - recall: <span class="token number">0.032</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.627</span> - recall: <span class="token number">0.048</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.595</span> - recall: <span class="token number">0.061</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.592</span> - recall: <span class="token number">0.076</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.577</span> - recall: <span class="token number">0.089</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.565</span> - recall: <span class="token number">0.116</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.576</span> - recall: <span class="token number">0.133</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.144</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.562</span> - recall: <span class="token number">0.158</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.543</span> - recall: <span class="token number">0.167</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.525</span> - recall: <span class="token number">0.175</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.520</span> - recall: <span class="token number">0.187</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.515</span> - recall: <span class="token number">0.198</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.500</span> - recall: <span class="token number">0.205</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.495</span> - recall: <span class="token number">0.216</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.481</span> - recall: <span class="token number">0.222</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.482</span> - recall: <span class="token number">0.235</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.473</span> - recall: <span class="token number">0.243</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.470</span> - recall: <span class="token number">0.253</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.462</span> - recall: <span class="token number">0.261</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.452</span> - recall: <span class="token number">0.267</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.442</span> - recall: <span class="token number">0.272</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.436</span> - recall: <span class="token number">0.279</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.424</span> - recall: <span class="token number">0.283</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.413</span> - recall: <span class="token number">0.286</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.404</span> - recall: <span class="token number">0.290</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.401</span> - recall: <span class="token number">0.298</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.392</span> - recall: <span class="token number">0.302</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.389</span> - recall: <span class="token number">0.309</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.381</span> - recall: <span class="token number">0.312</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.374</span> - recall: <span class="token number">0.316</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.370</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.370</span> - recall: <span class="token number">0.332</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.366</span> - recall: <span class="token number">0.338</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.362</span> - recall: <span class="token number">0.343</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.356</span> - recall: <span class="token number">0.347</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.351</span> - recall: <span class="token number">0.351</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.345</span> - recall: <span class="token number">0.354</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:21

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">8</span>/25 - current_alpha: <span class="token number">0.00108516</span> - loss: <span class="token number">0.182470</span> - 00:03:33

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.680</span> - recall: <span class="token number">0.017</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.650</span> - recall: <span class="token number">0.033</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.633</span> - recall: <span class="token number">0.049</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.620</span> - recall: <span class="token number">0.064</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.616</span> - recall: <span class="token number">0.079</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.597</span> - recall: <span class="token number">0.092</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.614</span> - recall: <span class="token number">0.110</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.615</span> - recall: <span class="token number">0.126</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.607</span> - recall: <span class="token number">0.140</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.602</span> - recall: <span class="token number">0.154</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.589</span> - recall: <span class="token number">0.166</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.570</span> - recall: <span class="token number">0.175</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.557</span> - recall: <span class="token number">0.186</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.547</span> - recall: <span class="token number">0.196</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.536</span> - recall: <span class="token number">0.206</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.525</span> - recall: <span class="token number">0.215</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.516</span> - recall: <span class="token number">0.225</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.507</span> - recall: <span class="token number">0.234</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.495</span> - recall: <span class="token number">0.241</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.484</span> - recall: <span class="token number">0.248</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.472</span> - recall: <span class="token number">0.254</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.467</span> - recall: <span class="token number">0.264</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.463</span> - recall: <span class="token number">0.273</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.454</span> - recall: <span class="token number">0.279</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.450</span> - recall: <span class="token number">0.288</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.440</span> - recall: <span class="token number">0.293</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.431</span> - recall: <span class="token number">0.298</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.424</span> - recall: <span class="token number">0.305</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.419</span> - recall: <span class="token number">0.311</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.412</span> - recall: <span class="token number">0.317</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.406</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.399</span> - recall: <span class="token number">0.328</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.396</span> - recall: <span class="token number">0.335</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.390</span> - recall: <span class="token number">0.340</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.382</span> - recall: <span class="token number">0.343</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.377</span> - recall: <span class="token number">0.348</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.375</span> - recall: <span class="token number">0.355</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.368</span> - recall: <span class="token number">0.359</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.364</span> - recall: <span class="token number">0.364</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.356</span> - recall: <span class="token number">0.366</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">9</span>/25 - current_alpha: <span class="token number">0.00106345</span> - loss: <span class="token number">0.174141</span> - 00:03:59

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.780</span> - recall: <span class="token number">0.020</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.650</span> - recall: <span class="token number">0.033</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.613</span> - recall: <span class="token number">0.047</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.062</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.616</span> - recall: <span class="token number">0.079</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.607</span> - recall: <span class="token number">0.093</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.108</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.605</span> - recall: <span class="token number">0.124</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.609</span> - recall: <span class="token number">0.141</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.578</span> - recall: <span class="token number">0.148</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.575</span> - recall: <span class="token number">0.162</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.565</span> - recall: <span class="token number">0.174</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.562</span> - recall: <span class="token number">0.187</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.553</span> - recall: <span class="token number">0.198</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.537</span> - recall: <span class="token number">0.207</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.520</span> - recall: <span class="token number">0.213</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.507</span> - recall: <span class="token number">0.221</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.500</span> - recall: <span class="token number">0.231</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.492</span> - recall: <span class="token number">0.239</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.483</span> - recall: <span class="token number">0.248</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.471</span> - recall: <span class="token number">0.254</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.462</span> - recall: <span class="token number">0.261</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.460</span> - recall: <span class="token number">0.271</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.452</span> - recall: <span class="token number">0.278</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.443</span> - recall: <span class="token number">0.284</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.439</span> - recall: <span class="token number">0.293</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.435</span> - recall: <span class="token number">0.301</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.429</span> - recall: <span class="token number">0.308</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.426</span> - recall: <span class="token number">0.316</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.420</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.414</span> - recall: <span class="token number">0.329</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.407</span> - recall: <span class="token number">0.334</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.400</span> - recall: <span class="token number">0.338</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.395</span> - recall: <span class="token number">0.345</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.391</span> - recall: <span class="token number">0.351</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.384</span> - recall: <span class="token number">0.355</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.378</span> - recall: <span class="token number">0.359</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.373</span> - recall: <span class="token number">0.364</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.367</span> - recall: <span class="token number">0.367</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.361</span> - recall: <span class="token number">0.371</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">10</span>/25 - current_alpha: <span class="token number">0.00104219</span> - loss: <span class="token number">0.170107</span> - 00:03:58

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.820</span> - recall: <span class="token number">0.021</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.700</span> - recall: <span class="token number">0.036</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.707</span> - recall: <span class="token number">0.054</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.700</span> - recall: <span class="token number">0.072</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.664</span> - recall: <span class="token number">0.085</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.647</span> - recall: <span class="token number">0.099</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.631</span> - recall: <span class="token number">0.113</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.630</span> - recall: <span class="token number">0.129</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.611</span> - recall: <span class="token number">0.141</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.606</span> - recall: <span class="token number">0.155</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.585</span> - recall: <span class="token number">0.165</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.575</span> - recall: <span class="token number">0.177</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.565</span> - recall: <span class="token number">0.188</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.554</span> - recall: <span class="token number">0.199</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.547</span> - recall: <span class="token number">0.210</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.533</span> - recall: <span class="token number">0.218</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.526</span> - recall: <span class="token number">0.229</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.516</span> - recall: <span class="token number">0.238</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.506</span> - recall: <span class="token number">0.247</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.497</span> - recall: <span class="token number">0.255</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.486</span> - recall: <span class="token number">0.262</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.476</span> - recall: <span class="token number">0.269</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.472</span> - recall: <span class="token number">0.278</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.463</span> - recall: <span class="token number">0.285</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.454</span> - recall: <span class="token number">0.291</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.444</span> - recall: <span class="token number">0.296</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.438</span> - recall: <span class="token number">0.303</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.428</span> - recall: <span class="token number">0.307</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.426</span> - recall: <span class="token number">0.316</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.417</span> - recall: <span class="token number">0.321</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.409</span> - recall: <span class="token number">0.325</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.403</span> - recall: <span class="token number">0.331</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.398</span> - recall: <span class="token number">0.337</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.392</span> - recall: <span class="token number">0.342</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.387</span> - recall: <span class="token number">0.348</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.384</span> - recall: <span class="token number">0.354</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.379</span> - recall: <span class="token number">0.359</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.372</span> - recall: <span class="token number">0.363</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.367</span> - recall: <span class="token number">0.367</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.363</span> - recall: <span class="token number">0.372</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">11</span>/25 - current_alpha: <span class="token number">0.00102134</span> - loss: <span class="token number">0.164617</span> - 00:04:04

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.780</span> - recall: <span class="token number">0.020</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.680</span> - recall: <span class="token number">0.035</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.647</span> - recall: <span class="token number">0.050</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.635</span> - recall: <span class="token number">0.065</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.620</span> - recall: <span class="token number">0.079</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.627</span> - recall: <span class="token number">0.096</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.609</span> - recall: <span class="token number">0.109</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.123</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.596</span> - recall: <span class="token number">0.137</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.580</span> - recall: <span class="token number">0.149</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.575</span> - recall: <span class="token number">0.162</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.577</span> - recall: <span class="token number">0.177</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.566</span> - recall: <span class="token number">0.189</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.557</span> - recall: <span class="token number">0.200</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.543</span> - recall: <span class="token number">0.209</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.535</span> - recall: <span class="token number">0.219</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.528</span> - recall: <span class="token number">0.230</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.520</span> - recall: <span class="token number">0.240</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.508</span> - recall: <span class="token number">0.248</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.499</span> - recall: <span class="token number">0.256</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.491</span> - recall: <span class="token number">0.265</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.478</span> - recall: <span class="token number">0.270</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.470</span> - recall: <span class="token number">0.277</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.461</span> - recall: <span class="token number">0.284</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.452</span> - recall: <span class="token number">0.290</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.445</span> - recall: <span class="token number">0.297</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.436</span> - recall: <span class="token number">0.302</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.432</span> - recall: <span class="token number">0.310</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.430</span> - recall: <span class="token number">0.319</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.429</span> - recall: <span class="token number">0.330</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.420</span> - recall: <span class="token number">0.334</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.412</span> - recall: <span class="token number">0.338</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.406</span> - recall: <span class="token number">0.344</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.402</span> - recall: <span class="token number">0.350</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.397</span> - recall: <span class="token number">0.356</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.391</span> - recall: <span class="token number">0.361</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.385</span> - recall: <span class="token number">0.366</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.382</span> - recall: <span class="token number">0.372</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.375</span> - recall: <span class="token number">0.375</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.371</span> - recall: <span class="token number">0.381</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">12</span>/25 - current_alpha: <span class="token number">0.00100091</span> - loss: <span class="token number">0.158291</span> - 00:03:49

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.760</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.680</span> - recall: <span class="token number">0.035</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.653</span> - recall: <span class="token number">0.050</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.640</span> - recall: <span class="token number">0.066</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.636</span> - recall: <span class="token number">0.082</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.623</span> - recall: <span class="token number">0.096</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.609</span> - recall: <span class="token number">0.109</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.595</span> - recall: <span class="token number">0.122</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.587</span> - recall: <span class="token number">0.135</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.576</span> - recall: <span class="token number">0.148</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.571</span> - recall: <span class="token number">0.161</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.562</span> - recall: <span class="token number">0.173</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.557</span> - recall: <span class="token number">0.186</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.550</span> - recall: <span class="token number">0.197</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.547</span> - recall: <span class="token number">0.210</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.538</span> - recall: <span class="token number">0.221</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.534</span> - recall: <span class="token number">0.233</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.521</span> - recall: <span class="token number">0.241</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.517</span> - recall: <span class="token number">0.252</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.501</span> - recall: <span class="token number">0.257</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.495</span> - recall: <span class="token number">0.267</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.482</span> - recall: <span class="token number">0.272</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.473</span> - recall: <span class="token number">0.279</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.467</span> - recall: <span class="token number">0.287</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.460</span> - recall: <span class="token number">0.295</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.451</span> - recall: <span class="token number">0.301</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.440</span> - recall: <span class="token number">0.305</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.434</span> - recall: <span class="token number">0.311</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.425</span> - recall: <span class="token number">0.316</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.419</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.412</span> - recall: <span class="token number">0.328</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.409</span> - recall: <span class="token number">0.335</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.402</span> - recall: <span class="token number">0.341</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.396</span> - recall: <span class="token number">0.345</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.393</span> - recall: <span class="token number">0.353</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.389</span> - recall: <span class="token number">0.359</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.384</span> - recall: <span class="token number">0.364</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.378</span> - recall: <span class="token number">0.369</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.377</span> - recall: <span class="token number">0.377</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.371</span> - recall: <span class="token number">0.381</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">13</span>/25 - current_alpha: <span class="token number">0.00098090</span> - loss: <span class="token number">0.157852</span> - 00:04:22

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.760</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.690</span> - recall: <span class="token number">0.035</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.680</span> - recall: <span class="token number">0.052</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.665</span> - recall: <span class="token number">0.068</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.652</span> - recall: <span class="token number">0.084</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.613</span> - recall: <span class="token number">0.094</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.609</span> - recall: <span class="token number">0.109</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.123</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.584</span> - recall: <span class="token number">0.135</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.592</span> - recall: <span class="token number">0.152</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.582</span> - recall: <span class="token number">0.164</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.572</span> - recall: <span class="token number">0.176</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.569</span> - recall: <span class="token number">0.190</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.570</span> - recall: <span class="token number">0.205</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.564</span> - recall: <span class="token number">0.217</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.555</span> - recall: <span class="token number">0.228</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.541</span> - recall: <span class="token number">0.236</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.530</span> - recall: <span class="token number">0.245</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.520</span> - recall: <span class="token number">0.253</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.507</span> - recall: <span class="token number">0.260</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.494</span> - recall: <span class="token number">0.266</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.489</span> - recall: <span class="token number">0.276</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.482</span> - recall: <span class="token number">0.284</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.477</span> - recall: <span class="token number">0.293</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.470</span> - recall: <span class="token number">0.302</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.461</span> - recall: <span class="token number">0.307</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.451</span> - recall: <span class="token number">0.312</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.444</span> - recall: <span class="token number">0.319</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.438</span> - recall: <span class="token number">0.326</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.435</span> - recall: <span class="token number">0.334</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.425</span> - recall: <span class="token number">0.337</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.416</span> - recall: <span class="token number">0.342</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.411</span> - recall: <span class="token number">0.348</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.405</span> - recall: <span class="token number">0.353</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.397</span> - recall: <span class="token number">0.356</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.392</span> - recall: <span class="token number">0.362</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.387</span> - recall: <span class="token number">0.367</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.383</span> - recall: <span class="token number">0.373</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.377</span> - recall: <span class="token number">0.377</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.374</span> - recall: <span class="token number">0.384</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">14</span>/25 - current_alpha: <span class="token number">0.00096128</span> - loss: <span class="token number">0.153716</span> - 00:03:42

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.720</span> - recall: <span class="token number">0.018</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.710</span> - recall: <span class="token number">0.036</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.687</span> - recall: <span class="token number">0.053</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.675</span> - recall: <span class="token number">0.069</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.640</span> - recall: <span class="token number">0.082</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.620</span> - recall: <span class="token number">0.095</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.108</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.123</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.591</span> - recall: <span class="token number">0.136</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.582</span> - recall: <span class="token number">0.149</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.573</span> - recall: <span class="token number">0.162</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.565</span> - recall: <span class="token number">0.174</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.187</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.561</span> - recall: <span class="token number">0.202</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.551</span> - recall: <span class="token number">0.212</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.545</span> - recall: <span class="token number">0.224</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.533</span> - recall: <span class="token number">0.232</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.521</span> - recall: <span class="token number">0.241</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.512</span> - recall: <span class="token number">0.249</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.507</span> - recall: <span class="token number">0.260</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.495</span> - recall: <span class="token number">0.267</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.492</span> - recall: <span class="token number">0.277</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.487</span> - recall: <span class="token number">0.287</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.477</span> - recall: <span class="token number">0.293</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.470</span> - recall: <span class="token number">0.301</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.458</span> - recall: <span class="token number">0.306</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.456</span> - recall: <span class="token number">0.315</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.449</span> - recall: <span class="token number">0.322</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.439</span> - recall: <span class="token number">0.326</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.431</span> - recall: <span class="token number">0.332</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.425</span> - recall: <span class="token number">0.337</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.417</span> - recall: <span class="token number">0.343</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.412</span> - recall: <span class="token number">0.349</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.406</span> - recall: <span class="token number">0.354</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.401</span> - recall: <span class="token number">0.360</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.396</span> - recall: <span class="token number">0.366</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.391</span> - recall: <span class="token number">0.371</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.389</span> - recall: <span class="token number">0.379</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.381</span> - recall: <span class="token number">0.381</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.376</span> - recall: <span class="token number">0.386</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">15</span>/25 - current_alpha: <span class="token number">0.00094205</span> - loss: <span class="token number">0.150468</span> - 00:04:12

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.780</span> - recall: <span class="token number">0.020</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.710</span> - recall: <span class="token number">0.036</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.693</span> - recall: <span class="token number">0.053</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.675</span> - recall: <span class="token number">0.069</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.688</span> - recall: <span class="token number">0.088</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.653</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.629</span> - recall: <span class="token number">0.113</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.598</span> - recall: <span class="token number">0.123</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.582</span> - recall: <span class="token number">0.134</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.580</span> - recall: <span class="token number">0.149</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.576</span> - recall: <span class="token number">0.163</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.570</span> - recall: <span class="token number">0.175</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.555</span> - recall: <span class="token number">0.185</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.544</span> - recall: <span class="token number">0.195</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.536</span> - recall: <span class="token number">0.206</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.530</span> - recall: <span class="token number">0.217</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.524</span> - recall: <span class="token number">0.228</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.519</span> - recall: <span class="token number">0.239</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.512</span> - recall: <span class="token number">0.249</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.504</span> - recall: <span class="token number">0.258</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.494</span> - recall: <span class="token number">0.266</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.488</span> - recall: <span class="token number">0.275</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.485</span> - recall: <span class="token number">0.286</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.478</span> - recall: <span class="token number">0.294</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.470</span> - recall: <span class="token number">0.301</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.459</span> - recall: <span class="token number">0.306</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.450</span> - recall: <span class="token number">0.312</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.441</span> - recall: <span class="token number">0.316</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.434</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.424</span> - recall: <span class="token number">0.326</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.421</span> - recall: <span class="token number">0.334</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.414</span> - recall: <span class="token number">0.339</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.412</span> - recall: <span class="token number">0.348</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.407</span> - recall: <span class="token number">0.355</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.401</span> - recall: <span class="token number">0.359</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.395</span> - recall: <span class="token number">0.365</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.390</span> - recall: <span class="token number">0.370</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.385</span> - recall: <span class="token number">0.375</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.379</span> - recall: <span class="token number">0.379</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.377</span> - recall: <span class="token number">0.386</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">16</span>/25 - current_alpha: <span class="token number">0.00092321</span> - loss: <span class="token number">0.145180</span> - 00:04:06

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.700</span> - recall: <span class="token number">0.018</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.750</span> - recall: <span class="token number">0.038</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.713</span> - recall: <span class="token number">0.055</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.700</span> - recall: <span class="token number">0.072</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.668</span> - recall: <span class="token number">0.086</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.640</span> - recall: <span class="token number">0.098</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.626</span> - recall: <span class="token number">0.112</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.615</span> - recall: <span class="token number">0.126</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.138</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.584</span> - recall: <span class="token number">0.150</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.575</span> - recall: <span class="token number">0.162</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.562</span> - recall: <span class="token number">0.173</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.549</span> - recall: <span class="token number">0.183</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.546</span> - recall: <span class="token number">0.196</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.543</span> - recall: <span class="token number">0.209</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.533</span> - recall: <span class="token number">0.218</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.532</span> - recall: <span class="token number">0.232</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.519</span> - recall: <span class="token number">0.239</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.512</span> - recall: <span class="token number">0.249</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.507</span> - recall: <span class="token number">0.260</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.498</span> - recall: <span class="token number">0.268</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.494</span> - recall: <span class="token number">0.278</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.484</span> - recall: <span class="token number">0.286</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.477</span> - recall: <span class="token number">0.294</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.469</span> - recall: <span class="token number">0.301</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.464</span> - recall: <span class="token number">0.309</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.456</span> - recall: <span class="token number">0.315</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.449</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.443</span> - recall: <span class="token number">0.329</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.438</span> - recall: <span class="token number">0.337</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.428</span> - recall: <span class="token number">0.341</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.424</span> - recall: <span class="token number">0.348</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.416</span> - recall: <span class="token number">0.352</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.409</span> - recall: <span class="token number">0.357</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.403</span> - recall: <span class="token number">0.362</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.400</span> - recall: <span class="token number">0.369</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.395</span> - recall: <span class="token number">0.374</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.391</span> - recall: <span class="token number">0.381</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.387</span> - recall: <span class="token number">0.387</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.380</span> - recall: <span class="token number">0.389</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">17</span>/25 - current_alpha: <span class="token number">0.00090475</span> - loss: <span class="token number">0.142947</span> - 00:03:53

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.840</span> - recall: <span class="token number">0.022</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.760</span> - recall: <span class="token number">0.039</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.720</span> - recall: <span class="token number">0.055</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.710</span> - recall: <span class="token number">0.073</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.672</span> - recall: <span class="token number">0.086</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.647</span> - recall: <span class="token number">0.099</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.634</span> - recall: <span class="token number">0.114</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.625</span> - recall: <span class="token number">0.128</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.613</span> - recall: <span class="token number">0.142</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.154</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.593</span> - recall: <span class="token number">0.167</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.580</span> - recall: <span class="token number">0.178</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.571</span> - recall: <span class="token number">0.190</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.201</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.559</span> - recall: <span class="token number">0.215</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.550</span> - recall: <span class="token number">0.226</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.544</span> - recall: <span class="token number">0.237</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.538</span> - recall: <span class="token number">0.248</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.528</span> - recall: <span class="token number">0.257</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.517</span> - recall: <span class="token number">0.265</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.503</span> - recall: <span class="token number">0.271</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.495</span> - recall: <span class="token number">0.279</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.491</span> - recall: <span class="token number">0.290</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.484</span> - recall: <span class="token number">0.298</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.477</span> - recall: <span class="token number">0.306</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.465</span> - recall: <span class="token number">0.310</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.457</span> - recall: <span class="token number">0.316</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.451</span> - recall: <span class="token number">0.324</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.443</span> - recall: <span class="token number">0.329</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.438</span> - recall: <span class="token number">0.337</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.432</span> - recall: <span class="token number">0.344</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.427</span> - recall: <span class="token number">0.350</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.420</span> - recall: <span class="token number">0.355</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.414</span> - recall: <span class="token number">0.361</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.411</span> - recall: <span class="token number">0.369</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.405</span> - recall: <span class="token number">0.374</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.398</span> - recall: <span class="token number">0.378</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.392</span> - recall: <span class="token number">0.382</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.388</span> - recall: <span class="token number">0.388</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.380</span> - recall: <span class="token number">0.390</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">18</span>/25 - current_alpha: <span class="token number">0.00088665</span> - loss: <span class="token number">0.138729</span> - 00:03:56

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.800</span> - recall: <span class="token number">0.021</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.780</span> - recall: <span class="token number">0.040</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.727</span> - recall: <span class="token number">0.056</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.695</span> - recall: <span class="token number">0.071</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.676</span> - recall: <span class="token number">0.087</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.643</span> - recall: <span class="token number">0.099</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.620</span> - recall: <span class="token number">0.111</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.615</span> - recall: <span class="token number">0.126</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.613</span> - recall: <span class="token number">0.142</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.612</span> - recall: <span class="token number">0.157</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.605</span> - recall: <span class="token number">0.171</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.588</span> - recall: <span class="token number">0.181</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.577</span> - recall: <span class="token number">0.192</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.567</span> - recall: <span class="token number">0.204</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.553</span> - recall: <span class="token number">0.213</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.543</span> - recall: <span class="token number">0.223</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.533</span> - recall: <span class="token number">0.232</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.521</span> - recall: <span class="token number">0.241</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.518</span> - recall: <span class="token number">0.252</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.511</span> - recall: <span class="token number">0.262</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.506</span> - recall: <span class="token number">0.272</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.502</span> - recall: <span class="token number">0.283</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.490</span> - recall: <span class="token number">0.289</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.477</span> - recall: <span class="token number">0.293</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.469</span> - recall: <span class="token number">0.301</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.463</span> - recall: <span class="token number">0.309</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.453</span> - recall: <span class="token number">0.314</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.449</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.443</span> - recall: <span class="token number">0.329</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.434</span> - recall: <span class="token number">0.334</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.427</span> - recall: <span class="token number">0.339</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.421</span> - recall: <span class="token number">0.346</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.419</span> - recall: <span class="token number">0.355</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.415</span> - recall: <span class="token number">0.362</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.410</span> - recall: <span class="token number">0.368</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.404</span> - recall: <span class="token number">0.373</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.400</span> - recall: <span class="token number">0.379</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.392</span> - recall: <span class="token number">0.382</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.385</span> - recall: <span class="token number">0.385</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.380</span> - recall: <span class="token number">0.390</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:23

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">19</span>/25 - current_alpha: <span class="token number">0.00086892</span> - loss: <span class="token number">0.137877</span> - 00:04:07

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.760</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.720</span> - recall: <span class="token number">0.037</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.693</span> - recall: <span class="token number">0.053</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.690</span> - recall: <span class="token number">0.071</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.672</span> - recall: <span class="token number">0.086</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.657</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.631</span> - recall: <span class="token number">0.113</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.620</span> - recall: <span class="token number">0.127</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.613</span> - recall: <span class="token number">0.142</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.596</span> - recall: <span class="token number">0.153</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.580</span> - recall: <span class="token number">0.164</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.575</span> - recall: <span class="token number">0.177</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.568</span> - recall: <span class="token number">0.189</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.559</span> - recall: <span class="token number">0.201</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.548</span> - recall: <span class="token number">0.211</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.538</span> - recall: <span class="token number">0.221</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.524</span> - recall: <span class="token number">0.228</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.520</span> - recall: <span class="token number">0.240</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.516</span> - recall: <span class="token number">0.251</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.508</span> - recall: <span class="token number">0.261</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.504</span> - recall: <span class="token number">0.271</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.495</span> - recall: <span class="token number">0.279</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.489</span> - recall: <span class="token number">0.288</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.484</span> - recall: <span class="token number">0.298</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.476</span> - recall: <span class="token number">0.305</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.468</span> - recall: <span class="token number">0.312</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.463</span> - recall: <span class="token number">0.321</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.455</span> - recall: <span class="token number">0.327</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.446</span> - recall: <span class="token number">0.331</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.441</span> - recall: <span class="token number">0.339</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.435</span> - recall: <span class="token number">0.346</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.426</span> - recall: <span class="token number">0.349</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.422</span> - recall: <span class="token number">0.357</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.416</span> - recall: <span class="token number">0.363</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.408</span> - recall: <span class="token number">0.366</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.402</span> - recall: <span class="token number">0.371</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.398</span> - recall: <span class="token number">0.378</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.390</span> - recall: <span class="token number">0.380</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.385</span> - recall: <span class="token number">0.385</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.378</span> - recall: <span class="token number">0.388</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:22

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">20</span>/25 - current_alpha: <span class="token number">0.00085154</span> - loss: <span class="token number">0.135148</span> - 00:04:04

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.760</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.750</span> - recall: <span class="token number">0.038</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.700</span> - recall: <span class="token number">0.054</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.670</span> - recall: <span class="token number">0.069</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.664</span> - recall: <span class="token number">0.085</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.653</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.640</span> - recall: <span class="token number">0.115</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.625</span> - recall: <span class="token number">0.128</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.613</span> - recall: <span class="token number">0.142</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.154</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.580</span> - recall: <span class="token number">0.164</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.575</span> - recall: <span class="token number">0.177</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.562</span> - recall: <span class="token number">0.187</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.551</span> - recall: <span class="token number">0.198</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.544</span> - recall: <span class="token number">0.209</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.526</span> - recall: <span class="token number">0.216</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.518</span> - recall: <span class="token number">0.226</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.511</span> - recall: <span class="token number">0.236</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.501</span> - recall: <span class="token number">0.244</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.499</span> - recall: <span class="token number">0.256</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.490</span> - recall: <span class="token number">0.264</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.484</span> - recall: <span class="token number">0.273</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.476</span> - recall: <span class="token number">0.281</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.470</span> - recall: <span class="token number">0.289</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.464</span> - recall: <span class="token number">0.297</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.462</span> - recall: <span class="token number">0.308</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.450</span> - recall: <span class="token number">0.311</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.441</span> - recall: <span class="token number">0.316</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.433</span> - recall: <span class="token number">0.322</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.427</span> - recall: <span class="token number">0.328</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.423</span> - recall: <span class="token number">0.336</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.417</span> - recall: <span class="token number">0.343</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.407</span> - recall: <span class="token number">0.345</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.405</span> - recall: <span class="token number">0.353</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.398</span> - recall: <span class="token number">0.357</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.395</span> - recall: <span class="token number">0.365</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.391</span> - recall: <span class="token number">0.371</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.384</span> - recall: <span class="token number">0.374</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.380</span> - recall: <span class="token number">0.380</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.375</span> - recall: <span class="token number">0.385</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:19

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">21</span>/25 - current_alpha: <span class="token number">0.00083451</span> - loss: <span class="token number">0.132989</span> - 00:04:03

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.740</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.720</span> - recall: <span class="token number">0.037</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.707</span> - recall: <span class="token number">0.054</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.705</span> - recall: <span class="token number">0.072</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.672</span> - recall: <span class="token number">0.086</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.647</span> - recall: <span class="token number">0.099</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.640</span> - recall: <span class="token number">0.115</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.618</span> - recall: <span class="token number">0.127</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.607</span> - recall: <span class="token number">0.140</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.154</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.600</span> - recall: <span class="token number">0.169</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.597</span> - recall: <span class="token number">0.184</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.577</span> - recall: <span class="token number">0.192</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.566</span> - recall: <span class="token number">0.203</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.549</span> - recall: <span class="token number">0.211</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.543</span> - recall: <span class="token number">0.223</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.536</span> - recall: <span class="token number">0.234</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.530</span> - recall: <span class="token number">0.245</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.525</span> - recall: <span class="token number">0.256</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.519</span> - recall: <span class="token number">0.266</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.506</span> - recall: <span class="token number">0.272</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.495</span> - recall: <span class="token number">0.279</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.489</span> - recall: <span class="token number">0.288</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.479</span> - recall: <span class="token number">0.295</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.473</span> - recall: <span class="token number">0.303</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.468</span> - recall: <span class="token number">0.312</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.461</span> - recall: <span class="token number">0.319</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.452</span> - recall: <span class="token number">0.325</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.443</span> - recall: <span class="token number">0.329</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.437</span> - recall: <span class="token number">0.336</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.431</span> - recall: <span class="token number">0.343</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.423</span> - recall: <span class="token number">0.347</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.416</span> - recall: <span class="token number">0.352</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.415</span> - recall: <span class="token number">0.362</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.411</span> - recall: <span class="token number">0.369</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.404</span> - recall: <span class="token number">0.373</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.399</span> - recall: <span class="token number">0.378</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.394</span> - recall: <span class="token number">0.384</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.388</span> - recall: <span class="token number">0.388</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.384</span> - recall: <span class="token number">0.394</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:18

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">22</span>/25 - current_alpha: <span class="token number">0.00081782</span> - loss: <span class="token number">0.130612</span> - 00:04:07

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.740</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.760</span> - recall: <span class="token number">0.039</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.733</span> - recall: <span class="token number">0.056</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.720</span> - recall: <span class="token number">0.074</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.684</span> - recall: <span class="token number">0.088</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.650</span> - recall: <span class="token number">0.100</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.620</span> - recall: <span class="token number">0.111</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.613</span> - recall: <span class="token number">0.126</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.591</span> - recall: <span class="token number">0.136</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.596</span> - recall: <span class="token number">0.153</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.593</span> - recall: <span class="token number">0.167</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.578</span> - recall: <span class="token number">0.178</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.565</span> - recall: <span class="token number">0.188</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.557</span> - recall: <span class="token number">0.200</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.560</span> - recall: <span class="token number">0.215</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.558</span> - recall: <span class="token number">0.229</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.553</span> - recall: <span class="token number">0.241</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.543</span> - recall: <span class="token number">0.251</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.529</span> - recall: <span class="token number">0.258</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.522</span> - recall: <span class="token number">0.268</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.518</span> - recall: <span class="token number">0.279</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.508</span> - recall: <span class="token number">0.287</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.497</span> - recall: <span class="token number">0.293</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.484</span> - recall: <span class="token number">0.298</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.476</span> - recall: <span class="token number">0.305</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.467</span> - recall: <span class="token number">0.311</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.460</span> - recall: <span class="token number">0.318</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.452</span> - recall: <span class="token number">0.325</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.444</span> - recall: <span class="token number">0.330</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.439</span> - recall: <span class="token number">0.338</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.435</span> - recall: <span class="token number">0.346</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.428</span> - recall: <span class="token number">0.351</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.419</span> - recall: <span class="token number">0.355</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.415</span> - recall: <span class="token number">0.362</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.407</span> - recall: <span class="token number">0.365</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.399</span> - recall: <span class="token number">0.368</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.393</span> - recall: <span class="token number">0.373</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.388</span> - recall: <span class="token number">0.378</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.384</span> - recall: <span class="token number">0.384</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.380</span> - recall: <span class="token number">0.390</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:19

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">23</span>/25 - current_alpha: <span class="token number">0.00080146</span> - loss: <span class="token number">0.127765</span> - 00:03:55

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.740</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.740</span> - recall: <span class="token number">0.038</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.700</span> - recall: <span class="token number">0.054</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.690</span> - recall: <span class="token number">0.071</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.676</span> - recall: <span class="token number">0.087</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.653</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.637</span> - recall: <span class="token number">0.114</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.627</span> - recall: <span class="token number">0.129</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.616</span> - recall: <span class="token number">0.142</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.604</span> - recall: <span class="token number">0.155</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.584</span> - recall: <span class="token number">0.165</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.562</span> - recall: <span class="token number">0.173</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.557</span> - recall: <span class="token number">0.186</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.543</span> - recall: <span class="token number">0.195</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.537</span> - recall: <span class="token number">0.207</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.531</span> - recall: <span class="token number">0.218</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.529</span> - recall: <span class="token number">0.231</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.526</span> - recall: <span class="token number">0.243</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.519</span> - recall: <span class="token number">0.253</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.503</span> - recall: <span class="token number">0.258</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.494</span> - recall: <span class="token number">0.266</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.489</span> - recall: <span class="token number">0.276</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.483</span> - recall: <span class="token number">0.285</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.477</span> - recall: <span class="token number">0.293</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.466</span> - recall: <span class="token number">0.298</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.456</span> - recall: <span class="token number">0.304</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.448</span> - recall: <span class="token number">0.310</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.443</span> - recall: <span class="token number">0.318</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.434</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.429</span> - recall: <span class="token number">0.330</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.425</span> - recall: <span class="token number">0.337</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.420</span> - recall: <span class="token number">0.345</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.415</span> - recall: <span class="token number">0.351</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.409</span> - recall: <span class="token number">0.356</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.402</span> - recall: <span class="token number">0.361</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.397</span> - recall: <span class="token number">0.366</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.391</span> - recall: <span class="token number">0.371</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.387</span> - recall: <span class="token number">0.377</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.383</span> - recall: <span class="token number">0.383</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.377</span> - recall: <span class="token number">0.387</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:19

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">24</span>/25 - current_alpha: <span class="token number">0.00078543</span> - loss: <span class="token number">0.124412</span> - 00:03:38

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.740</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.720</span> - recall: <span class="token number">0.037</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.720</span> - recall: <span class="token number">0.055</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.700</span> - recall: <span class="token number">0.072</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.692</span> - recall: <span class="token number">0.089</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.657</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.654</span> - recall: <span class="token number">0.117</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.640</span> - recall: <span class="token number">0.131</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.611</span> - recall: <span class="token number">0.141</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.612</span> - recall: <span class="token number">0.157</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.593</span> - recall: <span class="token number">0.167</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.580</span> - recall: <span class="token number">0.178</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.571</span> - recall: <span class="token number">0.190</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.556</span> - recall: <span class="token number">0.199</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.549</span> - recall: <span class="token number">0.211</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.549</span> - recall: <span class="token number">0.225</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.541</span> - recall: <span class="token number">0.236</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.537</span> - recall: <span class="token number">0.248</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.527</span> - recall: <span class="token number">0.257</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.515</span> - recall: <span class="token number">0.264</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.507</span> - recall: <span class="token number">0.273</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.501</span> - recall: <span class="token number">0.283</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.489</span> - recall: <span class="token number">0.288</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.482</span> - recall: <span class="token number">0.296</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.474</span> - recall: <span class="token number">0.304</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.461</span> - recall: <span class="token number">0.307</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.456</span> - recall: <span class="token number">0.315</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.448</span> - recall: <span class="token number">0.322</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.439</span> - recall: <span class="token number">0.326</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.432</span> - recall: <span class="token number">0.332</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.428</span> - recall: <span class="token number">0.341</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.424</span> - recall: <span class="token number">0.348</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.415</span> - recall: <span class="token number">0.351</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.410</span> - recall: <span class="token number">0.357</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.406</span> - recall: <span class="token number">0.365</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.400</span> - recall: <span class="token number">0.369</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.395</span> - recall: <span class="token number">0.374</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.392</span> - recall: <span class="token number">0.382</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.389</span> - recall: <span class="token number">0.389</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.383</span> - recall: <span class="token number">0.393</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:19

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Epoch <span class="token number">25</span>/25 - current_alpha: <span class="token number">0.00076973</span> - loss: <span class="token number">0.124694</span> - 00:04:05

<span class="token comment">##################################################</span>

Test start<span class="token punctuation">..</span>.

Number of <span class="token builtin class-name">test</span> samples <span class="token keyword">for</span> non NA relation: <span class="token number">1950</span>

precion/recall curves   <span class="token number">50</span> / <span class="token number">2000</span> - precision: <span class="token number">0.760</span> - recall: <span class="token number">0.019</span>
precion/recall curves  <span class="token number">100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.730</span> - recall: <span class="token number">0.037</span>
precion/recall curves  <span class="token number">150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.720</span> - recall: <span class="token number">0.055</span>
precion/recall curves  <span class="token number">200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.715</span> - recall: <span class="token number">0.073</span>
precion/recall curves  <span class="token number">250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.692</span> - recall: <span class="token number">0.089</span>
precion/recall curves  <span class="token number">300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.657</span> - recall: <span class="token number">0.101</span>
precion/recall curves  <span class="token number">350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.634</span> - recall: <span class="token number">0.114</span>
precion/recall curves  <span class="token number">400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.623</span> - recall: <span class="token number">0.128</span>
precion/recall curves  <span class="token number">450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.611</span> - recall: <span class="token number">0.141</span>
precion/recall curves  <span class="token number">500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.590</span> - recall: <span class="token number">0.151</span>
precion/recall curves  <span class="token number">550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.587</span> - recall: <span class="token number">0.166</span>
precion/recall curves  <span class="token number">600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.577</span> - recall: <span class="token number">0.177</span>
precion/recall curves  <span class="token number">650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.565</span> - recall: <span class="token number">0.188</span>
precion/recall curves  <span class="token number">700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.551</span> - recall: <span class="token number">0.198</span>
precion/recall curves  <span class="token number">750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.540</span> - recall: <span class="token number">0.208</span>
precion/recall curves  <span class="token number">800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.533</span> - recall: <span class="token number">0.218</span>
precion/recall curves  <span class="token number">850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.519</span> - recall: <span class="token number">0.226</span>
precion/recall curves  <span class="token number">900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.520</span> - recall: <span class="token number">0.240</span>
precion/recall curves  <span class="token number">950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.511</span> - recall: <span class="token number">0.249</span>
precion/recall curves <span class="token number">1000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.501</span> - recall: <span class="token number">0.257</span>
precion/recall curves <span class="token number">1050</span> / <span class="token number">2000</span> - precision: <span class="token number">0.492</span> - recall: <span class="token number">0.265</span>
precion/recall curves <span class="token number">1100</span> / <span class="token number">2000</span> - precision: <span class="token number">0.484</span> - recall: <span class="token number">0.273</span>
precion/recall curves <span class="token number">1150</span> / <span class="token number">2000</span> - precision: <span class="token number">0.477</span> - recall: <span class="token number">0.282</span>
precion/recall curves <span class="token number">1200</span> / <span class="token number">2000</span> - precision: <span class="token number">0.469</span> - recall: <span class="token number">0.289</span>
precion/recall curves <span class="token number">1250</span> / <span class="token number">2000</span> - precision: <span class="token number">0.468</span> - recall: <span class="token number">0.300</span>
precion/recall curves <span class="token number">1300</span> / <span class="token number">2000</span> - precision: <span class="token number">0.463</span> - recall: <span class="token number">0.309</span>
precion/recall curves <span class="token number">1350</span> / <span class="token number">2000</span> - precision: <span class="token number">0.454</span> - recall: <span class="token number">0.314</span>
precion/recall curves <span class="token number">1400</span> / <span class="token number">2000</span> - precision: <span class="token number">0.449</span> - recall: <span class="token number">0.323</span>
precion/recall curves <span class="token number">1450</span> / <span class="token number">2000</span> - precision: <span class="token number">0.440</span> - recall: <span class="token number">0.327</span>
precion/recall curves <span class="token number">1500</span> / <span class="token number">2000</span> - precision: <span class="token number">0.436</span> - recall: <span class="token number">0.335</span>
precion/recall curves <span class="token number">1550</span> / <span class="token number">2000</span> - precision: <span class="token number">0.428</span> - recall: <span class="token number">0.341</span>
precion/recall curves <span class="token number">1600</span> / <span class="token number">2000</span> - precision: <span class="token number">0.426</span> - recall: <span class="token number">0.350</span>
precion/recall curves <span class="token number">1650</span> / <span class="token number">2000</span> - precision: <span class="token number">0.419</span> - recall: <span class="token number">0.354</span>
precion/recall curves <span class="token number">1700</span> / <span class="token number">2000</span> - precision: <span class="token number">0.413</span> - recall: <span class="token number">0.360</span>
precion/recall curves <span class="token number">1750</span> / <span class="token number">2000</span> - precision: <span class="token number">0.406</span> - recall: <span class="token number">0.365</span>
precion/recall curves <span class="token number">1800</span> / <span class="token number">2000</span> - precision: <span class="token number">0.398</span> - recall: <span class="token number">0.368</span>
precion/recall curves <span class="token number">1850</span> / <span class="token number">2000</span> - precision: <span class="token number">0.395</span> - recall: <span class="token number">0.374</span>
precion/recall curves <span class="token number">1900</span> / <span class="token number">2000</span> - precision: <span class="token number">0.389</span> - recall: <span class="token number">0.379</span>
precion/recall curves <span class="token number">1950</span> / <span class="token number">2000</span> - precision: <span class="token number">0.383</span> - recall: <span class="token number">0.383</span>
precion/recall curves <span class="token number">2000</span> / <span class="token number">2000</span> - precision: <span class="token number">0.379</span> - recall: <span class="token number">0.389</span>

<span class="token builtin class-name">test</span> use <span class="token function">time</span> - 00:01:19

模型保存成功, 保存目录为: ./output/

Test end.

<span class="token comment">##################################################</span>

Train end.

<span class="token comment">##################################################</span>

$ tree
<span class="token builtin class-name">.</span>
├── build
│   ├── <span class="token builtin class-name">test</span>
│   └── train
├── clean.sh
├── init.h
├── output
│   ├── attention_weights.txt
│   ├── conv_1d.txt
│   ├── position_vec.txt
│   ├── pr.txt
│   ├── relation_matrix.txt
│   └── word2vec.txt
├── run.sh
├── test.cpp
├── test.h
└── train.cpp

<span class="token number">2</span> directories, <span class="token number">14</span> files
$ <span class="token function">bash</span> clean.sh 

<span class="token comment">##################################################</span>

./build 目录递归删除成功.

<span class="token comment">##################################################</span>

$ tree
<span class="token builtin class-name">.</span>
├── clean.sh
├── init.h
├── output
│   ├── attention_weights.txt
│   ├── conv_1d.txt
│   ├── position_vec.txt
│   ├── pr.txt
│   ├── relation_matrix.txt
│   └── word2vec.txt
├── run.sh
├── test.cpp
├── test.h
└── train.cpp

<span class="token number">1</span> directory, <span class="token number">12</span> files
$ <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="训练和测试的参数"><a href="#训练和测试的参数" class="headerlink" title="训练和测试的参数"></a>训练和测试的参数</h3><h4 id="train-cpp-1"><a href="#train-cpp-1" class="headerlink" title="train.cpp"></a>train.cpp</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">// ./train <span class="token punctuation">[</span>-batch BATCH<span class="token punctuation">]</span> <span class="token punctuation">[</span>-threads THREAD<span class="token punctuation">]</span> <span class="token punctuation">[</span>-alpha ALPHA<span class="token punctuation">]</span>
//         <span class="token punctuation">[</span>-init_rate INIT_RATE<span class="token punctuation">]</span> <span class="token punctuation">[</span>-reduce_epoch REDUCE_EPOCH<span class="token punctuation">]</span>
//         <span class="token punctuation">[</span>-epochs EPOCHS<span class="token punctuation">]</span> <span class="token punctuation">[</span>-limit LIMIT<span class="token punctuation">]</span> <span class="token punctuation">[</span>-dimension_pos DIMENSION_POS<span class="token punctuation">]</span>
//         <span class="token punctuation">[</span>-window WINDOW<span class="token punctuation">]</span> <span class="token punctuation">[</span>-dimension_c DIMENSION_C<span class="token punctuation">]</span>
//         <span class="token punctuation">[</span>-dropout DROPOUT<span class="token punctuation">]</span> <span class="token punctuation">[</span>-output_model <span class="token number">0</span>/1<span class="token punctuation">]</span>
//         <span class="token punctuation">[</span>-note NOTE<span class="token punctuation">]</span> <span class="token punctuation">[</span>-data_path DATA_PATH<span class="token punctuation">]</span>
//         <span class="token punctuation">[</span>-output_path OUTPUT_PATH<span class="token punctuation">]</span> <span class="token punctuation">[</span>--help<span class="token punctuation">]</span>

// optional arguments:
// <span class="token parameter variable">-batch</span> BATCH                   batch size. <span class="token keyword">if</span> unspecified, batch will default to <span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-threads</span> THREAD                number of worker threads. <span class="token keyword">if</span> unspecified, num_threads will default to <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-alpha</span> ALPHA                   learning rate. <span class="token keyword">if</span> unspecified, alpha will default to <span class="token punctuation">[</span><span class="token number">0.00125</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-init_rate</span> INIT_RATE           init rate of learning rate. <span class="token keyword">if</span> unspecified, current_rate will default to <span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-reduce_epoch</span> REDUCE_EPOCH     reduce of init rate of learning rate per epoch. <span class="token keyword">if</span> unspecified, reduce_epoch will default to <span class="token punctuation">[</span><span class="token number">0.98</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-epochs</span> EPOCHS                 number of epochs. <span class="token keyword">if</span> unspecified, epochs will default to <span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-limit</span> LIMIT                   限制句子中 <span class="token punctuation">(</span>头, 尾<span class="token punctuation">)</span> 实体相对每个单词的最大距离. 默认值为 <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-dimension_pos</span> DIMENSION_POS   位置嵌入维度，默认值为 <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-window</span> WINDOW                 一维卷积的 window 大小. 默认值为 <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-dimension_c</span> DIMENSION_C       sentence embedding size, <span class="token keyword">if</span> unspecified, dimension_c will default to <span class="token punctuation">[</span><span class="token number">230</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-dropout</span> DROPOUT               dropout probability. <span class="token keyword">if</span> unspecified, dropout_probability will default to <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-output_model</span> <span class="token number">0</span>/1              <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> 保存模型, <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> 不保存模型. 默认值为 <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-note</span> NOTE                     information you want to <span class="token function">add</span> to the filename, like <span class="token punctuation">(</span><span class="token string">"./output/word2vec"</span> + note + <span class="token string">".txt"</span><span class="token punctuation">)</span>. <span class="token keyword">if</span> unspecified, note will default to <span class="token string">""</span>
// <span class="token parameter variable">-data_path</span> DATA_PATH           folder of data. <span class="token keyword">if</span> unspecified, data_path will default to <span class="token string">"../data/"</span>
// <span class="token parameter variable">-output_path</span> OUTPUT_PATH       folder of outputing results <span class="token punctuation">(</span>precion/recall curves<span class="token punctuation">)</span> and models. <span class="token keyword">if</span> unspecified, output_path will default to <span class="token string">"./output/"</span>
// <span class="token parameter variable">--help</span>                         print <span class="token builtin class-name">help</span> information of ./train<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="test-cpp-1"><a href="#test-cpp-1" class="headerlink" title="test.cpp"></a>test.cpp</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">// ./test <span class="token punctuation">[</span>-threads THREAD<span class="token punctuation">]</span> <span class="token punctuation">[</span>-dropout DROPOUT<span class="token punctuation">]</span>
//        <span class="token punctuation">[</span>-note NOTE<span class="token punctuation">]</span> <span class="token punctuation">[</span>-data_path DATA_PATH<span class="token punctuation">]</span>
//        <span class="token punctuation">[</span>-load_path LOAD_PATH<span class="token punctuation">]</span> <span class="token punctuation">[</span>--help<span class="token punctuation">]</span>

// optional arguments:
// <span class="token parameter variable">-threads</span> THREAD                number of worker threads. <span class="token keyword">if</span> unspecified, num_threads will default to <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span>
// <span class="token parameter variable">-note</span> NOTE                     information you want to <span class="token function">add</span> to the filename, like <span class="token punctuation">(</span><span class="token string">"./output/word2vec"</span> + note + <span class="token string">".txt"</span><span class="token punctuation">)</span>. <span class="token keyword">if</span> unspecified, note will default to <span class="token string">""</span>
// <span class="token parameter variable">-data_path</span> DATA_PATH           folder of data. <span class="token keyword">if</span> unspecified, data_path will default to <span class="token string">"../data/"</span>
// <span class="token parameter variable">-load_path</span> LOAD_PATH           folder of pretrained models. <span class="token keyword">if</span> unspecified, load_path will default to <span class="token string">"./output/"</span>
// <span class="token parameter variable">--help</span>                         print <span class="token builtin class-name">help</span> information of ./test<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>第三十六篇博文写完，开心！！！！</p>
<p>今天，也是充满希望的一天。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">LuYF-Lemon-love</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://luyf-lemon-love.space/2022/10/19/00036-ji-yu-yu-ju-ji-bie-xuan-ze-xing-zhu-yi-li-ji-zhi-de-guan-xi-chou-qu-mo-xing-yuan-lun-wen-xue-xi-bi-ji/">https://luyf-lemon-love.space/2022/10/19/00036-ji-yu-yu-ju-ji-bie-xuan-ze-xing-zhu-yi-li-ji-zhi-de-guan-xi-chou-qu-mo-xing-yuan-lun-wen-xue-xi-bi-ji/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">LuYF-Lemon-love</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/C/">
                                    <span class="chip bg-color">C++</span>
                                </a>
                            
                                <a href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/">
                                    <span class="chip bg-color">多线程</span>
                                </a>
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">深度学习</span>
                                </a>
                            
                                <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                                    <span class="chip bg-color">知识图谱</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">谢谢小主！</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162303.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162220.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2022/11/26/00037-using-opencv-with-gcc-and-cmake/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/4637983068..png" class="responsive-img" alt="00037-Using OpenCV with gcc and CMake">
                        
                        <span class="card-title">00037-Using OpenCV with gcc and CMake</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-11-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/C/" class="post-category">
                                    C++
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/C/">
                        <span class="chip bg-color">C++</span>
                    </a>
                    
                    <a href="/tags/make/">
                        <span class="chip bg-color">make</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/10/10/00035-transe-yuan-lun-wen-xue-xi-bi-ji/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/ionia_placidium_01.jpg" class="responsive-img" alt="00035-TransE 原论文学习笔记">
                        
                        <span class="card-title">00035-TransE 原论文学习笔记</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-10-10
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Paper/" class="post-category">
                                    Paper
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/C/">
                        <span class="chip bg-color">C++</span>
                    </a>
                    
                    <a href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/">
                        <span class="chip bg-color">多线程</span>
                    </a>
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">深度学习</span>
                    </a>
                    
                    <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">
                        <span class="chip bg-color">知识图谱</span>
                    </a>
                    
                    <a href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E8%A1%A5%E5%85%A8/">
                        <span class="chip bg-color">知识图谱补全</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022-2024</span>
            
            <a href="/about" target="_blank">LuYF-Lemon-love</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">990.6k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "5";
                        var startDate = "7";
                        var startHour = "4";
                        var startMinute = "53";
                        var startSecond = "32";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/LuYF-Lemon-love" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:luyanfeng_nlp@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
     
        <script type="text/javascript">
            // 只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
