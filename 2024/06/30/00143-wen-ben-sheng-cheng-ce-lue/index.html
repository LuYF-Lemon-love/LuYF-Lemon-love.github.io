<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="00143 æ–‡æœ¬ç”Ÿæˆç­–ç•¥, NLP LLM DeepLearning LuYF-Lemon-love è‡ªç„¶è¯­è¨€å¤„ç† æ·±åº¦å­¦ä¹  å¤§è¯­è¨€æ¨¡å‹">
    <meta name="description" content="å‰è¨€æœ¬æ–‡ä»‹ç»äº†æ–‡æœ¬ç”Ÿæˆç­–ç•¥ã€‚
Hugging Face Github ä¸»é¡µ: https://github.com/huggingface
Text generation is essential to many NLP tasks, su">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>00143 æ–‡æœ¬ç”Ÿæˆç­–ç•¥ | LuYF-Lemon-love ã® Blog</title>
    <link rel="icon" type="image/jpeg" href="https://cos.luyf-lemon-love.space/images/è‹è‹1.jpeg">
    
    <style>
        body{
            background-image: url(https://cos.luyf-lemon-love.space/images/016-%E6%8A%A5%E7%BA%B8%E5%A2%99%E9%BA%BB%E8%A1%A3%E5%AD%A6%E5%A7%90.jpg);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <span class="logo-span">LuYF-Lemon-love ã® Blog</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>é¦–é¡µ</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>å½’æ¡£</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>æ ‡ç­¾</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>åˆ†ç±»</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>å…³äº</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>å‹æƒ…é“¾æ¥</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>List</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/galleries">
          
          <i class="fas fa-image" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Image</span>
        </a>
      </li>
      
      <li>
        <a href="/verse">
          
          <i class="fas fa-comments" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Verse</span>
        </a>
      </li>
      
      <li>
        <a href="/bilibili">
          
          <i class="fas fa-video" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>Bilibili</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="æœç´¢" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="æ·±è‰²/æµ…è‰²æ¨¡å¼" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <div class="logo-name">LuYF-Lemon-love ã® Blog</div>
        <div class="logo-desc">
            
            å¤©ä¹‹é“ï¼ŒæŸæœ‰ä½™è€Œè¡¥ä¸è¶³ï¼Œäººä¹‹é“åˆ™ä¸ç„¶ï¼ŒæŸä¸è¶³ä»¥å¥‰æœ‰ä½™ã€‚
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			é¦–é¡µ
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			å½’æ¡£
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			æ ‡ç­¾
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			åˆ†ç±»
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			å…³äº
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			å‹æƒ…é“¾æ¥
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			List
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/galleries " style="margin-left:75px">
				  
				   <i class="fa fas fa-image" style="position: absolute;left:50px" ></i>
			      
		          <span>Image</span>
                  </a>
                </li>
              
                <li>

                  <a href="/verse " style="margin-left:75px">
				  
				   <i class="fa fas fa-comments" style="position: absolute;left:50px" ></i>
			      
		          <span>Verse</span>
                  </a>
                </li>
              
                <li>

                  <a href="/bilibili " style="margin-left:75px">
				  
				   <i class="fa fas fa-video" style="position: absolute;left:50px" ></i>
			      
		          <span>Bilibili</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/yanfeng98/paper-is-all-you-need" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/yanfeng98/paper-is-all-you-need" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('è¯·è¾“å…¥è®¿é—®æœ¬æ–‡ç« çš„å¯†ç ')).toString(CryptoJS.enc.Hex)) {
                alert('å¯†ç é”™è¯¯ï¼Œå°†è¿”å›ä¸»é¡µï¼');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://cos.luyf-lemon-love.space/images/006-119971407.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">00143 æ–‡æœ¬ç”Ÿæˆç­–ç•¥</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                <span class="chip bg-color">æ·±åº¦å­¦ä¹ </span>
                            </a>
                        
                            <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                                <span class="chip bg-color">å¤§è¯­è¨€æ¨¡å‹</span>
                            </a>
                        
                            <a href="/tags/huggingface/">
                                <span class="chip bg-color">huggingface</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-category">
                                å¤§è¯­è¨€æ¨¡å‹
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>å‘å¸ƒæ—¥æœŸ:&nbsp;&nbsp;
                    2024-06-30
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>æ›´æ–°æ—¥æœŸ:&nbsp;&nbsp;
                    2024-12-28
                </div>
                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- æ˜¯å¦åŠ è½½ä½¿ç”¨è‡ªå¸¦çš„ prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        
        <!-- ä»£ç å—æŠ˜è¡Œ -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="å‰è¨€"><a href="#å‰è¨€" class="headerlink" title="å‰è¨€"></a>å‰è¨€</h2><p>æœ¬æ–‡ä»‹ç»äº†æ–‡æœ¬ç”Ÿæˆç­–ç•¥ã€‚</p>
<p>Hugging Face Github ä¸»é¡µ: <a href="https://github.com/huggingface">https://github.com/huggingface</a></p>
<p>Text generation is essential to many NLP tasks, such as open-ended text generation, summarization, translation, and more. It also plays a role in a variety of mixed-modality applications that have text as an output like speech-to-text and vision-to-text. Some of the models that can generate text include GPT2, XLNet, OpenAI GPT, CTRL, TransformerXL, XLM, Bart, T5, GIT, Whisper.</p>
<p>Check out a few examples that use [<code>~transformers.generation_utils.GenerationMixin.generate</code>] method to produce text outputs for different tasks:</p>
<ul>
<li><a href="./tasks/summarization#inference">Text summarization</a></li>
<li><a href="./model_doc/git#transformers.GitForCausalLM.forward.example">Image captioning</a></li>
<li><a href="./model_doc/whisper#transformers.WhisperForConditionalGeneration.forward.example">Audio transcription</a></li>
</ul>
<p>Note that the inputs to the generate method depend on the modelâ€™s modality. They are returned by the modelâ€™s preprocessor class, such as AutoTokenizer or AutoProcessor. If a modelâ€™s preprocessor creates more than one kind of input, pass all the inputs to generate(). You can learn more about the individual modelâ€™s preprocessor in the corresponding modelâ€™s documentation.</p>
<p><strong>The process of selecting output tokens to generate text is known as decoding, and you can customize the decoding strategy that the <code>generate()</code> method will use.</strong> Modifying a decoding strategy does not change the values of any trainable parameters. <strong>However, it can have a noticeable impact on the quality of the generated output. It can help reduce repetition in the text and make it more coherent.</strong></p>
<p>This guide describes:</p>
<ul>
<li><strong>default generation configuration</strong></li>
<li><strong>common decoding strategies and their main parameters</strong></li>
<li><strong>saving and sharing custom generation configurations with your fine-tuned model on ğŸ¤— Hub</strong></li>
</ul>
<p>æ“ä½œç³»ç»Ÿï¼šWindows 11 å®¶åº­ä¸­æ–‡ç‰ˆ</p>
<h2 id="å‚è€ƒæ–‡æ¡£"><a href="#å‚è€ƒæ–‡æ¡£" class="headerlink" title="å‚è€ƒæ–‡æ¡£"></a>å‚è€ƒæ–‡æ¡£</h2><ol>
<li><a href="https://huggingface.co/docs/transformers/generation_strategies">Text generation strategies</a></li>
</ol>
<h2 id="Default-text-generation-configuration"><a href="#Default-text-generation-configuration" class="headerlink" title="Default text generation configuration"></a>Default text generation configuration</h2><p>A decoding strategy for a model is defined in its generation configuration. <strong>When using pre-trained models for inference within a [<code>pipeline</code>], the models call the <code>PreTrainedModel.generate()</code> method that applies a default generation configuration under the hood. The default configuration is also used when no custom configuration has been saved with the model.</strong></p>
<p><strong>When you load a model explicitly, you can inspect the generation configuration that comes with it through <code>model.generation_config</code>:</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM

<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"distilbert/distilgpt2"</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> model<span class="token punctuation">.</span>generation_config
GenerationConfig <span class="token punctuation">&#123;</span>
    <span class="token string">"bos_token_id"</span><span class="token punctuation">:</span> <span class="token number">50256</span><span class="token punctuation">,</span>
    <span class="token string">"eos_token_id"</span><span class="token punctuation">:</span> <span class="token number">50256</span><span class="token punctuation">,</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>Printing out the <code>model.generation_config</code> reveals only the values that are different from the default generation configuration, and does not list any of the default values.</strong></p>
<p><strong>The default generation configuration limits the size of the output combined with the input prompt to a maximum of 20 tokens to avoid running into resource limitations. The default decoding strategy is greedy search, which is the simplest decoding strategy that picks a token with the highest probability as the next token. For many tasks and small output sizes this works well. However, when used to generate longer outputs, greedy search can start producing highly repetitive results.</strong></p>
<h2 id="Customize-text-generation"><a href="#Customize-text-generation" class="headerlink" title="Customize text generation"></a>Customize text generation</h2><p><strong>You can override any <code>generation_config</code> by passing the parameters and their values directly to the [<code>generate</code>] method:</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> my_model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> num_beams<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># doctest: +SKIP</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>Even if the default decoding strategy mostly works for your task, you can still tweak a few things. Some of the<br>commonly adjusted parameters include:</p>
<ul>
<li><code>max_new_tokens</code>: <strong>the maximum number of tokens to generate.</strong> In other words, <strong>the size of the output sequence, not including the tokens in the prompt.</strong> As an alternative to using the outputâ€™s length as a stopping criteria, you can choose to stop generation whenever the full generation exceeds some amount of time. To learn more, check [<code>StoppingCriteria</code>].</li>
<li><code>num_beams</code>: by specifying a number of beams higher than 1, you are effectively switching from greedy search to beam search. <strong>This strategy evaluates several hypotheses at each time step and eventually chooses the hypothesis that has the overall highest probability for the entire sequence. This has the advantage of identifying high-probability sequences that start with a lower probability initial tokens and wouldâ€™ve been ignored by the greedy search.</strong></li>
<li><code>do_sample</code>: <strong>if set to <code>True</code>, this parameter enables decoding strategies such as multinomial sampling, beam-search multinomial sampling, Top-K sampling and Top-p sampling. All these strategies select the next token from the probability distribution over the entire vocabulary with various strategy-specific adjustments.</strong></li>
<li><code>num_return_sequences</code>: <strong>the number of sequence candidates to return for each input. This option is only available for the decoding strategies that support multiple sequence candidates, e.g. variations of beam search and sampling. Decoding strategies like greedy search and contrastive search return a single output sequence.</strong></li>
</ul>
<h2 id="Save-a-custom-decoding-strategy-with-your-model"><a href="#Save-a-custom-decoding-strategy-with-your-model" class="headerlink" title="Save a custom decoding strategy with your model"></a>Save a custom decoding strategy with your model</h2><p>If you would like to share your fine-tuned model with a specific generation configuration, you can:</p>
<ul>
<li><strong>Create a [<code>GenerationConfig</code>] class instance</strong></li>
<li><strong>Specify the decoding strategy parameters</strong></li>
<li><strong>Save your generation configuration with [<code>GenerationConfig.save_pretrained</code>], making sure to leave its <code>config_file_name</code> argument empty</strong></li>
<li>Set <code>push_to_hub</code> to <code>True</code> to upload your config to the modelâ€™s repo</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> GenerationConfig

<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"my_account/my_model"</span><span class="token punctuation">)</span>  <span class="token comment"># doctest: +SKIP</span>
<span class="token operator">>></span><span class="token operator">></span> generation_config <span class="token operator">=</span> GenerationConfig<span class="token punctuation">(</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     max_new_tokens<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> top_k<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> eos_token_id<span class="token operator">=</span>model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>eos_token_id
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> generation_config<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">"my_account/my_model"</span><span class="token punctuation">,</span> push_to_hub<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># doctest: +SKIP</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>You can also store several generation configurations in a single directory, making use of the <code>config_file_name</code> argument in [<code>GenerationConfig.save_pretrained</code>]. You can later instantiate them with [<code>GenerationConfig.from_pretrained</code>]. This is useful if you want to store several generation configurations for a single model (e.g. one for creative text generation with sampling, and one for summarization with beam search).</strong> You must have the right Hub permissions to add configuration files to a model.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForSeq2SeqLM<span class="token punctuation">,</span> AutoTokenizer<span class="token punctuation">,</span> GenerationConfig

<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"google-t5/t5-small"</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"google-t5/t5-small"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> translation_generation_config <span class="token operator">=</span> GenerationConfig<span class="token punctuation">(</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     num_beams<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     early_stopping<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     decoder_start_token_id<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     eos_token_id<span class="token operator">=</span>model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>eos_token_id<span class="token punctuation">,</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     pad_token<span class="token operator">=</span>model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>pad_token_id<span class="token punctuation">,</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> <span class="token comment"># Tip: add `push_to_hub=True` to push to the Hub</span>
<span class="token operator">>></span><span class="token operator">></span> translation_generation_config<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">"/tmp"</span><span class="token punctuation">,</span> <span class="token string">"translation_generation_config.json"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> <span class="token comment"># You could then use the named generation config file to parameterize generation</span>
<span class="token operator">>></span><span class="token operator">></span> generation_config <span class="token operator">=</span> GenerationConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"/tmp"</span><span class="token punctuation">,</span> <span class="token string">"translation_generation_config.json"</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">"translate English to French: Configuration files are easy to use!"</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> generation_config<span class="token operator">=</span>generation_config<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">print</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'Les fichiers de configuration sont faciles Ã  utiliser!'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h2><p>The <code>generate()</code> supports streaming, through its <code>streamer</code> input. <strong>The <code>streamer</code> input is compatible with any instance from a class that has the following methods: <code>put()</code> and <code>end()</code>. Internally, <code>put()</code> is used to push new tokens and <code>end()</code> is used to flag the end of text generation.</strong></p>
<p>The API for the streamer classes is still under development and may change in the future.</p>
<p>In practice, you can craft your own streaming class for all sorts of purposes! We also have basic streaming classes ready for you to use. <strong>For example, you can use the [<code>TextStreamer</code>] class to stream the output of <code>generate()</code> into your screen, one word at a time:</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer<span class="token punctuation">,</span> TextStreamer

<span class="token operator">>></span><span class="token operator">></span> tok <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"openai-community/gpt2"</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"openai-community/gpt2"</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tok<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"An increasing sequence: one,"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> streamer <span class="token operator">=</span> TextStreamer<span class="token punctuation">(</span>tok<span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> <span class="token comment"># Despite returning the usual output, the streamer will also print the generated text to stdout.</span>
<span class="token operator">>></span><span class="token operator">></span> _ <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> streamer<span class="token operator">=</span>streamer<span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>
An increasing sequence<span class="token punctuation">:</span> one<span class="token punctuation">,</span> two<span class="token punctuation">,</span> three<span class="token punctuation">,</span> four<span class="token punctuation">,</span> five<span class="token punctuation">,</span> six<span class="token punctuation">,</span> seven<span class="token punctuation">,</span> eight<span class="token punctuation">,</span> nine<span class="token punctuation">,</span> ten<span class="token punctuation">,</span> eleven<span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="Decoding-strategies"><a href="#Decoding-strategies" class="headerlink" title="Decoding strategies"></a>Decoding strategies</h2><p><strong>Certain combinations of the <code>generate()</code> parameters, and ultimately <code>generation_config</code>, can be used to enable specific decoding strategies. If you are new to this concept, we recommend reading <a href="https://huggingface.co/blog/how-to-generate">this blog post that illustrates how common decoding strategies work</a>.</strong></p>
<p>Here, weâ€™ll show some of the parameters that control the decoding strategies and illustrate how you can use them.</p>
<h3 id="Greedy-Search"><a href="#Greedy-Search" class="headerlink" title="Greedy Search"></a>Greedy Search</h3><p><strong>[<code>generate</code>] uses greedy search decoding by default so you donâ€™t have to pass any parameters to enable it. This means the parameters <code>num_beams</code> is set to 1 and <code>do_sample=False</code>.</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer

<span class="token operator">>></span><span class="token operator">></span> prompt <span class="token operator">=</span> <span class="token string">"I look forward to"</span>
<span class="token operator">>></span><span class="token operator">></span> checkpoint <span class="token operator">=</span> <span class="token string">"distilbert/distilgpt2"</span>

<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'I look forward to seeing you all again!\n\n\n\n\n\n\n\n\n\n\n'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Contrastive-search"><a href="#Contrastive-search" class="headerlink" title="Contrastive search"></a>Contrastive search</h3><p>The contrastive search decoding strategy was proposed in the 2022 paper <a href="https://arxiv.org/abs/2202.06417">A Contrastive Framework for Neural Text Generation</a>. <strong>It demonstrates superior results for generating non-repetitive yet coherent long outputs.</strong> To learn how contrastive search works, check out <a href="https://huggingface.co/blog/introducing-csearch">this blog post</a>. <strong>The two main parameters that enable and control the behavior of contrastive search are <code>penalty_alpha</code> and <code>top_k</code>:</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM

<span class="token operator">>></span><span class="token operator">></span> checkpoint <span class="token operator">=</span> <span class="token string">"openai-community/gpt2-large"</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> prompt <span class="token operator">=</span> <span class="token string">"Hugging Face Company is"</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> penalty_alpha<span class="token operator">=</span><span class="token number">0.6</span><span class="token punctuation">,</span> top_k<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span>'Hugging Face Company <span class="token keyword">is</span> a family owned <span class="token keyword">and</span> operated business<span class="token punctuation">.</span> We pride ourselves on being the best
<span class="token keyword">in</span> the business <span class="token keyword">and</span> our customer service <span class="token keyword">is</span> second to none<span class="token punctuation">.</span>\n\nIf you have <span class="token builtin">any</span> questions about our
products <span class="token keyword">or</span> services<span class="token punctuation">,</span> feel free to contact us at <span class="token builtin">any</span> time<span class="token punctuation">.</span> We look forward to hearing <span class="token keyword">from</span> you!'<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Multinomial-sampling"><a href="#Multinomial-sampling" class="headerlink" title="Multinomial sampling"></a>Multinomial sampling</h3><p><strong>As opposed to greedy search that always chooses a token with the highest probability as the next token, multinomial sampling (also called ancestral sampling) randomly selects the next token based on the probability distribution over the entire vocabulary given by the model. Every token with a non-zero probability has a chance of being selected, thus reducing the risk of repetition.</strong></p>
<p>To enable multinomial sampling set <code>do_sample=True</code> and <code>num_beams=1</code>.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForCausalLM<span class="token punctuation">,</span> set_seed
<span class="token operator">>></span><span class="token operator">></span> set_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># For reproducibility</span>

<span class="token operator">>></span><span class="token operator">></span> checkpoint <span class="token operator">=</span> <span class="token string">"openai-community/gpt2-large"</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> prompt <span class="token operator">=</span> <span class="token string">"Today was an amazing day because"</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_beams<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span>'Today was an amazing day because when you go to the World Cup <span class="token keyword">and</span> you don\'t<span class="token punctuation">,</span> <span class="token keyword">or</span> when you don\'t get invited<span class="token punctuation">,</span>
that\<span class="token string">'s a terrible feeling."'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Beam-search-decoding"><a href="#Beam-search-decoding" class="headerlink" title="Beam-search decoding"></a>Beam-search decoding</h3><p><strong>Unlike greedy search, beam-search decoding keeps several hypotheses at each time step and eventually chooses the hypothesis that has the overall highest probability for the entire sequence. This has the advantage of identifying high-probability sequences that start with lower probability initial tokens and wouldâ€™ve been ignored by the greedy search.</strong></p>
<p>To enable this decoding strategy, specify the <code>num_beams</code> (aka number of hypotheses to keep track of) that is greater than 1.</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer

<span class="token operator">>></span><span class="token operator">></span> prompt <span class="token operator">=</span> <span class="token string">"It is astonishing how one can"</span>
<span class="token operator">>></span><span class="token operator">></span> checkpoint <span class="token operator">=</span> <span class="token string">"openai-community/gpt2-medium"</span>

<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> num_beams<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span>'It <span class="token keyword">is</span> astonishing how one can have such a profound impact on the lives of so many people <span class="token keyword">in</span> such a short period of
time<span class="token punctuation">.</span><span class="token string">"\n\nHe added: "</span>I am very proud of the work I have been able to do <span class="token keyword">in</span> the last few years<span class="token punctuation">.</span>\n\n"I have'<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Beam-search-multinomial-sampling"><a href="#Beam-search-multinomial-sampling" class="headerlink" title="Beam-search multinomial sampling"></a>Beam-search multinomial sampling</h3><p><strong>As the name implies, this decoding strategy combines beam search with multinomial sampling. You need to specify the <code>num_beams</code> greater than 1, and set <code>do_sample=True</code> to use this decoding strategy.</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSeq2SeqLM<span class="token punctuation">,</span> set_seed
<span class="token operator">>></span><span class="token operator">></span> set_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># For reproducibility</span>

<span class="token operator">>></span><span class="token operator">></span> prompt <span class="token operator">=</span> <span class="token string">"translate English to German: The house is wonderful."</span>
<span class="token operator">>></span><span class="token operator">></span> checkpoint <span class="token operator">=</span> <span class="token string">"google-t5/t5-small"</span>

<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> num_beams<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token string">'Das Haus ist wunderbar.'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="Diverse-beam-search-decoding"><a href="#Diverse-beam-search-decoding" class="headerlink" title="Diverse beam search decoding"></a>Diverse beam search decoding</h3><p><strong>The diverse beam search decoding strategy is an extension of the beam search strategy that allows for generating a more diverse set of beam sequences to choose from.</strong> To learn how it works, refer to <a href="https://arxiv.org/pdf/1610.02424.pdf">Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models</a>. <strong>This approach has three main parameters: <code>num_beams</code>, <code>num_beam_groups</code>, and <code>diversity_penalty</code>. The diversity penalty ensures the outputs are distinct across groups, and beam search is used within each group.</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSeq2SeqLM

<span class="token operator">>></span><span class="token operator">></span> checkpoint <span class="token operator">=</span> <span class="token string">"google/pegasus-xsum"</span>
<span class="token operator">>></span><span class="token operator">></span> prompt <span class="token operator">=</span> <span class="token punctuation">(</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"The Permaculture Design Principles are a set of universal design principles "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"that can be applied to any location, climate and culture, and they allow us to design "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"the most efficient and sustainable human habitation and food production systems. "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"Permaculture is a design system that encompasses a wide variety of disciplines, such "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"as ecology, landscape design, environmental science and energy conservation, and the "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"Permaculture design principles are drawn from these various disciplines. Each individual "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"design principle itself embodies a complete conceptual framework based on sound "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"scientific principles. When we bring all these separate  principles together, we can "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"create a design system that both looks at whole systems, the parts that these systems "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"consist of, and how those parts interact with each other to create a complex, dynamic, "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"living system. Each design principle serves as a tool that allows us to integrate all "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"the separate parts of a design, referred to as elements, into a functional, synergistic, "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"whole system, where the elements harmoniously interact and work together in the most "</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token string">"efficient way possible."</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForSeq2SeqLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> num_beams<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> num_beam_groups<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> max_new_tokens<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> diversity_penalty<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
'The Design Principles are a <span class="token builtin">set</span> of universal design principles that can be applied to <span class="token builtin">any</span> location<span class="token punctuation">,</span> climate <span class="token keyword">and</span>
culture<span class="token punctuation">,</span> <span class="token keyword">and</span> they allow us to design the'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>This guide illustrates the main parameters that enable various decoding strategies. More advanced parameters exist for the [<code>generate</code>] method, which gives you even further control over the [<code>generate</code>] methodâ€™s behavior. For the complete list of the available parameters, refer to the <a href="./main_classes/text_generation.md">API documentation</a>.</p>
<h3 id="Speculative-Decoding"><a href="#Speculative-Decoding" class="headerlink" title="Speculative Decoding"></a>Speculative Decoding</h3><p><strong>Speculative decoding (also known as assisted decoding) is a modification of the decoding strategies above, that uses an assistant model (ideally a much smaller one) with the same tokenizer, to generate a few candidate tokens. The main model then validates the candidate tokens in a single forward pass, which speeds up the decoding process.</strong> If <code>do_sample=True</code>, then the token validation with resampling introduced in the <a href="https://arxiv.org/pdf/2211.17192.pdf">speculative decoding paper</a> is used.</p>
<p><strong>Currently, only greedy search and sampling are supported with assisted decoding, and assisted decoding doesnâ€™t support batched inputs.</strong> To learn more about assisted decoding, check <a href="https://huggingface.co/blog/assisted-generation">this blog post</a>.</p>
<p><strong>To enable assisted decoding, set the <code>assistant_model</code> argument with a model.</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer

<span class="token operator">>></span><span class="token operator">></span> prompt <span class="token operator">=</span> <span class="token string">"Alice and Bob"</span>
<span class="token operator">>></span><span class="token operator">></span> checkpoint <span class="token operator">=</span> <span class="token string">"EleutherAI/pythia-1.4b-deduped"</span>
<span class="token operator">>></span><span class="token operator">></span> assistant_checkpoint <span class="token operator">=</span> <span class="token string">"EleutherAI/pythia-160m-deduped"</span>

<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> assistant_model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>assistant_checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> assistant_model<span class="token operator">=</span>assistant_model<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'Alice and Bob are sitting in a bar. Alice is drinking a beer and Bob is drinking a'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>When using assisted decoding with sampling methods, you can use the <code>temperature</code> argument to control the randomness, just like in multinomial sampling. However, in assisted decoding, reducing the temperature may help improve the latency.</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">>></span><span class="token operator">></span> <span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer<span class="token punctuation">,</span> set_seed
<span class="token operator">>></span><span class="token operator">></span> set_seed<span class="token punctuation">(</span><span class="token number">42</span><span class="token punctuation">)</span>  <span class="token comment"># For reproducibility</span>

<span class="token operator">>></span><span class="token operator">></span> prompt <span class="token operator">=</span> <span class="token string">"Alice and Bob"</span>
<span class="token operator">>></span><span class="token operator">></span> checkpoint <span class="token operator">=</span> <span class="token string">"EleutherAI/pythia-1.4b-deduped"</span>
<span class="token operator">>></span><span class="token operator">></span> assistant_checkpoint <span class="token operator">=</span> <span class="token string">"EleutherAI/pythia-160m-deduped"</span>

<span class="token operator">>></span><span class="token operator">></span> tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

<span class="token operator">>></span><span class="token operator">></span> model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> assistant_model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>assistant_checkpoint<span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> outputs <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> assistant_model<span class="token operator">=</span>assistant_model<span class="token punctuation">,</span> do_sample<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
<span class="token operator">>></span><span class="token operator">></span> tokenizer<span class="token punctuation">.</span>batch_decode<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token string">'Alice and Bob are going to the same party. It is a small party, in a small'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>Alternativelly, you can also set the <code>prompt_lookup_num_tokens</code> to trigger n-gram based assisted decoding, as opposed to model based assisted decoding.</strong> You can read more about it <a href="https://twitter.com/joao_gante/status/1747322413006643259">here</a>.</p>
<h2 id="ç»“è¯­"><a href="#ç»“è¯­" class="headerlink" title="ç»“è¯­"></a>ç»“è¯­</h2><p>ç¬¬ä¸€ç™¾å››åä¸‰ç¯‡åšæ–‡å†™å®Œï¼Œå¼€å¿ƒï¼ï¼ï¼ï¼</p>
<p>ä»Šå¤©ï¼Œä¹Ÿæ˜¯å……æ»¡å¸Œæœ›çš„ä¸€å¤©ã€‚</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        æ–‡ç« ä½œè€…:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">LuYF-Lemon-love</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        æ–‡ç« é“¾æ¥:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://luyf-lemon-love.space/2024/06/30/00143-wen-ben-sheng-cheng-ce-lue/">https://luyf-lemon-love.space/2024/06/30/00143-wen-ben-sheng-cheng-ce-lue/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        ç‰ˆæƒå£°æ˜:
                    </i>
                </span>
                <span class="reprint-info">
                    æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ¥å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜æ¥æº
                    <a href="/about" target="_blank">LuYF-Lemon-love</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>å¤åˆ¶æˆåŠŸï¼Œè¯·éµå¾ªæœ¬æ–‡çš„è½¬è½½è§„åˆ™</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">æŸ¥çœ‹</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                                    <span class="chip bg-color">æ·±åº¦å­¦ä¹ </span>
                                </a>
                            
                                <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                                    <span class="chip bg-color">å¤§è¯­è¨€æ¨¡å‹</span>
                                </a>
                            
                                <a href="/tags/huggingface/">
                                    <span class="chip bg-color">huggingface</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">èµ</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">è°¢è°¢å°ä¸»ï¼</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">æ”¯ä»˜å®</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">å¾® ä¿¡</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162303.png" class="reward-img" alt="æ”¯ä»˜å®æ‰“èµäºŒç»´ç ">
                    </div>
                    <div id="wechat">
                        <img src="https://cos.luyf-lemon-love.space/images/20220511162220.png" class="reward-img" alt="å¾®ä¿¡æ‰“èµäºŒç»´ç ">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;ä¸Šä¸€ç¯‡</div>
            <div class="card">
                <a href="/2024/06/30/00144-chatgpt-bei-hou-de-gong-chen-rlhf-ji-zhu-xiang-jie/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/009-119961062.jpg" class="responsive-img" alt="00144 ChatGPT èƒŒåçš„â€œåŠŸè‡£â€â€”â€”RLHF æŠ€æœ¯è¯¦è§£">
                        
                        <span class="card-title">00144 ChatGPT èƒŒåçš„â€œåŠŸè‡£â€â€”â€”RLHF æŠ€æœ¯è¯¦è§£</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-06-30
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-category">
                                    å¤§è¯­è¨€æ¨¡å‹
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ·±åº¦å­¦ä¹ </span>
                    </a>
                    
                    <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                        <span class="chip bg-color">å¤§è¯­è¨€æ¨¡å‹</span>
                    </a>
                    
                    <a href="/tags/huggingface/">
                        <span class="chip bg-color">huggingface</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                ä¸‹ä¸€ç¯‡&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/06/30/00142-gong-xiang-zi-ding-yi-mo-xing/">
                    <div class="card-image">
                        
                        <img src="https://cos.luyf-lemon-love.space/images/005-119971407.jpg" class="responsive-img" alt="00142 å…±äº«è‡ªå®šä¹‰æ¨¡å‹">
                        
                        <span class="card-title">00142 å…±äº«è‡ªå®šä¹‰æ¨¡å‹</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-06-30
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" class="post-category">
                                    å¤§è¯­è¨€æ¨¡å‹
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                        <span class="chip bg-color">æ·±åº¦å­¦ä¹ </span>
                    </a>
                    
                    <a href="/tags/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">
                        <span class="chip bg-color">å¤§è¯­è¨€æ¨¡å‹</span>
                    </a>
                    
                    <a href="/tags/huggingface/">
                        <span class="chip bg-color">huggingface</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- æ˜¯å¦åŠ è½½ä½¿ç”¨è‡ªå¸¦çš„ prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;ç›®å½•</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2022-2025</span>
            
            <a href="/about" target="_blank">LuYF-Lemon-love</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;æ€»è®¿é—®é‡:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;æ€»è®¿é—®äººæ•°:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2022";
                        var startMonth = "5";
                        var startDate = "7";
                        var startHour = "4";
                        var startMinute = "53";
                        var startSecond = "32";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
                <span id="icp"><img src="/medias/icp.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="https://beian.miit.gov.cn" target="_blank">å†€ICPå¤‡2022012632å·-1</a>
            </span>
            
            <br>
            
                <span id="gongan"><img src="https://cos.luyf-lemon-love.space/images/å¤‡æ¡ˆå›¾æ ‡.png"
                                    style="vertical-align: text-bottom;"/>
                <a href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=32011502011618" target="_blank">è‹å…¬ç½‘å®‰å¤‡ 32011502011618å·</a>
            </span>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yanfeng98" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:luyanfeng_nlp@qq.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS è®¢é˜…" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;æœç´¢</span>
            <input type="search" id="searchInput" name="s" placeholder="è¯·è¾“å…¥æœç´¢çš„å…³é”®å­—"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- ç™½å¤©å’Œé»‘å¤œä¸»é¢˜ -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
     
        <script type="text/javascript">
            // åªåœ¨æ¡Œé¢ç‰ˆç½‘é¡µå¯ç”¨ç‰¹æ•ˆ
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/libs/others/star.js"><\/script>');
            }
        </script>
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--è…¾è®¯å…”å°å·¢-->
    
    
    <script type="text/javascript" color="0,0,255"
        pointColor="0,0,255" opacity='0.7'
        zIndex="-1" count="99"
        src="/libs/background/canvas-nest.js"></script>
    

    

    
    <script type="text/javascript" src="/libs/background/ribbon-dynamic.js" async="async"></script>
    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
